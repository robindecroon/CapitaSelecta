<rdf:RDF
    xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
    xmlns:foaf="http://xmlns.com/foaf/0.1/"
    xmlns:dcterms="http://purl.org/dc/terms/"
    xmlns:dc="http://purl.org/dc/elements/1.1/"
    xmlns:ical="http://www.w3.org/2002/12/cal/ical#"
    xmlns:swrc="http://swrc.ontoware.org/ontology#"
    xmlns:bibo="http://purl.org/ontology/bibo/"
    xmlns:swc="http://data.semanticweb.org/ns/swc/ontology#"
    xmlns:led="http://data.linkededucation.org/ns/linked-education.rdf#"
    xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#" >
	<swc:ConferenceEvent rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008">
		<swc:completeGraph rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/complete"/>
		<swc:hasAcronym>EDM2008</swc:hasAcronym>
		<swc:hasRelatedDocument rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<rdfs:label>Educational Data Mining 2008</rdfs:label>	<ical:dtend rdf:datatype="http://www.w3.org/2001/XMLSchema#date">0000-00-00</ical:dtend>
		<ical:dtstart rdf:datatype="http://www.w3.org/2001/XMLSchema#date">0000-00-00</ical:dtstart><foaf:homepage rdf:resource=""/>
	</swc:ConferenceEvent>
	<swrc:Proceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings">
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/209"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/210"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/211"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/212"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/214"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/215"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/216"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/217"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/218"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/219"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/220"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/221"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/222"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/223"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/224"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/226"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/227"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/228"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/229"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/230"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/231"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/232"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/233"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/234"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/235"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/236"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/237"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/238"/>
		<swc:hasPart rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/239"/>
		<swc:relatedToEvent rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008"/>
		<swrc:booktitle>Proceedings of Educational Data Mining, 2008</swrc:booktitle>
		<swrc:month></swrc:month>
		<swrc:series></swrc:series>
		<swrc:year>2008</swrc:year>
	</swrc:Proceedings>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/209">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Mining Free-form Spoken Responses to Tutor Prompts</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/209/authorlist"/>
		<swrc:abstract>How can an automated tutor assess children’s spoken responses despite imperfect speech recognition?  We address this challenge in the context of tutoring children in explicit strategies for reading comprehension.  We report initial progress on collecting, annotating, and mining their spoken responses. Collection and annotation yield authentic but sparse data, which we use to synthesize additional realistic data.  We train and evaluate a classifier to estimate the probability that a response mentions a given target.</swrc:abstract>
		<led:body><![CDATA[ 1. 
 Table 1:  Predictors used in the logistic regression model. 
 To combine this information, we use binomial (or binary) logistic regression, which estimates the probability of an event Y as a logistic function of a set of input predictors X1, X2, …, Xn . In our case, Y = 1 iff a target occurs in an utterance, and X1, …, X5 are the five predictor variables in Table 1. The logit (i.e., the logarithm of the odds) of the target occurring is modeled as a linear function of the Xi, as shown in Equation 1: 
 FORMULA_1.
 Here Pr(occur) is the probability that the target occurs in the utterance, 0β is the intercept, and 1β , …, 5β are the respective regression coefficients for the predictors in Table 1.  The regression coefficient for each predictor describes the change in the logit associated with a unit change in that predictor.  A positive (negative) β means that an increase in the predictor will increase (decrease) the probability of the outcome. To make different β’s comparable, we first normalize the input predictors to range from 0 to 1, so that the absolute value of β measures the impact of that predictor compared to the others.  Given Pr(occur) for a target, we decide whether the target occurs by comparing Pr(occur) to a threshold, e.g. 0.5.  We decide yes if it’s larger than the threshold, otherwise no. We use a logistic regression model for several reasons.  First, it’s compact to represent, fast to compute, and easy to interpret.  Second, unlike linear regression it does not assume normally distributed variables.  Third, rather than a binary judgment as to whether the target occurs, it outputs a probability that a tutor could use to decide more judiciously which feedback to provide.  For example, if the tutor thinks the student said the target but is not very confident, it should hedge its reply rather than praise an answer that may well be wrong.  Finally, logistic regression outperformed the alternatives we compared it to. In cross-validation tests, it achieved higher precision, recall, and AUC (described in Section 4) than a Naïve Bayes classifier or a J48 decision tree. We used Weka 3.5.7 (from weka.sourceforge.net) to train the logistic regression model on the 9891 synthetic examples. As noted earlier, the class distribution on synthetic training data is skewed, with 9547 negative examples but only 344 positive examples for the 21 targets defined.  In contrast, the 64 held-out authentic utterances are more balanced, comprising 30 positive instances and 34 negative instances.   Differences in class distribution between training data and test data can hurt classifier performance, for instance by biasing the classifier against a class rare in the training set but common in the test set.  To address this problem, we used Weka’s cost-sensitive classification mechanism to balance the training data, so that its distribution of positive and negative instances resembles the distribution on authentic data.  Table 2 shows the resulting β parameter estimates for our five predictors. 
 Table 2:  Parameter estimates of the logistic regression model.
 As Table 2 shows, all predictors are positively correlated with the odds that the target occurs, but acoustic confidence is the strongest predictor.  Although one might expect long responses to be likelier to contain the target than short responses, the UttDur predictor is very weak, probably because we measured it by the size of the audio recording.   This recording includes the tutor prompt in the background, so its size reflects the combined duration of the prompt and the student’s utterance. 
 4 Evaluation.
 We tested our logistic regression model on both synthetic and authentic data.  We used 10-fold cross validation on the synthetic training data.   We also evaluated the model on the 64 authentically labeled utterances we used as held-out test data.  We compared against a majority class baseline model, which simply predicts the most common class for all instances. Table 3 compares the model performance on both data sets. We evaluate the classifiers on several metrics.  Overall accuracy is the fraction of cases classified correctly, i.e. (# TP (true positive) + # TN (true negative)) / # total cases, so it reflects the class distribution.  The TP rate, also called sensitivity or recall, is the fraction # TP / (# TP + # FN) of actual positive cases correctly classified as positive.  The FP (false positive) rate is the fraction # FP / (# TN + # FP) of actual negative cases misclassified as positive.  Its complement, called specificity, measures what fraction of actual negative cases is classified correctly as negative.  All these metrics depend on the probability threshold for classifying a case as positive – namely 0.5 for our model. Cross validation of the majority class baseline shows very high accuracy and zero FP rate because the synthetic data is highly skewed toward negative examples; its accuracy is much lower on the authentic data.  More importantly, such a classifier is useless because it cannot detect any mention of the target:  its TP Rate is 0.  In contrast, the logistic regression model is much more sensitive to positive examples. 
 Table 3:  Model performance under different testing options. 
 In practice, for the probabilistic output of logistic regression model Pr(occur) to be useful, we need to turn the probabilities into discrete decisions so as to provide tutorial feedback accordingly. For example, if the tutor is very sure that the target didn’t occur, it should give corrective feedback; but if it’s not sure, then a hedged reply is probably preferable. With this intuition, we decide on a preliminary division of Pr(occur) into 3 disjoint regions, based on two threshold values th and tl (0 < tl < th <1): • Yes:  confident that the target occurred in the utterance (Pr(occur) ≥ th); • No:  confident that the target didn’t occur in the utterance (Pr(occur) ≤ tl); • Unsure:  neither (tl < Pr(occur) < th). These thresholds control the tradeoff between coverage and precision. The higher the value of th, the fewer Yes decisions the tutor will make, but the more confident it can be of these decisions (assuming we have a reasonable model).  On the other hand, the tutor will hedge more of its feedback, presumably making it less helpful to students. To describe this tradeoff, Table 4 shows model coverage and precision on the set of 64 authentic responses for various threshold values. In the table, Pr(Yes) and Pr(No ) mean the probability of outputting a Yes and a No decision, respectively. Precision is the proportion of Yes (No) decisions that are in fact correct, i.e., positive (negative) examples.  For example, with high_threshold = 0.9 the tutor will decide only about 14% of the time that Yes, the student mentioned the target – but roughly 89% of these decisions will be correct. By dropping this threshold to 0.5, it can decide Yes more than twice as often – almost 30% of responses – and still be right about 84% of them. 
 Table 4:  Model coverage and precision with different threshold values. 
 Table 4 provides guidance both about where to set the threshold values, and about how definitively to phrase tutor feedback.  For example, it indicates that precision for Yes decisions is roughly the same (81%-89%) for thresholds from 0.5 to 0.9, so the tutor may as well set high_threshold at 0.5 (possibly even lower) in order to decide Yes more often, but its feedback must reflect that the student response probably contains the target but may well not.  For example, the tutor might refrain from confirming the answer as correct, but still treat it as correct in updating its student model.  In contrast, precision for No decisions is much more sensitive, ranging from 71% to 100% as low_threshold varies from 0.5 down to 0.1 – but with coverage ranging from over 70% to below 11%.  So the tradeoff between coverage and precision differs for the No case.  If our authentic training data is representative, setting low_threshold to 0.1 will avoid any false rejections, allowing definitively phrased corrective feedback.  However, at this threshold value, the tutor will decide No less than 11% of the time, even though the target will be absent about half the time.  On the other hand, a value of 0.5 will let the tutor decide No for 70% of student responses, but only 71% of these decisions will be correct.  In this case, tutor feedback must be phrased to avoid characterizing the student response as wrong. 
 5 Contributions and future work.
 This paper formulates the general problem of extracting reliable, tutorially useful information from children’s free-form spoken responses despite imperfect speech recognition, so as to assess their comprehension and select appropriate tutor feedback. We focus on the simpler but common and useful case of estimating the probability that an utterance mentions a given target concept. We describe efficient methods to collect authentic student data labeled by expert tutors, and to expand it into a much larger set of synthetic yet realistic data.  We present a logistical regression model to estimate the probability of a target by combining features of the target and utterance with the acoustic confidence output by a speech recognizer. We cross-validate the accuracy of the resulting probability estimates on synthetic data, and evaluate it on a smaller held-out set of authentic data. Concept mention is just one useful feature for tutors to detect.  We need to extend it to handle synonyms, but we have already extended it (in work omitted here to save space) from the single-target problem addressed in this paper to the multiple-target problem of deciding whether an utterance mentions any, all, or none of N given targets.  Another useful feature is the distinction between confident and tentative responses [6, 7].  Other distinctions in our expert tutor’s annotations include correct vs. incorrect, vague vs. detailed, and answered easily vs. with difficulty.  Future work includes using these distinctions to update student models and guide tutor decisions.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Mining Free-form Spoken Responses to Tutor Prompts</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/xiaonan-zhang"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/xiaonan-zhang"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/jack-mostow"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/jack-mostow"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/nell-duke"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/nell-duke"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/christina-trotochaud"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/christina-trotochaud"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-valeri"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-valeri"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/albert-t-corbett"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/albert-t-corbett"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/209/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/xiaonan-zhang"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/jack-mostow"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/nell-duke"/>
		<rdf:_4 rdf:resource="http://data.linkededucation.org/resource/lak/person/christina-trotochaud"/>
		<rdf:_5 rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-valeri"/>
		<rdf:_6 rdf:resource="http://data.linkededucation.org/resource/lak/person/albert-t-corbett"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/210">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Acquiring Background Knowledge for Intelligent Tutoring Systems</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/210/authorlist"/>
		<swrc:abstract>One of the unresolved problems faced in the construction of intelligent tutoring systems is the acquisition of background knowledge, either for the specification of the teaching strategy, or for the construction of the student model, identifying the deviations of students’ behavior. In this paper, we argue that the use of sequential pattern mining and constraint relaxations can be used to automatically acquire that knowledge. We show that the methodology of constrained pattern mining used can solve this problem in a way that is difficult to achieve with other approaches.</swrc:abstract>
		<led:body><![CDATA[ 1. Hierarchy of constraint relaxations. 
 Conservative relaxations group the already known relaxations, used in SPIRIT [4], and a third one – the Valid-Prefix. These relaxations impose a weaker condition than the original constraint, accepting patterns that are subsequences of accepted sequences. Although these relaxations have a considerable restrictive power, which improves significantly the focus on user expectations, they do not allow for the existence of errors. Approx relaxations accept sequences that are approximately accepted by the constraint, which means that the patterns are at an acceptable edit distance from some sequence accepted by the constraint. This edit distance reflects the cost of operations (such as insertion deletion or replacement), that have to be applied to a given sequence, so it would be accepted as a positive example of a given formal language [5]. Approx relaxations can be combined with other relaxations resulting in a new set of relaxations. In general, approximate relaxations can be seen as less restrictive than conservative ones, and can be used to identify the common behaviours of students that made a limited number of errors when comparing to the curriculum knowledge. The third class of relaxations is the Naïve relaxation, which corresponds to a simple item constraint. However, in the context of constraints expressed as formal languages, it can be seen as a relaxation that only accepts patterns containing the items that belong to the alphabet of the language. The naïve relaxation can be used to identify a portion of the frequent behaviours that comprise specific actions, permitting to understand the relations between those actions. Finally, Non-Accepted relaxations accept patterns that are not accepted by the constraint. This type of relaxation is useful when there is a well-known model for the generality of sequences, and the goal is to identify the sequences that are not accepted by that model. In this manner, it is possible to identify low frequency behaviors that are still very significant to the domain. Fraud detection is the paradigm of such task. Note that the difficulties in fraud detection are related with the explosion of discovered information when the minimum support decreases. It is important to note that the non-accepted relaxation will find all the patterns discovered by the other relaxations, representing a small improvement in the focus on user expectations. An interesting issue is to associate a subset of the alphabet in conjunction with non-accepted relaxation. This conjunction allows for focusing the mining process over a smaller part of the data, reducing the number of discovered sequences, and contributing to reach our goal. Like before, the sub-classes of Non- Accepted relaxations result by combining the non-acceptance philosophy with each one of the others relaxations. While non-accepted relaxation filters only a few patterns, when the constraint is very restrictive, the non-legal relaxation filters all the patterns that are non-legal with respect to the constraint. With this relaxation is possible to discover the behaviours that completely deviate from the accepted ones, helping to discover the fraudulent behaviours. A detailed definition of these relaxations for constraints specified as context-free languages see [3]. In the context of the acquisition of the bug library, the non-accepted relaxation is useful to discover the low-frequent misconceptions. Despite, they are less representative they could be very important as can be seen in the case study. 
 Table 1. List of common subjects, distributed by scientific area. 
 4 Curricula Analysis: a case study.
 In order to demonstrate our claims, consider the curriculum of an undergraduate program on information technology and computer science, with duration of five years (10 semesters) with 20 obligatory subjects (listed in Table 1), 16 subjects from a specific specialty area, an undergraduate thesis and 4 optional subjects in the last year. Also, consider there are four specialty areas: PSI – Programming and Information Systems; SCO – Computer Systems; IAR – Artificial Intelligence and IIN – Information Systems for Factory Automation. This information is usually publicly and previously known, and can be represented as a deterministic finite automaton (as shown on Figure 2). (This DFA shows the curriculum model for each specialty area (from the top to bottom: PSI, SCO, IAR and IIN, respectively; the existence of two different transitions per semester for SCO students, are due to a minor reorganization of the SCO curriculum on 1995/1996). 
 Figure 2. DFA for specifying the model curriculum for LEIC specialty areas. 
 The data used in this study refers to the data of the undergraduate students of the Licenciatura em Engenharia Informática e de Computadores (LEIC) at Instituto Superior Técnico, from the academic years of 1989/90 to 1999/2000. From these students we have only considered the students that have registered for at least eight semesters, and therefore may have concluded the 4th year. In this manner, the dataset is composed of 1440 sequences, corresponding to the curriculum followed by each LEIC student. These sequences have an average length equal to 11.58 semesters. Most of the students (72%) have between 8 and 12 enrolments. In terms of the number of enrolments per semester, its mean is 4.82 enrolments on subjects per semester, with most of students (75%) enrolling on between 4 and 6 units. Another interesting issue is the distribution of students per specialty area: 55% are PSI students, 19% SCO students, and IAR and IIN have 13% of students each. This distribution conditions the number of enrolments per course. For example, subjects exclusive to Artificial Intelligence and IIN have at most 13% of support. It is interesting to note that only 823 students (57%) have concluded the undergraduate thesis (TFC1 and TFC2). Since it is usual that students only took optional subjects in parallel or after finishing the undergraduate thesis, the support for optional subjects is at most 57%. Since the options are chosen from a large set of choices (130 subjects), their individual support is considerably lower. Indeed the course on Management (G) is the optional course with more students, about 40%. The goal of this study is to demonstrate that with the use of the program curriculum as background knowledge and the use of constraint relaxations is possible to discover the frequent students’ behaviours that approximately follow the curriculum. Note that if the background knowledge is used as a constraint to the sequential pattern mining process, only five patterns can be discovered: one for each specialty area (two for SCO). Moreover, it is probable that each pattern would have very low supports, since just a few students conclude all the subjects on their first enrolment. Next, we will present two experiments that illustrate the utility and effectiveness of our approach, respectively. 
 4.1 Finding frequent behaviours per specialty area.
 The first problem is related to the discovery of frequent behaviours per specialty area, and demonstrates the utility of our methodology. It is non trivial due to the difficulty of discovering which optional subjects are frequently chosen by which students. The difficulty of this task resides on the fact that all non-common subjects can be chosen as optional by some student. In this manner, a simple count of each subject support does not give the expected answer, since most of the subjects are required to some percentage of students. The other usual approach to find out the frequent choices would be to query the database to count the support of each course, knowing that students have followed some given curriculum. However, this approach is also unable to answer the question, since a considerable number of students (more than 50%) have failed one or more subjects, following a slightly different curriculum. In order to discover frequent behaviours, we have used the new methodology with the constraint based on the DFA in Figure 3, which corresponds to a sub-graph of the previous one. This automaton accepts sequences that represent the curricula on the fourth curricular year for each specialty area. With a constraint defined over this DFA filters all patterns that do not respect the model curriculum for the last two curricular years. 
 Figure 3. DFA for constraining the search of frequent behaviors per specialty areas. 
 The use of constrained sequential pattern mining (with the specified constraint) would not contribute significantly to answer the initial question, since it would only achieve results similar to the ones achieved by the query described above. However, the use of the Approx relaxation that accepts at most two errors (ε=2) chosen from a restricted alphabet composed by every non-common course, allows the discovery of 25 patterns with a support at least equal to 1% (Table 2). These patterns show that, in general, students mostly attend Computer Graphics and Economical subjects. 
 Table 2. Some of the discovered patterns with optional subjects. 
 It is interesting to note that whenever IIN students have failed on some course on the 4th year, they choose one of two particular courses in Economy; the same is true for PSI and IAR students (shadowed patterns in Table 2). Note that in order to discover these rules, we have to be able to admit some errors on the obligatory curricula per specialty area, which is not easily achieved by executing a query to a database. 
 4.2 Finding Abandon Reasons.
 The great difficulty in determining the effectiveness of our mining process is to determine which patterns are the relevant or interesting ones. In order to perform this evaluation, we considered a smaller problem whose results can be easily analyzed. The selected problem is to find the reasons why students abandon LEIC before concluding the 42 subjects required. This problem was chosen because it is easy to enumerate some reasons for abandon in LEIC. By applying common sense, we can suggest two different reasons: the inability to conclude the first computer science specific subjects (‘Programming Introduction’-[IP], ‘Digital Systems’-[SD], ‘Algorithms and Data Structures’-[AED] and ‘Computer Architecture’-[AC]), and the inability to conclude the generic engineering subjects (‘Linear Algebra’-[AL] and ‘Mathematical Analysis 1 and 2’-[AM1, AM2]). This knowledge can be represented by the automaton in Figure 4. 
 Figure 4. DFA for specifying the anticipated abandon reasons. 
 The dataset used to analyze this question consists on the set of sequences corresponding to the curriculum followed by each LEIC student, with his first enrolment made between 1989 and 1997. The dataset includes all the students that abandoned LEIC (at least temporarily). The dataset (LEICabandons) contains 489 sequences. In order to choose the relevant patterns, we applied the pattern discovery algorithms on both the LEICabandons and LEIC1989-2001 datasets, and identified as relevant the sequences that are frequent in the first dataset but are not frequent in the second one. With a support of 50%, 91 sequences have been discovered. From these, 79 are relevant by this criterion. A simple analysis of those sequences shows that most students that cancel their registration are not able to conclude more than two subjects in the second semester. Additionally, this analysis shows that the cancellation reasons anticipated and represented in the automaton in Figure 4 are close to the real reasons. 
 Table 3. Precision and Recall. 
 Assuming these sequences are relevant for this task, it is now possible to evaluate the effectiveness of the new methodology by comparing its results with the results reached with constraints, by counting the number of relevant sequences discovered with each relaxation. Considering the notions of precision and recall usually used for evaluating the effectiveness of information retrieval algorithms, it is possible to compare the use of constraints with the use of relaxations as proposed in this work. When applied to the mining process, precision corresponds to the ratio of relevant patterns retrieved by the process to all patterns retrieved by the process, and recall corresponds to the ratio of relevant patterns retrieved by the process to all relevant patterns in the dataset. Applying those measures it is clear that there are significant differences among the relaxations, as shown in Figure 5. 
 Figure 5. Precision and Recall chart. 
 Since there are only two retrieved sequences when the constraint is used, it is clear that the existing background knowledge is not complete, but is correct. In this manner, the recall of the constrained process is usually very low. The existence of more accurate background knowledge would increase the recall. On the other side, all the accepted sequences are relevant, which makes the precision of the process 100%. The relaxation that shows a better balance between those measures and the efficiency of the process is the approx relaxation, because it is possible to adjust the number of patterns discovered without compromising the precision. By increasing or decreasing the number of errors allowed, it is possible to compensate the excessive selectiveness of the background knowledge. Note that the recall increases considerably when the number of allowed errors increase, but the decrease of the precision is less accentuated. From this analysis and the other experiments presented in this work, it is clear that the great challenge of pattern mining, in general, and of sequential pattern mining, in particular, is to reach the balance between the number of discovered patterns and the user’s ability to analyze those patterns with the ability to discover unknown and useful information. The use of constraint relaxations, proposed in this work, represents a first step in this direction. 
 5 Conclusions.
 One of the problems in the construction of intelligent tutoring systems is the acquisition of background knowledge, both the teaching strategy and students’ frequent behaviour. In this paper, we proposed a methodology to acquire parts of that knowledge, based on the use of sequential pattern mining. Our methodology consists of discovering the frequent sequential patterns among the recorded behaviours, keeping the discovery limited to the sequences that, in some manner, are approximately in accordance to the existing background knowledge. The methodology assumes that the existing background knowledge can be represented by a context-free language, which plays the role of a constraint in the sequential pattern mining process. The use of the constraint relaxations enables the discovery of unknown patterns that correspond to the deviations to the expected behaviours. Different classes of relaxations express different levels of deviation of interest to the analyst. In this paper, we have applied the methodology on identifying the deviations of students’ behaviour from a pre-specified curriculum. In order to do that, we have represented the curriculum knowledge as a finite automaton, which establish the order of subjects that a student should attend to finish his graduation. Along with the use of sequential pattern mining, we tried the different relaxations, to answer specific challenges ranging from the identification of the frequent curricula instantiations, to the discovery of abandon reasons. Although the identified behaviours can be used to classify a student and to predict his next result, alone they do not identify the causes of the failures. An interesting open issue is the correlation of the students’ results with a specific teaching strategy. If this strategy and the corresponding expected results are known beforehand, our methodology can be used to identify the steps of the strategy that do not result as expected. In particular, the strategy in conjunction with the expected results can be represented as a context-free language and used as a constraint, to the sequential pattern mining process. In addition, an approx constraint will be able to discover the behaviour patterns that slightly deviate from the expected ones, which identify the failure steps.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Acquiring Background Knowledge for Intelligent Tutoring Systems</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/claudia-antunes"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/claudia-antunes"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/210/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/claudia-antunes"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/211">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Interestingness Measures for Association Rules in Educational Data</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/211/authorlist"/>
		<swrc:abstract>Educational data differs from traditional knowledge discovery domains in several ways. One of them is the fact that it is difficult, or even impossible, to compare different methods or measures a posteriori and  deduce which the best is. It is therefore essential to use techniques  and measurements that are fairly intuitive and easy to interpret.  Extracting the most interesting association rules can  be  quite  tricky.  One  of  the  difficulties  is  that  many  measures  of interestingness  do  not  work  effectively  for  all  datasets  and  are  hard  to understand intuitively by the teachers. We argue in this paper that  cosine and added value (or equivalently lift) are well suited to educational data, and that teachers can interpret their results easily. We argue that interestingness should be checked  with  cosine  first,  and  then with  lift  if  cosine rates  the  rule  as  non- interesting. If both measures disagree, teachers should use the intuition behind the measures to decide whether or not to dismiss the association rule. We provide a case study with data from a LMS.</swrc:abstract>
		<led:body><![CDATA[ 1. In terms of probability, this means that the occurrence of X and the occurrence of Y in the same transaction are independent events, hence X and Y are not correlated. It is easy to show that the lift is 1 exactly when added value is  0, the lift is greater than 1 exactly when added value is positive and the lift is below 1 exactly when added value is negative. Further AV(X→Y) tends towards 1 when lift(X→Y) tends towards infinity, and  AV(X→Y) tends towards -1 when lift(X→Y) tends towards 0. Note that  lift  X→Y =∣X ,Y∣. n∣X∣.∣Y∣  so the result is proportional to n, the total number of transactions. As opposed to cosine, lift does not hold the null-invariant property. 
 2.4 Typical values for cosine and lift.
 To fix  ideas  let  us  look  at  typical  values  for  these  measures  Suppose  that  among  n transactions,  m contain either  X or  Y or both,  with  m  ≤  n,  and that  n - m transactions contain neither X nor Y. First consider the case where all m transactions contain both X and Y. Then: cosine(X→Y) = 1. Conversely, it is easy to show that  cosine(X→Y) = 1 implies that all m transactions contain both  X and  Y. As for the lift, lift  X→Y =m . n/m. m=n /m . So if m = n, lift(X→Y)=1. If m = ½ . n,  lift(X→Y)=2 and so on. Consider now the case where 90% of the m transactions contain both X and Y, and 10% of the rest contain X but not Y. Then: 
 FORMULA_2.
 Now consider again the case where 90% of the m transactions contain both X and Y, but 5% of the rest contain X and not Y, and the other 5% contain Y and not X. In other words X and Y are evenly spread  among the transactions containing either X or Y but not both Then: 
 FORMULA_3.
 Table 1 summarizes further results. Lines should be read as follows: (a,b,c) means that a % of the m transactions contain both X and Y, b%  contain X and c% contain Y. Therefore (75, 100, 75) means that 75% of the  m transactions contain both  X and  Y and that the remaining 25% contain X but not Y (X is present in 100% of the transactions and Y in 75% of them), while (75, 87.5, 87.5) means that X or Y are evenly spread among the 25% of the remaining transactions. Discussion: In the case of strong symmetric association rules, which means that  ∣X∣ , ∣Y∣  and ∣X , Y∣  are all big numbers close to n, cosine and lift do not rate rules the same way, as pointed out  in [7]. In this case, cosine performs better than lift. Added value and lift  rely on probabilities, which make more sense when the number of observations is large. Further we see also that lift and added value, unlike cosine, depend on the number of transactions that contain neither X nor Y. In the educational field it is not clear that these null-transactions should play a role. We come to the same conclusion as [3]: double check the interestingness of association rules with cosine first, then with lift if cosine is not conclusive. Table 1 suggests that a value around or below 0.65 is rejected by cosine : as we can see 0.66 corresponds to the lowest threshold with 50% of common values (50, 75, 75). In case of contradictory results then decide using the information that these two measures represent. 
 Table 1.  Typical values for cosine and lift, where the 3 figures of the first column show the percentage of transactions containing X and Y, X and Y. 
 3 Improving Teacher Support: Case Study.
 The  present  case  study  describes  a  standard  use  of  a  Learning  Management  System (LMS) for providing additional resources to students in a face-to-face teaching context. Teachers want to figure out whether students use these resources and possibly whether their use has any (positive) impact on marks. The LMS Moodle [10] was used in the context of the course Formal Basics of Computer Science for first semester students enrolled in the degree “Computer Science and Media” at the University of Applied Sciences TFH Berlin during Winter Semester 2007/08. The cohort of 84 students enrolled in that course is divided into two groups. Students had a 3- hour  weekly  lecture.  It  includes  formal  teaching  where  concepts  are  explained, paper/pencil exercises to apply these concepts, and  exercises discussed on the spot. To pass this course students take two exams. The first one takes place about 8 weeks after the beginning of the semester and the second one at the end of the semester. The present case study uses data gathered till the first exam. Moodle is used for posting lecture slides and accessing the following extra resources: - Book: a link to the homepage of the text book “Introduction to Automata Theory, Languages  and  Computation”  used  for  this  course  [4].  From  this  homepage students could access a set of exercises with solutions. - DP:  extra reading “Design Patterns for finite automata” [6]. - Jflap [5], a software to practice automata construction. - Ex1, Ex2 ... Ex7 : a set of seven extra self-evaluation exercises.  One exercise is published in Moodle each week right after the lecture. The last exercise Ex7 was put 2 weeks before the exam. - TrEx01 and TrEx02 : two sample exams,  published 3 weeks before the exam. - TrEx01S and  TrEx02S,  the  solutions  to  the  sample  exams,  published  10  days before the exam. 
 The use of  Moodle, its additional resources and its self-evaluation exercises were not compulsory though strongly encouraged. Therefore for the teacher it is quite important to know: what do students do with those extra resources? What do they view? Is there any relationship between their use of these resources and their result in the exam? To answer these questions we have used solely the log data available in Moodle. Log data gives, for each resource and each student login, when the resource was accessed. It also gives, for each  exercise  and  each  student  login,  whether  the  exercise  has  been  attempted,  and whether the first trial was a success or not. 
 3.1 Exploring Data.
 From the 84 students enrolled in the course, 81 were enrolled in Moodle. The case study considers only those 81 students. From them, 52 passed the exam, 8 failed and 21 did not come. From the 60 who took the exam, statistics on their marks is given in the first line “General” of Table 4. Did students do the exercises? Table 2 summarizes the figures. Lines should be read as follows. For example line 2 means that 46 students did not attempt exercise 1, 21 students gave a correct answer on their first trial and 14 gave a wrong answer on their first trial. One notices that as time goes there is always less students attempting exercises. 
 Table 2.  Exploring exercises among all students. 
 Table 3.  Viewing resources. 
 Did they access other resources? Table 3 summarizes the figures. The first column says that  59 students  have viewed the first  sample exam,  the second column says that  52 students have viewed the solution of the first sample exam, and so on. One extra column has been added. AtLeast1Ex says that 38 students have attempted at least 1 exercise. What are the results in the exam for each group of Table 3? Table 4 summarizes the results. Two extra lines have been added. NoEx shows the results for students who have never attempted any exercise.  AtLeast1Ex shows the results for the students who have attempted at least 1 exercise. Table 3 and Table 4 suggest that the standard preparation for the exam is to look at sample exams and/or their solutions. Students who invest some more time with extra material tend to have better marks. The biggest positive impact on the marks is given by DP. 
 Table 4.  Viewing resources and marks in the exam. 
 Table 3 and 4 confirm the expected outcome. Table 4 also shows something that was not known before: students tend to access a sample exam more that its solution. This  first  exploration gives also directions for  more investigation:  If  students  attempt exercise 2, do they also attempt exercise 1? If they look at the solution of a sample exam, do they also look at the sample exam itself? This kind of questions can be investigated with association rules. 
 3.2 Association Rules.
 We  begin  with  association  rules  tackling  sample  exams.  The  following  rules  again confirm the expected finding. If students look at the solution of a sample exam, they look also at the sample exam itself. Further, if they view the second exam, then they also view the first one. The other way round does also hold, but with a slightly lower confidence. 
 Table 5.  Association rules for sample exams. 
 Results are similar when rules are mined restricting the population to the students who came to the exam as shown for the first sample exam in the lines in italic of Table 5. Notice however that the lift diminishes as the rules become stronger [7]. Table 2 gives a direction for further rules to investigate: Is there any association between attempting exercise i and exercise j? One expects that many students enthusiastically have begun with exercise 1 at the beginning of the semester and then slowly have stopped doing them, till exercise 4 where a bunch of students just keep doing them. The rules we have obtained confirm this interpretation. We have mined these rules restricting the data to students who have attempted at least 1 exercise, which means 38 transactions. Rules with a high confidence relate attempting exercise 2 and exercise 3,  exercises 4 to 7, as well as exercise 1, and not attempting exercises 2 to 3, or not attempting exercises 4 to 7.  Table 6 presents a sample of the extracted associations. Note that  !Ex2 means that exercise 2 has not been attempted. So the first line says if students don't attempt exercise 2, then they don't attempt exercise 3. 
 Table 6.  Association rules for attempted exercises. 
 For all these rules, except the last one, cosine and lift rate associations the same way. The drop  between  attempting  exercises  1  to  3  and  attempting  the  others  has  led  us  to investigate the marks of this population. Surprisingly, their average mark is smaller than for all students who have attempted at least 1 exercise. 
 Table 7.  Attempting exercises 4 to 7 and marks in the exam. 
 As for the other resources, were they consulted by the same students? We have looked at associations between DP, Jflap, Book and AtLeast1Ex considering the full population and show two rules found in Table 8. Here lift does not confirm the non-interesting rating given by cosine. As before, !DP means that the resource DP has not been viewed. 
 Table 8.  Association rules for the other resources. 
 Keeping  in  mind  the  meaning  of  measures  can  help  deciding  what  to  do  with  an association. Let us consider the last rule of Table 6. Cosine indicates that, among the students who have not done Ex5 nor Ex6, over 60% had done Ex1 (consult the typical figures in Table 1), while lift indicates that the proportion of students who have not done Ex5 and Ex6 is not larger in students who did Ex1 (which represented 43% of the students, according to table 2) than in all  students. However, from a pedagogical point of view, the case of students who did not attempt Ex1 is not relevant for this analysis. Therefore the teacher would probably find it useful to keep this rule, hence following cosine, though lift gives here an interesting complementary information. Let  us  now  consider  the  second  rule  of  Table  8.  Cosine  gives  us  the  following information: among the students who consulted the Book web site, the extra material on Design Patterns (DP) and done at least one exercise, less than 40% used Jflap (refer to the typical values in Table 1). The lift gives us the following information: the proportion of students who looked at  Jflap is higher among the students who looked at the Book web site, the DP material and done at least one exercise than in the whole student population. Given the very small number of students (as we can see from the support, there are 10 students who satisfied these three criteria on the left hand side of the rule), it is prudent to follow cosine and reject the rule. It is interesting to note though that if the cosine and lift had given similar values, but with a higher number of students satisfying the three criteria in the left side of the rule, it would then have been advisable to follow the lift and retain the rule. 
 Conclusion. 
 Association rules are useful in Educational Data Mining for analysing learning data. This technique  requires  not  only  that  adequate  thresholds  be  chosen  for  the  two  standard parameters  of  support  and  confidence,  but  also  that  appropriate  measures  of interestingness be considered to retain meaningful rules and filter uninteresting ones out. In this paper we revisited and gave an interpretation for two interestingness measures: cosine and added value (which we saw is closely related to the lift). We presented typical values for these measures. An association rule is rated uninteresting by cosine if its value is around or smaller than 0.65, whereas it is rated uninteresting by the lift if its value is around or under 1. We came to a similar conclusion as in [3]: the interestingness of a rule should be first measured by the cosine, then with lift if cosine rated it as uninteresting. In case  of  conflict  between  the  two  measures,  the  user  needs  to  take  into  account  the intuitive  information  provided  by  each  measure  and  decide  upon  it.  The  case  study presented in the paper depicts a standard situation: a LMS provides additional resources for students in complement to the face-to-face teaching context. Teachers want to figure out whether students use these resources and whether these have any (positive) impact on marks.  Few association rules (without being strong symmetric  ones) came out with a contradictory result for cosine and lift. Keeping in mind the intuition behind cosine and lift helped to decide whether to discard these rules. Another conclusion of this work is that common LMS are far from being data mining friendly. Log data concerning access to resources and test data are not stored the same way for example. Complex data manipulation is needed to get all data consolidated in a useful  form. LMS  present statistics,  however these are very limited.  LMS should be enhanced with a special module with good facilities for exploring data. Data mining tools for  LMS should  have  an  association rules  module  with  good facilities  to  choose  the attributes to derive association rules for and with the two interestingness measures cosine and lift.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Interestingness Measures for Association Rules in Educational Data</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/agathe-merceron"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/agathe-merceron"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/kalina-yacef"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/kalina-yacef"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/211/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/agathe-merceron"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/kalina-yacef"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/212">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>A pilot study on logic proof tutoring using hints generated from historical student data</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/212/authorlist"/>
		<swrc:abstract>We have proposed a novel application of Markov decision processes (MDPs), a reinforcement learning technique, to automatically generate hints using historical student data. Using this technique, we have modified a an existing, non-adaptive logic proof tutor called Deep Thought with a Hint Factory that provides hints on the next step a student might take. This paper presents the results of our pilot study using Deep Thought with the Hint Factory, which demonstrate that hints generated from historical data can support students in writing logic proofs.</swrc:abstract>
		<led:body><![CDATA[]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>A pilot study on logic proof tutoring using hints generated from historical student data</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/tiffany-barnes"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/tiffany-barnes"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/john-c-stamper"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/john-c-stamper"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/lorrie-lehman"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/lorrie-lehman"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/m-croy"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/m-croy"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/212/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/tiffany-barnes"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/john-c-stamper"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/lorrie-lehman"/>
		<rdf:_4 rdf:resource="http://data.linkededucation.org/resource/lak/person/m-croy"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Can an Intelligent Tutoring System Predict Math Proficiency as Well as a Standardized Test?</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213/authorlist"/>
		<swrc:abstract>It has been reported in previous work that students’ online tutoring data collected from intelligent tutoring systems can be used to build models to predict actual state test scores. In this paper, we replicated a previous study to model students’ math proficiency by taking into consideration students’ response data during the tutoring session and their help-seeking behavior. To extend our previous work, we propose a new method of using students test scores from multiple years (referred to as cross-year data) for determining whether a student model is as good as the standardized test to which it is compared at estimating student math proficiency. We show that our model can do as well as a standardized test. We show that what we assess has prediction ability two years later. We stress that the contribution of the paper is the methodology of using student cross-year state test score to evaluate a student model against a standardized test.</swrc:abstract>
		<led:body><![CDATA[ 1.89 that is 11% of the maximum score on half of the test.  Since their prediction error in [9] is very close to 11%, they claimed that their approach did as well as MCAS test on predicting math proficiency. In this paper, we propose a different approach to use student cross-year data for determining whether a student model is as good as the standardized test at estimating student proficiency. Assume student math proficiency in the 8th grade and in the 10th grade are highly correlated. Since the 6 Raftery [[13] discussed a Bayesian model selection procedure, in which the author proposed the heuristic of a BIC difference of 10 is about the same as getting a p-value of p = 0.05 measurement error is relatively independent due to the two years time interval between the tests, therefore, whichever (our student model or the MCAS test) better predicts 10th grade MCAS score is better assessing student  math skill at 8th grade. Let define MCAS8’ be the leave-one-out7 predicted score for 8th grade MCAS that comes from our best student model, the mixed model; MCAS8 be the actual 8th grade MCAS score and MCAS10 be the actual 10th grade MCAS score. Then we asked the question: Can MCAS8’ predict MCAS10 better than MCAS8 does? To answer the question, we calculated the correlation between the three metrics: MCAS8’, MCAS8 and MCAS10, as presented in Figure 1. 
 Figure 1: Correlation between IRT student proficiency estimate, MCAS8’, MCAS8 and MCAS10. 
 First of all, we want to point out that all correlations in Figure 1 are statistically reliable (p < 0.001). The student proficiency estimated by the lean model correlates with MCAS10 with r equal to .628. It does not do as well as MCAS8 and MCAS8’ as we have expected. Even though, we think it is worth finding out and having this lean model, which is based on less data, as a contrast case. It is the most direct test of the question of whether ASSISTment use could essentially replace the 8th grade test. Both MCAS8 and MCAS8’ are reliable predictors of MCAS10. MCAS8 correlates with MCAS10 with r equal to 0.731 while the correlation between MCAS8’ and MCAS10 is fractionally lower (r = 0.728). A significance test8 shows they are not statistically reliably different, which suggests that our student model can do as well as MCAS test on predicting the MCAS score two years later. Since both MCAS tests are measuring the student’s math proficiency, it can be considered as the evidence that the student model is doing a good job estimating student math proficiency. At the very least, what our system is modeling is relatively stable across a two-year interval. 
 {7} The adjusted predicted score is calculated by doing “leave-one-out” cross validation in SPSS. 
 {8} The test is done online at http://www.quantitativeskills.com/sisa/statistics/correl.htm 
 4 Discussion.
 There has been a big interest on modeling student knowledge. Corbett & Bhatnagar [6] describes an early and successful effort to increase the predictive validity of student modeling in the ACT Programming Tutor (APT). They used assessments from a series of short tests to adjust the knowledge tracing process in the tutor and more accurately predict individual differences among students in the post test. Beck & Sison [3] used knowledge tracing to construct a student model that can predict student performance at both coarse- (overall proficiency) and fine-grained (for a particular word in the reading tutor) sizes. Anozie & Junker [1] pursued a rather different approach, looking at the changing influence of online ASSISTment metrics on MCAS performance over time. They computed monthly summaries of online metrics similar to those developed in [8], and built several linear prediction models, predicting end-of-year raw MCAS scores for each month. In [8] we developed the metrics as listed in section 3.2 to measure the amount of assistance a student needs to solve a problem, how fast a student can solve a problem, etc. and showed these metrics helped us better assess students. The result in this paper reinforced our previous result as evaluated by a different approach. In section 3, we describe the method of using student test data from multiple years to compare a student model to a standardized test. Two other approaches have been described in the literature. In [3], Beck & Sison found 3 tests that measures extremely similar constructs to the standardized test that they were interested in. They took the arithmetic mean of those tests as a proxy measure for the true score on the original measure. The pro of this method is that it can be done quickly while the con is that construct validity could be an issue. In [9], we ran a simulation study by “splitting” a standardized test into two parts and the prediction power of the standardized test (actually a half of the standardized test) is determined by how well student performance on one half of the test predicts their performance on the other half. Similarly to the “proxy” measure method in [3], the pro of the “splitting” method is the quickness but it also has some cons. Firstly, if there is measurement error for a particular day (e.g. a student is somewhat ill or just tired), then splitting the test in half will produce a correlated measurement error in both halves, artificially increasing the test's reliability relative to the measure we bring up in this paper (which is not based on data from the same day as the MCAS).  Secondly, to do the splitting, it required assess to item level data which is not always available. In this paper, we propose a third method, which is a longitudinal approach. By going across years, we avoid this confound with measurement error, and get a fairer baseline. Though, we do admit that it takes longer time and harder effort to collect data across years (in our case, 3 years). 
 5 Future work and Conclusions.
 We will continue working on improving the online assistance metrics. For instance, since the number of hints available is different across problems and the amount of information released in each level of hint differs too, instead of simply summing-up or computing the mean value, we want to construct some weighting function to better measure the amount of assistance students requested to solve a problem. Another piece of work follows up is to predict fine grained knowledge across years. Since our model is clearly capturing something that is predictive of student future performance, we are considering focusing on determining what predicts specific deficits in an area. The research question we want to answer will be: can an 8th grade student model be used to predict the student will have a problem with a specific 10th grade skill? Teachers will be glad to know the answer so that they can adjust their instruction to better help student knowledge learning. In this paper, we replicated the study in [8], showing the online ASSISTment metrics are doing a good job at predicting student math proficiency. On top of that, we propose a new method for evaluating the predictive accuracy of a student model relative to the standardized test, using student standardized test scores across years (2005 through 2007). We found some evidence that we can model student math proficiency as well as the standardized test as measured by the new evaluation criterion. Additionally, we want to stress that this is a rather long-term prediction. The collection of the online data started in September, 2004; the 8th grade MCAS score that we are predicting came in at the end of year 2005; while the 10th grade MCAS score that we used to evaluate our prediction were available at the end of year 2007. We consider the new method as a main contribution of this paper as there are few results showing a student model is as good as a standardized test. We have shown that our model hits this level and have presented an alternative way of performing the comparison. 
 Acknowledgement.
 This research was made possible by the U.S. Department of Education, Institute of Education Science (IES) grants, “Effective Mathematics Education Research” program grant #R305K03140 and “Making Longitudinal Web-based Assessments Give Cognitively Diagnostic Reports to Teachers, Parents, & Students while Employing Mastery learning” program grant #R305A070440, the Office of Naval Research grant # N00014-03-1-0221, NSF CAREER award to Neil Heffernan, and the Spencer Foundation. All the opinions, findings, and conclusions expressed in this article are those of the authors, and do not reflect the views of any of the funders. 
 Reference.
 [1] Anozie N., & Junker B. W. (2006). Predicting end-of-year accountability assessment scores from monthly student records in an online tutoring system. In Beck, J., Aimeur, E., & Barnes, T. (Eds). Educational Data Mining: Papers from the AAAI Workshop. Menlo Park, CA: AAAI Press. pp. 1-6. Technical Report WS-06-05. 
 [2] Ayers E., & Junker B. W. (2006). Do skills combine additively to predict task difficulty in eighth grade mathematics? In Beck, J., Aimeur, E., & Barnes, T. (Eds). Educational Data Mining: Papers from the AAAI Workshop. Menlo Park, CA: AAAI Press. pp. 14-20. Technical Report WS-06-05. 
 [3] Beck, J. E., & Sison, J. (2006). Using knowledge tracing in a noisy environment to measure student reading proficiencies. International Journal of Artificial Intelligence in Education, 16, 129-143. 
 [4] Brown, A. L., Bryant, N.R., & Campione, J. C. (1983). Preschool children’s learning and transfer of matrices problems: Potential for improvement. Paper presented at the Society for Research  in Child Development meetings, Detroit. 
 [5] Corbett, A. T., Koedinger, K. R.,& Hadley,W. H. (2001). Cognitive Tutors: From the research classroom to all classrooms. In Goodman, P. S. (Ed.) Technology Enhanced Learning: Opportunities for Change. Mahwah, NJ: Lawrence Erlbaum Associates. 
 [6] Corbett, A.T. and Bhatnagar, A. (1997).  Student modeling in the ACT Programming Tutor: Adjusting a procedural learning model with declarative knowledge.  Proceedings of the Sixth International Conference on User Modeling.  New York:  Springer-Verlag Wein. 
 [7] Embretson, S. E. & Reise, S. P. (2000). Item Response Theory for Psychologists. Lawrence Erlbaum Associates, New Jersey. 
 [8] Feng, M., Heffernan, N.T., & Koedinger, K.R. (2006a). Addressing the Testing Challenge with a Web-Based E-Assessment System that Tutors as it Assesses. Proceedings of the Fifteenth International World Wide Web Conference. pp. 307-316. New York, NY: ACM Press. 2006. 
 [9] Feng, M., Heffernan, N.T., & Koedinger, K.R. (2006b). Predicting state test scores better with intelligent tutoring systems: developing metrics to measure assistance required. In Ikeda, Ashley & Chan (Eds.). Proceedings of the 8th International Conference on Intelligent Tutoring Systems. Springer-Verlag: Berlin. pp. 31-40. 2006. 
 [10] Feng, M. & Heffernan, N. (2007). Towards Live Informing and Automatic Analyzing of Student Learning: Reporting in ASSISTment System. Journal of Interactive Learning Research. 18 (2), pp. 207-230. Chesapeake, VA: AACE. 
 [11] Grigorenko, E. L. & Sternberg, R. J. (1998). Dynamic Testing. In Psychological Bulletin, 124, pages 75-111. 
 [12] Olson, L. (2005). Special report: testing takes off. Education Week, November 30, 2005, pp. 10–14. 
 [13] Raftery, A. E. (1995). Bayesian model selection in social research. In Sociological Methodology, 25, pages 111-163. 
 [14] Razzaq, L., Feng, M., Nuzzo-Jones, G., Heffernan, N.T., Koedinger, K. R., Junker, B., Ritter, S., Knight, A., Aniszczyk, C., Choksey, S., Livak, T., Mercado, E., Turner, T.E., Upalekar. R, Walonoski, J.A., Macasek. M.A., Rasmussen, K.P. (2005). The Assistment Project: Blending Assessment and Assisting. In C.K. Looi, G. McCalla, B. Bredeweg, & J. Breuker (Eds.) Proceedings of the 12th International Conference on Artificial Intelligence In Education, 555-562. Amsterdam: ISO Press 
 [15] Razzaq, Feng, Heffernan, Koedinger, Nuzzo-Jones, Junker, Macasek, Rasmussen, Turner & Walonoski (2007). Blending Assessment and Instructional Assistance. In Nadia Nedjah, Luiza deMacedo Mourelle, Mario Neto Borges and Nival Nunesde Almeida (Eds). Intelligent Educational Machines within the Intelligent Systems Engineering Book Series . pp.23-49. (see http://www.isebis.eng.uerj.br/). Springer Berlin / Heidelberg. 
 [16] Van der Linden, W. J. & Hambleton, R. K. (eds.) (1997). Handbook of Model Item Response Theory. New York: Springer Verlag.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Can an Intelligent Tutoring System Predict Math Proficiency as Well as a Standardized Test?</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/mingyu-feng"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/mingyu-feng"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-e-beck"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-e-beck"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/mingyu-feng"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-e-beck"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan"/>
		<rdf:_4 rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/214">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Argument Graph Classification via Genetic Programming and C4.5</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/214/authorlist"/>
		<swrc:abstract>In well-defined domains there exist well-accepted criteria for detecting good and bad student solutions. Many ITS implement these criteria characterize solutions and to give immediate feedback. While this has been shown to promote learning, it is not always possi- ble in ill-defined domains that typically lack well-accepted criteria. In this paper we report on the induction of classification rules for student solutions in an ill-defined domain. 1 We compare the viability of classifications using statistical measures with classification trees induced via C4.5 and Genetic Programming.</swrc:abstract>
		<led:body><![CDATA[ 1. LARGO analyzes the student diagrams for structural, contextual and content-related “charac- teristics” which we use as the basic features of our current analysis. Each characteristic is defined by a particular graphical pattern that, if it matches some portion of a student’s diagram, identifies a possible structural weakness or opportunity for reflection. 
 Figure 1. Sample LARGO Graph. 
 The characteristics were developed with the help of an experienced legal instructor. For example UNLINKED_TEST, a context char- acteristic is active when the student has formed a test box in the graph but has not linked that box to the transcript. Such linking is a necessary part of good note-taking as it enables the students to reconnect their diagrams to the relevant parts of the arguments. The structural characteristic FACTS_ISOLATED_FROM_HYPOS is active when the student has produced a fact node but not linked it to the relevant hypothetical nodes. These diagram characteristics are associated with phases of graph production (1=orientation, 2=transcript markup, 3=diagram creation, 4=analysis, and 5=reflection). Characteristics of phases 1-3 can be thought of as indicating basic “weaknesses” of a diagram (e.g. UNLINKED_TEST), while characteristics of phases 4 and 5 stand for opportunities for reflection contained in a diagram. The system provides feedback on diagrams in the form of self-explanation prompts triggered by the characteristics. In the earlier phases these prompts inform the student about how to fix up the diagrams. In the later phases, the prompts encourage reflection on the diagram and argument representation. These hints are provided upon request. LARGO also contains a facility for collaborative feedback. For each case in the system we have identified two target test statements in the transcript. These are test statements that our do- main expert considered to be particularly crucial for the analysis process. Students who link a test node to one of these statements are given the opportunity to rate other students’ statements of the same test and to reconsider their own. Students who go through the process and whose tests are rated poorly by their peers are given the opportunity to change their own test in response. This characteristic is TEST_REVISION_SUGGESTED. It is active for students whose test has been rated poorly but have not changed the test statement. See [14] for a more detailed analysis of the help system and an argument example. We have completed three studies of the LARGO system. In the Fall of 2006 we conducted a study with paid volunteers taken from the first year class at the University of Pittsburgh’s School of Law (Novice-2006). Students were randomly assigned to analyze a pair of cases using LARGO or a text-based notepad tool with no feedback. We compared test scores between the groups and analyzed student interactions with the system. We found no overriding difference between the conditions, and close examination of the questions showed that some were too easy causing a ceiling effect. However on other question types lower aptitude students, as measured by their Law School Admission Test (LSAT) score (a frequently used predictor for success at law schools) in the LARGO condition, showed higher learning gains on some question types than their low-LSAT text peers. Also, the use of the help features was strongly correlated with learning [15]. In the Fall of 2007 we performed a follow-up study as part of the first year legal process course (Novice-2007). The study was mandatory for all 85 class members. As before students were assigned randomly to text or graph conditions. However the study included one additional case and students answered case-specific essay questions after each session. We also replaced some questions from the pre- and post-tests that had produced a ceiling effect with more challenging alternatives. We again found no significant differences between conditions. A post-hoc analysis revealed that the students in the first study made far more use of the advice functions than the students in the second study, which may explain the difference between the study outcomes. We are presently conducting a follow-up study with LARGO among third-year law students (Expert-2008). All participants in this study used LARGO and performed the same set of tasks as those in Expert-2007. The purpose of this study is to examine novice-expert differences in the context of LARGO. At the time of this paper a total of 17 third-year students have completed the study and their data, along with data from the Novice-2007 study, are employed below. C4.5 is a decision tree induction algorithm [16]. When presented with data it induces an n-ary decision tree that acts as a functional classifier. Each interior node of the tree represents a logical test that branches to one child or another based upon the outcome of the test. Leaf nodes represent predictions or decisions made. Decision trees are traversed from root to leaf. Each decision path p from the root to a leaf node defines a class of cases based upon the relevant features and a classification tag to be assigned to those cases. Each tree therefore represents a hypothesis or test for carving up the space of diagrams according to the factors involved in each. One such decision tree, and its representation in pseudocode are shown in Figure 2. As we shall discuss below this tree predicts student scores as at or below the mean (0) or above the mean (1) where the inner nodes represent tests for the presence or absence of graph characteristics and the leaves, classifications. Each unique path from root to leaf in a decision tree defines a distinct class of objects. For our purposes these denote unique classes of student solutions. Intriguingly TEST_REVISION_SUGGESTED is taken as a sign of high performance. As we noted above, this is a later phase characteristic and will not be active unless the students have successfully marked up a target region of the diagram with a test node, and then made use of the collaborative feedback with their test summary having been given a poor rating by their peers. 
 Figure 2. Sample Decision Tree with Pseudocode. 
 Genetic Programming (GP) is a type of Evolutionary Computation (EC) [12, 2]. In EC algorithms a population of candidate problem solutions is evolved over time via selection mutation, multiple-parent crossover and other operations inspired by biological reproduction. The field of EC arose initially out of work in artificial life [13] and has since been applied in a number of domains including design and decision making. EC is a stepwise algorithm that starts with a population of randomly generated or externally defined candidate solutions. The fitness of each individual is assessed either by comparison to a gold standard or a competitive “tournament” selection. Based upon this fitness individuals are then permitted to pass their genetic code to the next by means of cloning, combination of genetic material with other fit members, or random mutation. The algorithm as a whole continues until an absolute fitness threshold is reached or a maximum number of generations has passed. In genetic programming the individual members of the population are interpreted as function code with their performance compared against a target function or task. For the purposes of our experiments the target function was the mapping φ : f → bm of graph features f to the mean- score bin bm we discussed above. In this case the raw fitness is defined by the ratio of correct classifications to total classifications in the set. One disadvantage of GP is the tendency of systems using unconstrained representations (like ours) to select for code that is not just successful but genetically robust. Such code is characterized by introns or redundant code elements that protect the core function from destructive crossover and slow the discovery of new solutions. This necessitates the use of parsimony pressure to control code growth. In this project we applied a scaled penalty based upon size. Higher performing trees were assessed a larger penalty than lower performers. In this experiment we made use of two reproduction operators: mutation and crossover. Under mutation an individual is copied directly into the next generation with a sub-tree being replaced by a new, randomly generated sub-tree. Under crossover, two parents exchange randomly selected sub-trees with the children being passed to the next generation. Members of the population at time t are selected for reproduction based upon their fitness. Some forms of GP select individuals proportionally according to their absolute fitness. However this often results in extreme genetic drift toward initially fit individuals and reduces the selection pressure as the σ f ,t goes down. We therefore employed sigma scaling to assign each individual a reproductive fitness value of: 
 FORMULA_1.
 We then select individuals using Stochastic Universal Sampling [12] which ensures that each individual reproduces at least ⌊Exp(i, t)⌋ but no more than ⌈Exp(i, t)⌉ times. Taken together these measures prevent genetic drift by ensuring that selection pressure is still high even as the absolute fitness increases. As a machine learning algorithm, GP has a number of advantages. It is well suited to the evolution of arbitrary structures ranging from neural networks to object-oriented programs. This makes it attractive for our present purposes. However, GP also has a number of disadvantages. As a non-deterministic algorithm it makes fewer guarantees about its performance than a more bounded, biased and specialized algorithm such as C4.5. And, while the statistical behavior of the system and use of proper tuning work to prevent random drift, it cannot be completely eliminated. It is also computationally costly; each of our runs required 12 hours of operation on a modern PC. 
 3 Results and Analysis.
 As stated in the introduction, our goal in this study is to examine the prospects for automatically inducing higher-order pedagogical knowledge from subject graphs. By analyzing subject graphs using machine learning methods we seek to identify potential target rules for the classification of successful and unsuccessful learners and to explore the interaction of the graph characteristics. For purposes of this analysis we made use of the final graphs and post-test scores taken from the Novice-2007 and Expert-2008 studies. In both studies the subjects followed the same procedure and took the same tests. The graphs we analyzed were produced for two competing arguments in the Burnham v. Superior Court (495 U.S. 604) case, each of which was represented as a single unified set of graph characteristics as interpreted by LARGO. The post-test score was a single value representing their overall score in the absolute range. We elected to use the final graph students generated in the course of the study as it was created as the culmination of the students’ training and thus, was most likely to be correlated with their final performance. We were forced to remove some of the Novice-2007 subjects from our analysis as they took too little time on the post-test or too little time to read the cases (both indicating a lack of serious effort) or, in the case of four, because they candidly informed us that they were not trying to answer the questions. This left us with 34 students from the Novice-2007 study and 17 from the Expert-2008 study giving us a total of 51 graph/test pairs. We binned the graph/test pairs according to their post-test score. We then binned the subjects by mean score (0.63) into two groups, those above the mean, and those at or below it. Of the 51 students 22 were below the mean while 29 were above it. Two of the Expert-2008 subjects fell below the mean score. Our χ2, C4.5 and GP analyses below are based upon this grouping. Statistical Comparisons: As we report in [10], simple statistical analyses of the graph fea- tures such as the number of nodes or relations do not correlate highly with the students’ learning outcomes. This was true both for the full set of 51 subjects as well as the study subgroups. While some of the measures do correlate with group membership (i.e., expert students produce more in- terconnected graphs than non-experts) they do not correlate with students’ ultimate performance. Our analysis showed no overall correlation between the phase groups and student performance. Again while there was some difference between the study groups those differences were not signif- icant. However, once we binned the full set of graph results by mean score a distinction emerged. In particular two of the characteristics were significantly correlated with bin membership. UN- LINKED_HYPO was significantly correlated with having a less than average score (c2(16.16,N = 51) = 1.00, p < 0.001) as was UNLINKED_TEST (c2(18.27,N = 51) = 1.00, p < 0.001). This highlights the importance of students’ linking of tests and hypos in their diagrams to the argument transcript. In addition, TEST_REVISION_SUGGESTED was marginally significantly correlated with high performance (c2(4.07,N = 51) = 1.00, p < 0.05). As the reader will recall this is a ’late phase’ characteristic and requires some successful problem solving steps to occur before it is active. This strong correlation of the linking features with student performance fits our domain model. The connection of diagram elements to the argument transcript enables students to retain the context for each note and helps them to develop a “respect for the text” that is a goal of legal instruction. The significance of TEST_REVISION_SUGGESTED prompted us to examine the student help behavior more closely. As you will recall this characteristic is activated when a student has marked up the target region, completed collaborative feedback, but not changed his test. From that we determined that very few of the students modified their test statements in response to this char- acteristic. Thus students who reached this point are not sufficiently differentiated. This led us to conclude that additional effort must be made to motivate student’s help usage, particularly in the later “reflective” phases of work. C4.5: We split the individual datapoints evenly into a 90/10 Test-train split with 45 Training cases (19 at or below the mean and 26 above) and 6 test cases (3 at or below and 3 above). We did not perform an iterative cross-validation as our goal was to induce information from known algorithms, not to validate the algorithms on existing data. C4.5 produces the pruned tree that is shown in Figure 2. This tree successfully classifies 82.2% of the training cases and 100% of the test cases. Interestingly the only graph features employed within it are UNLINKED_TEST and TEST_REVISION_SUGGESTED. In many respects the tree supports the χ2 analysis in highlighting the importance of the tran- script linking, particularly for test nodes. Students who link their nodes to the transcripts do well while those who do not are split between students who receive a TEST_REVISION_SUGGESTED and are above the mean and those who are not. Thus students who perform well in other respects by highlighting the key transcript region, summarizing it, and partially completing collaborative filtering have been able to avoid linking all of their test nodes. GP: For the Genetic Programming experiments we employed the same test/train split over all as with C4.5. On both the Mean classification task the evolutionary algorithm showed early successes. As of generation 93 the system produced the Mean classification tree shown in Figure 3. This tree correctly classified 87% of training cases successfully and 100% of test cases. Subsequent generations showed some improvements with the system achieving 89% correct classification of training instances as of generation 659. However the resulting trees were quite large suggesting a problem of overfitting the data. Introns were already present at generation 93 as shown by the useless appearances of NO_ELEMENTS and ISOLATED_HYPO_DISCUSS and the frequency of such code only increased as the process went on. Note also that both the UNLINKED_TEST and TEST_REVISION_SUGGESTED rules are present in this tree but not UNLINKED_HYPO. 
 Figure 3. GP Mean Decision Tree. 
 In analyzing the tree shown in Figure 3 we will focus on the three classes of poor perform- ing students that it defines. The root node of the tree is DISTINGUISH_WITHOUT_TEXT. This characteristic is active when a student has noted that one node is distinguished from another (irre- spective of node type) without giving a justification. As we noted above distinctions, according to our model, are always motivated by some principled or factual justification with which the student should annotate the arc. As with the C4.5 tree students who exhibit this characteristic alone are rated low unless they also exhibit TEST_REVISION_SUGGESTED. The significance of this characteristics prompted us to examine the student help behavior more closely. Recall that this characteristic is activated when a student has marked up the target region, completed collaborative feedback, but not changed his test. From that we determined that very few of the students modified their test statements in response to this characteristic. Students who exhibit both DISTINGUISH_WITHOUT_TEXT and the FACTS_RELATIONS characteristic are classified as below the mean. This latter characteristic indicates that the stu- dents added arcs relating fact nodes to one another. Again this is a violation of our model. Taken together these characteristics indicate a misunderstanding of the role of facts in the domain model both in terms of how distinctions are drawn using facts and how nodes may be interrelated. The third class is the set of students who do not exhibit DISTINGUISH_WITHOUT_TEXT but do exhibit UNLINKED_TEST and TEST_FACTS_RELATION_SPECIFIC. This latter characteris- tic is active when the student has constructed a specific relation (e.g., “Modified To”) to the facts of the case. This is an example of the system’s providing more novel pedagogical information. While our domain model endorses the use of general relationships between the test and fact nodes, it is clear that some good students, who leave tests unlinked, also choose to use specific relations for test and fact nodes. This may signal a valid alternative to our model that bears further exploration. In this paper we assessed the potential of inspectable machine learning methods to induce useful domain information from student work. Our goal was to demonstrate the potential of these meth- ods to yield useful insights into the quality of student solutions, the tutoring system’s behavior, and the domain itself. The results we describe above have led us to conclude that these methods do hold potential for domain exploration but not without some measure of guidance. Our statistical analysis highlighted three salient graph characteristics one of which demon- strated how the use of the system by well-performing students was at odds with our desires. How- ever apart from that it validated our domain model. The use of C4.5 further confirmed the above results and helped to validate some of our domain assumptions but otherwise did not yield much in the way of new information. GP by contrast yielded a set of classification trees one of which we presented here. Examination of this tree yielded useful information both about student miscon- ceptions and student divergence from our domain model. This information has led us to consider alterations to the advice system and a reconsideration of some aspects of our domain model. These results lead us to conclude that the use of GP to induce “inspectable” classifiers is a fruitful method of data extraction both for behavioral and pedagogical information. We believe that this process is especially useful in ill-defined domains where the relationship among individually detectable solution characteristics is not clear and the means for assessing them, open for debate. In cases such as these the use of inspectable post-hoc classification has been shown to reveal useful insights. We plan to expand upon this work by moving from the present high-level graph classification into the induction of both lower level graph characteristics and student classifiers that track per- formance over the course of the study, again with the goal of identifying useful pedagogical and performance information. At the same time we plan to combine these automatic insights with ex- pert human grading. This summer we will engage the services of law school instructors to grade the student graphs. We will then use this data to compare our assessment of good and poor stu- dents with theirs and make use of their data to train further classifiers. This will enable us to check the value of our present grading mechanism and to provide expert-level analysis to augment our existing classifications.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Argument Graph Classification via Genetic Programming and C4.5</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/collin-lynch"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/collin-lynch"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/kevin-d-ashley"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/kevin-d-ashley"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/niels-pinkwart"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/niels-pinkwart"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/vincent-aleven"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/vincent-aleven"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/214/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/collin-lynch"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/kevin-d-ashley"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/niels-pinkwart"/>
		<rdf:_4 rdf:resource="http://data.linkededucation.org/resource/lak/person/vincent-aleven"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/215">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Argument Mining Using Highly Structured Argument Repertoire</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/215/authorlist"/>
		<swrc:abstract>Argumentation theory is considered an interdisciplinary research area. Its tech- niques and results have found a wide range of applications in both theoretical and practical branches of artificial intelligence, education, and computer science. Most of the work done in argumentation use the on-line textual data (i.e. unstructured or semi-structured) which is intractable to be processed. This paper reports a novel approach to build a Relational Argu- ment DataBase (RADB) with managing tools for argument mining, the design of the RADB depends on the Argumentation Interchange Format Ontology(AIF) using ”Walton Theory”. The proposed structure aims to: (i) summon and provide a myriad of arguments at the user’s fingertips, (ii) retrieve the most relevant results to the subject of search, (iii) support the fast interaction between the different mining techniques and the existing arguments, and (iv) facilitate the interoperability among various agents/humans.</swrc:abstract>
		<led:body><![CDATA[ 1. Argument network representation for different Walton schemes. 
 The premises block gathers the different premises types (majors, minors). The critical question’s conclusion block assembles the result of the different critical questions together with the results of the different presumption questions that are to be exposed in a specific scheme. Considering the canonical representation for the schemes, we pose some sentiments about the relational database baselines. In our design, we gather the different scheme information into three basic files (tables): Scheme TBL, Scheme Struct TBL and Data TBL. First, the scheme kind is formulated in Scheme TBL Fig. 2, in which rows act as records of data for different schemes, and columns as features (attributes) of records. The Scheme TBL creates an identification number(ID) for each scheme name (Scheme Name), where this ID plays a role of primary key for the table and foreign key in the others. In addition, any ID attribute will stand for the same function in all files. Scheme Struct TBL assembles the different information associated with different schemes. Such that, Scheme Id stands for the foreign key of Scheme TBL, indicating the scheme concerned. The Content field contains the details of the associated information (premises, conclusion,... etc.). The Type field has four values, P for premises, C for conclusion, CQ for critical question and CC for critical argument conclusion. For instance, the expert opinion scheme[4] can be represented as shown in Scheme Struct TBL of Fig. 2. 
 Fig. 2. The main structure of different schemes. 
 The Data TBL table contains all users’ transactions. This table gathers all users’ analysis for dif- ferent arguments. The table consists of : the Stru Id that serves as foreign key for the Scheme Struct TBL’s ID, and refers to a specific part of the scheme details, the Content attribute contains a por- tion of the analyzed text that fulfills the referred fixed scheme part, the Type attribute, which holds three values only, 1 for the supported node, 0 for rebuttal node, -1 for undetermined value that denotes neither supported nor rebuttal node. Since we consider any argument network as a kind of directed rooted tree, the Child Of attribute points to the parent of each node, whereas the root node has no parents (0 refers to no parent). The level attribute refers to the level of each node in the tree, such that the value 0 indicates the root node. Finally, the argumentation no attribute contains the number of the analyzed argument context. For example, the following context below from Araucaria2 repository database[2, 3, 12] is reana- lyzed based on expert opinion scheme as shown in Fig.3 and Fig.4. ”Eight monthold Kyle Mutch’s tragic death was not an accident and he suffered injuries consistent with a punch or a kick, a court heard yesterday. The baby, whose stepfather denies murder, was examined by pathologist Dr James Grieve shortly after his death. Dr. Grieve told the High Court at For far the youngest was covered in bruises and had suffered a crushed intestine as well as severe internal bleeding. When asked by Advocate Depute Mark Stewart, prosecuting, if the bruises could have been caused by an accident, he said ”No. Not in a child that is not walking, not toddling and has not been in a motor car.” Dr. Grieve said the injuries had happened ”pretty quickly” and would be ”difficult for an infant to cope with”. The lecturer in forensic medicines at Aberdeen University told the jury that the bruises could have been caused by a single blow from a blunt instrument, like a closed hand. Death, not accident, court told, ”Evening Telegraph”, Monday, September 13, 2004, p.11” Regarding to the canonical representation for Waltons schemes presented in Fig.1, the given context could be analyzed as shown in Fig.3 based on expert opinion scheme [1]. Moreover, this analysis will be devolved through transaction records, as shown in Fig.4, to the structured data base (RADB) revealing the different parties of the analysis. 
 2.2 Framework Overview.
 Yun Chi et al. [13] surveyed the current algorithms used for mining frequent subtrees from databases. They focused on two main components of these algorithms, the candidate generation step and the support counting step. They revealed that there is no single best tree mining algorithm. Some algo- rithms offer a better time efficiency, while others require less memory. So every time we manipulate the proposed RADB we will consider the time and memory consuming. 
 {2} http:// araucaria.computing.dundee.ac.uk/.
 Fig. 3. The analysis diagram of the above context based on expert opinion scheme. 
 Fig. 4. The transaction records of the above analysis. 
 We draw a preliminary vision for retrieving and mining the RADB, using a framework with ITS component incorporated. The framework as depicted in Fig.5 consists of three main components: the parser module, the mining classifier agent, and the ITS. The parser module receives a statement S from the intended users such as students or agents. the statement is divided by the parser into tokens, then the number of tokens is reduced. Finally the final crucial set of words { I1, I2,..., In } is sent to the classifier agent. The tokens are reduced if they belong to a look up table containing the set of all unnecessary words like{a, an, the,...,etc }, otherwise it is added to the set of tokens to be sent to the classifier agent. The importance of the parser module lies in reducing the set of tokens which in turn will reduce the number of iterations done by the classifier agent, and improve the complexity of the used mining algorithms. The classifier agent classifies the retrieved contexts depending on the students specification. The agent can classify the retrieved arguments by priority, polarity, scheme name, premises (with/against), and by conclusion. 
 Fig. 5. Framework outline.
 The priority aims to show the retrieved contexts organized by the maximum support number based on the classification mining technique AprioriTid [10, 5]. Polarity classifies the retrieved arguments in to two classes, support class and against class, using the text mining techniques. Scheme name retrieves the desired contexts depending on a specific scheme name deter- mined by the student. Premises (with/against) retrieves arguments by searching only in the different premises, and conclusion retrieves and classifies the arguments by searching only in the different conclusions. The classifier agent receives the set of crucial words { I1,I2, ..., In } from the parser module and the search type from the student, then retrieves and classifies the documents that are relevant to the student’s search statement from the RADB using the multi-term text phrases ap- proach[5] such that T={ T1,T2,...,Tm } is the collection of raw documents, I={ I1,I2,,In } is a set of words appearing in T. T’={ T’1, T’2,..., T’m } is the set of documents, where T’i contains a set of multi-term phrases I’={ I’1, I’2,..., I’n }, I’i= Ij [1,2,..,k-j], and Ii can appear in I’i repeatedly. The importance of this classifier agent lays in manging the different mining techniques in order to: (i) direct the search towards hypotheses that are more relevant to the user’s needs, (ii) add flexibility to the retrieving process to suit the users aims (iii) offer a myriad of arguments at users fingertips. After the classifier agent exposed the pertinent contexts to the student, the student picks up one context among them. The student preference then delegates to the ITS program. The program exposes the corresponding context, and gives the student the ability to analyze the selected argu- ment based on a specific chosen scheme. Finally the program negotiates with the student about the way of analysis through mining techniques to (i) provide constrains that guide the argument analysis process based on scheme structure and pre-existing arguments, (ii) refine the user’s underlying classi- fication, (iii) provide an analysis background to the different users, (iv) deepen the understanding of negotiation, decision making, (v) develop critical and intellectual thinking of students, and improve the analysis ability. 
 2.3 Illustrative Example.
 Suppose the student wants to know anything about Iraq war, so he/she come up with a statement ”the destructive war in Iraq”. First the parser module will divide the statement into tokens {the, destructive, war, in, Iraq}, such that I1=the, I2=destructive, I3=war, I4=in, I5=Iraq, then access to the data base through the ODBC connection to compare each token with the lookup table entities and reduce the number of tokens, after checking the lookup table the tokens will be I1=destructive, I2=war, I3=Iraq. So the output will be the item sets {destructive, war, Iraq}. Now the classifier should find the set of raw documents T= {T1,T2,...,Tn }. Assume the conclusion is the search criteria, so the classifier will use the mining AprioriTid algorithm [10, 5] to make all the possible combination of the item sets and classify the result depending on the support number for each combination. Firstly, the algorithm will calculate the support number for each single token, and select the tokens that have support number greater than minsup, that is a number specified by the student, however in our case we will take the minsup=1 so any token appears at least once will be considered. Since we assume that the student choose to search by conclusion then the support number for each token can be counted by the number of transactions resulted from the following select statements. 
 The output of this step will be the set of ordered pairs L1 = {(destructive, 5), (war, 10), (Iraq, 20)}, where the ordered pair is of the form (the token, the support number), and the set A1={argument 801, argument 509,...} which contains the non repetitive arguments (argument no) that contains these tokens. Secondly, the algorithm consequently builds the super set Ck = apriori gen(Lk−1) for all possible combinations of the tokens. Fig.6. Shows the first iteration for C2=apriori gen(L1). 
 Fig. 6. The super set C2 of the singleton token set L1. 
 Then the support number for each combination is checked through the set A1. Suppose that the support number for the item set ”War Iraq” is 0, which is less than the minsup=1, so this item set is neglected. The output of this iteration will be L2= {(Destructive war, 3), (Destructive Iraq, 5)}, and the set A2={argument 509,...}. Finally, the last iteration of our example will out put the set L3={(Destructive war Iraq, 1)} and the set of arguments A3={ argument 509}. Suppose that A3 had more than one argument no, we add function to the algorithm to check the counter argument of each argument no and order the arguments depending on the possessed counter arguments, such that the argument that contains more cons is the weakest. Therefore, the conclusions corresponding to the retrieved arguments are organized, such that the argument1 is highly relevant to the issue of search rather than argumentn as shown in Fig. 7. When the student pickup one of the classified output conclusions the ITS will access to the database to retrieve the corresponding context and then the context is exposed to the student giving him/her the ability to analyze. Furthermore, the ITS will negotiate with the student partially (step by step hints) or totally (compare the student whole analysis with the original one retrieved from the repository) as discussed in the next section, in order to improve his/her analysis skill. 
 Fig. 7. The argument retrieval output. 
 3 Motivation.
 In this paper, firstly we introduce a novel approach to retrieve the information using mining tech- niques based on RADB, which is a highly structured repertoire gathers the argument dataset, such that all needed information is encoded in an appropriate form. This structure facilitates fast in- teraction, and enjoys general applicability since it does not require a specialized knowledge. The idea is to mine the pre-existing arguments in order to (i) direct the search towards hypotheses that are more relevant to the users needs, even with more than one word in the search statement, (ii) add flexibility to the retrieving process to suit the users aims (iii) offer a myriad of arguments at users fingertips (iv) provide an analysis background to the different users. Secondly, we assemble the different retrieving techniques in a Classifier agent to be merged with an ITS. The agent based in- telligent tutoring system aims to (i) provide constrains to guide the argument analysis process based on scheme structure and pre-existing arguments, (ii) refine the users’ underlying classification, (iii) deepen the understanding of negotiation, decision making, develop critical and intellectual thinking of students, and improve the analysis ability. I. Rahwan presents the ArgDf system [1, 6], through which users can create, manipulate, and query arguments using different argumentation schemes. Comparing ArgDf system to our approach, both of them sustain creating new arguments based on existing argument schemes. The available argument schemes are listed, enabling the user to choose the scheme to which the argument belongs. Details of the selected argumentation scheme are then retrieved from the repository, and the generic form of the argument is displayed to the user to guide the creation of the premises and conclusion. For example, querying the ArgDF repository to extract the name of the schemes can be done through the following RQL query. In addition, the ArgDf system guides the user during the creation process based on the scheme structure only, the user relies on his efforts and his background to analyze the argument. However, in our approach, the user is not only guided by the scheme structure but also by crucial hints devolved through mining techniques. Accordingly, the creation process is restricted by comparing the contrasting reconstruction of the user’s analysis and the pre-existing one. such restriction helps in refining the user’s underlying classification. In the ArgDf system, searching existing arguments is revealed by specifying text in the premises or the conclusion, as well as the type of relationship between them. Then the user can choose to filter arguments based on a specific scheme. Whereas, in our approach, searching the existing arguments is not only done by specifying text in the premises or the conclusion but also by providing different strategies based on different mining techniques (as explained in subsection 2.2). This method guarantees the retrieval of the most convenient hypotheses relevant to the subject of search. 
 4 Conclusions and Future Work.
 In this paper, we present a novel approach of building a highly structured argument repertoire (RADB) that uses different mining techniques to support argument analysis, retrieval, and re-usage. The paper also introduced an educational framework that utilizes the RABD. The proposed structure aims to: (i) summon and provide a myriad of arguments at the user’s fingertips, (ii) retrieve the most relevant results to the subject of search, (iii) support the fast interaction between the different mining techniques and the existing arguments, and (iv) facilitate the interoperability among various agents/humans. Our attempt enjoys certain advantages when compared to others, especially with respect to the search of pre-existing arguments. The results obtained are very promising, where highly relevant and convenient arguments are obtained, especially when the search statement is in this form: ”the destructive war in Iraq”. Future work mainly concerns with the implementation of the rest of the framework components.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Argument Mining Using Highly Structured Argument Repertoire</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/safia-abbas"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/safia-abbas"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/hajime-sawamura"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/hajime-sawamura"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/215/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/safia-abbas"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/hajime-sawamura"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/216">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Skill Set Profile Clustering Based on Student Capability Vectors Computed From Online Tutoring Data</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/216/authorlist"/>
		<swrc:abstract>In educational research, a fundamental goal is identifying which skills stu- dents have mastered, which skills they have not, and which skills they are in the process of mastering. As the number of examinees, items, and skills increases, the estimation of even simple cognitive diagnosis models becomes difficult. To address this, we introduce a capability matrix showing for each skill the proportion correct on all items tried by each student involving that skill. We apply variations of common clustering methods to this matrix and discuss conditioning on sparse subspaces. We demonstrate the feasibility and scalability of our method on several simulated datasets and illustrate the difficulties inherent in real data using a subset of online mathematics tutor data. We also comment on the interpretability and application of the results for teachers.</swrc:abstract>
		<led:body><![CDATA[ 1. Set the starting cluster centers mg to the corners of the K-dim hyper-cube (2K centers). 2. Create the cluster assignment vector A by assigning each Bi to the closest mg. 3. For all clusters g, if no Bi is assigned to mg, i.e. 4. Alternate between 2) and 3) until the cluster assignment vector A does not change. 
 This flexible k-Means variation allows for empty clusters or fewer clusters than origi- nally requested and removes the constraint that there be one cluster per skill set profile. 
 3.2 Model-based Clustering.
 Model-based clustering [3,9] is a parametric statistical approach that assumes: the data X = {x1, x2, ..., xn}, xi ∈ <K are an independently and identically distributed sample from some unknown population density p(x); each population group g is represented by a (often Gaussian) density pg(x); and p(x) is a weighted mixture of these density components, i.e. 
 FORMULA_3.
 where ∑ pig = 1, 0 < pig ≤ 1 for g = 1, 2, ...,G, and θg = (µg,Σg) for Gaussian compo- nents. The method finds estimates for the number of clusters G as well as their centers and variances (µg,Σg) that maximize a chosen information criterion. Essentially, it finds the weighted combination of Gaussian densities that “best fits” the data. While it may require the groups to have Gaussian densities, it is very flexible (unlike k-Means) on the shape, volume, and orientation of the densities. This freedom allows model-based clustering to fit a wide array of student groups of different shapes and sizes. Both methods return a set of cluster centers and variances and an assignment vector mapping each Bi to a cluster. They do not, however, automatically assign a natural skill set profile (hyper-cube corner) to each cluster. Ideally, we have 2K clusters, each closest to a unique corner. In reality, some corners will have no students nearby. The k-Means algo- rithm has been altered to allow for this option; model-based clustering estimates centers in high-frequency areas and should not put a center near an empty corner. We do not advocate a one-to-one mapping of clusters to corners; clusters near areas of uncertainty in the hyper- cube should be identified as such. If a cluster of students is centered at {0.12, 0.88, 0.55}, they should be labeled as likely not having skill 1, likely having skill 2, and uncertain on skill 3. This conservative classification will help teachers avoid misclassifying students. To classify a new student, we calculate the capability vector and assign to the nearest cluster. 
 3.3 Subspace Clustering.
 If few items require skill k, Bik only take a few unique values. For example, if three items need skill k, Bik ∈ {0, 13 , 12 , 23 , 1}. Clustering on the K-dimensional hyper-cube may not perform well as students will map to only a few (K-1)-dimensional hyper-cubes. Instead we recommend conditioning on the coarsely gridded dimension (skill k, where students are already well-separated) and clustering on the (K-1)-dimensional conditional subspaces (repeating as needed). 
 4 Examples.
 For our simulated data, we use the deterministic inputs, noisy “and” gate model (DINA; [8]) a conjunctive cognitive diagnosis model. The DINA model item response form is 
 FORMULA_4.
 where αik = I{Student i has skill k} indicates if student i possesses skill indicates if student i has all skills needed for item j, for item j, s j = P(Yi j = 0 | ηi j = 1) is the slip parameter and g j = P(Yi j = 1 | ηi j = 0) is the guess parameter. If a student is missing any of the required skills, the probability that they will answer an item correctly drops due to the conjunctive assumption. When simulating data from the DINA model, we first fix skill difficulties and inter-skill correlation and generate true skill set profiles Ci for each student. If skills are of equal diffi- culty with little or no inter-skill correlation, students are evenly spread among the 2K natural skill set profiles. If skill difficulty varies, skill set profiles with only “easy” skills will have more students than those including the “hard” skills. High inter-skill correlation pulls stu- dents toward the no mastered skills and all mastered skills corners (Ci = {0}, {1}). Next we draw slip and guess parameters from a random uniform distribution (s j ∼Unif(0,0.30); g j ∼ Unif(0,0.15)). Given profiles and slip/guess parameters, we generate the student response matrix Y . Prior to clustering, we remove 10% of the responses completely at random. For these examples we know the true underlying skill set profiles Ci and can calculate their agreement with the clustering partitions using the Adjusted Rand Index (ARI; [7]), a common measure of agreement between two partitions. The expected value of the ARI is zero and the maximum value is one, with larger values indicating better agreement. 
 4.1 Simulated DINA Data.
 In Example 1, we generated response data for N = 250 students for J = 30 items, K = 2 skills. The Q-matrix contains only single skill items, 15 items per skill. The skills are equal difficulty with an inter-skill correlation of 0.25. Figure 2(a) shows the results. Clusters are number/color coded with triangle centers. We asked k-Means for 2K = 4 clusters; all students were clustered correctly (ARI = 1). Model-based clustering chooses five clusters (ARI = 0.926). The “extra” high frequency area near {1, 1} results from the close proximity or identical locations of the 19 students in Cluster 5. Teachers could interpret these results as two groups with similar skill 2 mastery but different skill 1 mastery. 
 Figure 2: Simulated data examples for K = 2, 3 skills, single skill and multiple skill items, 10% missing responses. Clusters are color/number coded, centers denoted by triangles. 
 In Example 2, we simulated as in Example 1 but increased the number of skills to K = 3. Again the Q-matrix was designed to only include single skill items, 10 items per skill. Here, both k-Means and model-based clustering recovered the true skill set profiles (ARI=1). Figure 2(b) shows the clustering results for both methods. For Example 3, we simulated as in Example 2 but used a balanced design Q-matrix including multiple skill items where each skill appeared by itself in four items, in four double skill items with each of the other two skills, and in three triple skill items. Results are in Figure 2(c). Both methods find clusters of students showing mastery of all three skills in the back upper right corner near the {1, 1, 1} skill set profile. However, the remaining students are pulled toward the front lower left corner (the {0, 0, 0} skill set profile), a direct result of the combination skill items. If a student incorrectly answers a multiple skill item, all skills required by that item are penalized (not just the unmastered skills). We have seen that a balanced design negates the penalty effect (ARI = 0.837, 0.829); the remaining clusters are effectively scaled and maintain their separation. The datasets presented are missing 10% of the responses; we compare their results to those for only students not missing any responses. In educational data mining, we com- monly use case-wise deletion of students to generate a complete dataset. This method is impractical here as it leaves us with 11, 10, and 15 students respectively. Instead we use the original generated response matrices prior to removing responses at random. The B- matrices are re-calculated and clustered. Only Example 3 had different ARIs. When using the complete data set, the ARI for k-Means increases from 0.837 to 0.880, for model-based clustering, 0.829 to 0.946. These jumps are expected as the lack of missingness increases the number of items seen (and the fineness of the grid) and decreases the relative effect of the penalty associated with incorrectly answering a multiple skill item; the resulting clusters are less removed from the corners. A higher dimensional example with N = 1000 students, J = 80 items, and K = 20 skills was also explored. In this case there were 425 unique latent classes used to generate the data. Model-based clustering found 424 clusters and had an ARI of 0.99. Giving k-means 220 starting centers is unreasonable; we’re currently developing methods to systematically and appropriately choose a smaller set of starting centers. 
 4.2 Assistment Data.
 Figure 3: Assistment System example of conditional k-Means clustering on the B-matrix; clusters are color/number coded. The table shows the cluster centers. 
 For our real data, we use a subset of 26 items requiring three skills (for easy visual- ization) from the Assistment System online mathematics tutor [5]. The Q-matrix is unbal- anced; Skill 1 (Evaluating Functions) appears in eight items, Skill 2 (Multiplication) in 20 items, and Skill 3 (Unit Conversion) in two items. Overall, 551 students answered at least one item, however there is a large amount of missing data (57%). Recall, if student i did not see any items requiring skill k, Bik = 0.5. Since Unit Conversion appears in only two items, BiUC ∈ {0, 12 , 1}. The three corresponding planes are visible in Figure 3. We condition the unique BiUC values and apply our k-Means variation (Section 3.1) to each plane. The final cluster centers are in the table in Figure 3. k-Means is preferable here because the limited number of unique values in the Evaluate Functions skill dimension leads to instability in the more flexible model-based clustering models. The planes corresponding to BiUC = 0 and 0.5 each have four clusters; the plane for BiUC = 1 has two. There are natural interpre- tations for each of the clusters. For example, a teacher might interpret Cluster 9 as students who know Unit Conversion and Multiplication, but are uncertain on Evaluating Functions. Cluster 10 could be interpreted as the students who have mastered all three skills. 
 5 Conclusions and Future Work.
 We derived a capability matrix to summarize student skill mastery for use in clustering algorithms. In simulated datasets, the method performed well (i.e., high values of ARI). In the Assistments data the method responded well to missing data, allowing us to draw conclusions for the skills that students have seen and distinguish the skills that require more assessment. Early results suggest that the Q-matrix design plays a large role in the location and interpretation of the clusters. Finally, we visually presented examples with K = 2 and K = 3 skills and showed the method scales to a larger number of skills. Currently, we are comparing our results to other student skill knowledge estimates. For example, using WinBUGS [11], the DINA model estimates produce essentially the same profile clusters for the simulated datasets; however, it runs around 700 times more slowly.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Skill Set Profile Clustering Based on Student Capability Vectors Computed From Online Tutoring Data</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/elizabeth-ayers"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/elizabeth-ayers"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/rebecca-nugent"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/rebecca-nugent"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/nema-dean"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/nema-dean"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/216/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/elizabeth-ayers"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/rebecca-nugent"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/nema-dean"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/217">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>A Preliminary Analysis of the Logged Questions that Students Ask in Introductory Computer Science</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/217/authorlist"/>
		<swrc:abstract>Asking questions is widely believed to contribute to student learning, but little is known about the questions that students ask or how to exploit them in tutorial interventions to help students learn.  This paper presents a preliminary analysis of student questions from an introductory computer science course, logged automatically when students requested help during open lab consulting hours.  The data set consists of one hundred and forty two questions that introductory computer science students asked while working on four weekly programming assignments.  The initial data suggest that student questions can be repetitive in nature and different students ask different kinds of questions.  The paper concludes by suggesting that an analysis technique that is more sophisticated than cosine similarity applied to raw text with stop words removed will be necessary to classify student initiated questions.</swrc:abstract>
		<led:body><![CDATA[ 1. Virtual Teaching Assistant Interfaces for Student(a) and TA(b). 
 One of the long term goals of the Virtual Teaching Assistant project is to provide automated answers to some of questions that students ask.  This paper examines the data logged during one month of usage.  The paper presents a preliminary analysis of finding similar questions, and it concludes that applying cosine similarity to raw text with the stop words removed is insufficient for finding similar previous questions that could be exploited in a tutorial intervention. 
 2 Prior Work.
 Because novices are notoriously inept at articulating their reasoning, many intelligent tutoring systems use one of two approaches to dealing with the questions that students ask.  Several tutoring systems have completely bypassed the problem of poorly articulated student language by restricting the size of the information space that the system covers (e.g. single physics problem[3], a sentence to be read aloud[8], or algebra symbolization[5]), dividing each problem into a set of skills, and creating interventions or help messages for each skill.  Alternatively, some systems have focused specifically on helping students to articulate their reasoning (e.g. providing explanations for steps in a geometry problem[2], describing general physics principles in natural language[4], and listing required hardware for a computer task[4]) because generating natural language may help students develop deep learning. However, these systems are generally trying to elicit specific pieces of natural language from the student instead of providing answers to student questions. Research on producing automated responses to student generated questions is remarkably sparse throughout the literature. 
 3 Study Design.
 3.1 Participants.
 The study participants were students from Introduction to Computer Science 1 (CS1410) at the University of Utah.   Most students in Computer Science 1 are age 18-22, but there are also a few non-traditional students, such as a student from a local high school or adults who have returned to school later in life.  Computer Science 1 is the first required computer science course for computer science majors, and it is a gatekeeper course with a strong emphasis on the Java programming language as well as the traditionally long hours for novice programmers and the typically high dropout, fail, and withdrawal rates. The majority of students who take Computer Science 1 hope to major in computer science or a related field, but they must pass that class along with three others with sufficiently high grades to attain official status as a computer science major.  Although approximately seventy eight students were active in the course during the study, only twenty four of them asked questions using the Virtual Teaching Assistant software during the month long study period. 
 3.2 Data Cleansing.
 When the data logging software was designed, every effort was made to facilitate rapid data analysis.  The long term goal is to complete the analysis for a question in real time and exploit it for an instant tutorial intervention.  However, even though the data set was carefully designed, some cleansing was necessary.  For example, some students used several computers away from the lab, and their logins needed to be recoded for consistency.  In a few cases, the only way to obtain their login was to look in the comments in the source code.  Some students asked the same question twice because of a glitch in the software that caused a delay between question submission and system acknowledgement; the duplicate questions were removed from the dataset, but the original questions were left in the dataset.  If the human TA did not provide an adequate answer category for a student question, and a category could not be generated using the student’s natural language or the status of the source code, then the question was excluded. 
 4 Similarity Analyses.
 To calculate the similarity of a new question to a previous questions, the natural language from the student questions is extracted and represented in vector form where each row of the vector corresponds to a particular word, and the value of that vector element is the number of times that word appears in the student’s question.  The vector representation excluded stop words from this list[1]; stop words are words such as “the”, “a”, “I”, “you”, and other common words.  A vector similarity measurement calculates the similarity of a pair of questions on a scale of 0 to 1.  In these measurements, 0 means that the pair has no common words, and 1 means that the questions are identical.  The experiments described below utilize cosine similarity[7]. As a gold standard, a question is similar to a previous question if it has the same answer category.  Table 1 provides an illustrative data set.  To conserve space, questions and answer categories are referred to by number; in the actual analysis, the original natural language is used.  As described in the introduction, when using the Virtual TA system, the human TAs must assign an answer category to each student question that they answer.  A previous question with the same answer category is called a target question. In Table 2, “target question(s)” lists previous questions with the same answer category. Additionally, for each question, the similarity between that question and each previous question is calculated.  The previous question that has the highest similarity score when paired with the current question has the “max similarity score”, and it is considered the “most similar previous question”.  If multiple previous questions have the same highest similarity score, the most recent question is considered the “most similar previous question”. 
 Table 1. Question Similarity Scores.
 The original plan was to simply use the answer categories as recorded by the human TAs. Unfortunately, not all of the answer categories that the TAs chose are particularly descriptive of the student’s question.  For example, the human TAs often used the category “Answered in Person”, as opposed to a category that provided a meaningful description of the student’s question.  Excluding such poorly described answer category data results in a smaller dataset as shown in the “Excluding recoded data” and “Excluding both” columns of Table 2.  A second alternative is to recode the data; resulting in a larger dataset as shown in the “Everything” and “Excluding compiler errors” columns of Table 
 2.   This disaggregation shows how much of each type of data was recoded. 
 An additional disaggregation considers the questions associated with source code that doesn’t compile.  Because the compiler can indicate without human intervention whether or not the source code compiles, the kinds of automated data collection and analyses that are possible differ depending on whether or not the source code compiles.  For example, if the source code does not compile, the compiler output may be exploited for question classification.  If the source code does compile, then comparison algorithms can exploit the output of parse tree analysis or runtime analysis techniques such as program slicing and comparison[6]. 
 Table 2. Data set with and without exclusions. 
 In all four conditions shown in Table 2, the algorithm found similar previous questions for at least a few questions, but only a very small percentage of the time. Similar previous questions could be exploited in a tutorial intervention if a similarity score threshold separates those questions with a target question from those questions without a target question.  Figure 2 is an attempt to find such a threshold when excluding compiler errors. The independent variable is the maximum similarity score for a question, and the dependent variable 0 if there was not a similar previous question, 1 if there was a most similar question and it was found by the algorithm, and 0.5 if there was a similar previous question, but it was not found by the algorithm.   If Figure 2 were a step function, then the threshold would be the location of the step.  Unfortunately, this data does not seem to have such a threshold.  Consequently, applying cosine similarity to raw text with stop words removed is insufficient to classify many student questions, and maximum similarity score with natural language is insufficient to identify previous questions to exploit in an automated tutoring intervention. 
 Figure 2. Thresholding. 
 4 Conclusions.
 4.1 Limitations.
 This work has all of the standard limitations of work based on a single intelligent tutoring system deployed in a single class; the results hold for this population of students using this tutoring system in the setting described in the paper.  Additionally, the numbers are small because it is a only month long study.  The paper does not show p-values for any of the claims, nor does it calculate the correlations of variables.  A first attempt at correlating the number of questions with average assignment score or midterm, not presented in this paper, suggests that this is a difficult problem for this domain because several of the students who ask questions early in the semester decide to drop, withdraw, or fail before the first midterm.  How to properly deal with such students is an interesting, open research question for educational data mining. 
 4.2 Contributions.
 This is the first paper to analyze data from the Spring 2008 version of the Virtual Teaching Assistant, a tool that logs the questions that students ask and the answer categories that human TAs use to describe student questions. A set of preliminary analyses suggest that using raw natural language is not sufficient to find previous student questions that can be exploited in an automated tutorial intervention. 
 4.3 Future Work.
 This paper presents a preliminary analysis of a month-long study of student questions using only the natural language of the questions that students asked. This analysis may be refined using a more complete task-specific stopword list.  Several words such as “cool”, “awesome”, “thanks”, “need”, “help”, and “question” that are not normally considered stopwords behave like stop words for this task.  Treating them like stopwords may improve accuracy.  Additionally, a more vigorous recoding of answer categories and/or a clearer set of guidelines for creating answer may improve question classification accuracy.  Even in the recoded categories, there are several redundant answer categories such as “Moving the pyramid”, “sizing the pyramid”, and “Pyramid location” that should probably all be recoded to the same general category; another example is the redundant answer categories of “mortgage equation” and “calculating mortgage”. Previous work suggests that the majority of questions asked by students about a programming assignment are often clustered around one or two topics[9], but these topics are too vague to be useful for question classification; creating a question classification scheme that is simple enough for introductory computer science TAs to use is an area that merits further research. The next step for this research is to cleanse the data more thoroughly and scale up this study to a semester long study, and include other forms of data such as student source code and educational context, e.g. the assignment the student is working on, as part of the classification algorithm.  The plan is to compare the plain natural language version with the extended version that uses source code and educational context, and hopefully show that using the extra data results in a statistically significant improvement in question classification.  Also, with improved question classification, it may be possible to exploit the question classification in a tutorial intervention to help students learn more.  Showing that previous questions, mined in real time from the knowledge base of the system, can be used in a tutorial intervention to help students learn is the long term goal of this research project. In addition to extending the VTA project, future work is needed to clarify the differences in student and tutor initiated open ended dialog.  Previous work has shown that cosine similarity was as effective as an untrained human tutor in a tutor initiated open ended dialog[10], but in this scenario, the student can exploit both the natural language in the tutor-initiated question as well as text within a window from which the question was drawn.  Consider the example given in that paper: The tutor-initiated question is  “How is an operating system like a communications coordinator?”, a student response is “It communicates with the peripherals”, and a model answer is “A computer's operating system includes programs that take care of the details of communication with peripherals.” (emphasis added)  As the emphasis added shows, many terms that are used in a tutor-initiated question also tend to appear in both the student answer and the model answer.  The topic of this question was probably drawn from a specific segment of a written text, and with high probability the student would have extracted their answers from a segment of the text with the same information.  Student initiated questions do not have the added advantage of the language from the tutor-prompt, and it is not clear whether or not cosine-similarity can be exploited to help answer them.  A more detailed comparison of several dialogues from both student-initiated and tutor-initiated systems may shed light on additional differences in dialogues based on who initiates them. 
 Acknowledgements.
 Thanks to Hal Daume, Joe Zachary, Joseph Beck, Peter Jensen and others who have provided helpful comments and feedback on various versions of this work.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>A Preliminary Analysis of the Logged Questions that Students Ask in Introductory Computer Science</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/cecily-heiner"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/cecily-heiner"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/217/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/cecily-heiner"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/218">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Machine Classification of Peer Comments in Physics</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/218/authorlist"/>
		<swrc:abstract>As part of an ongoing project where SWoRD, a Web-based reciprocal peer review system, is used to support disciplinary writing, this study reports machine learning classifications of student comments on peer writing collected in the SWoRD system. The student comments on technical lab reports were first manually decomposed and coded as praise, criticism, problem detection, solution suggestion, summary, or off-task. Then TagHelper 2.0 was used to classify the codes, using three frequently used algorithms: Naïve Bayes, Support Vector Machine, and a Decision Tree. It was found that Support Vector machine performed best in terms of Cohen’s Kappa.</swrc:abstract>
		<led:body><![CDATA[ 1. Performance of Classification Approaches. 
 Table 1 shows the experimental results. With the training set, the highest performance measured as Cohen’s Kappa was achieved with SVM. Although the performances of the models were a little decreased with the test dataset, the highest Cohen’s Kappa was still found with SVM. This result is consistent with other text classification studies. To identify the source of errors or performance reduction, we analyzed the confusion matrices provided by TagHelper. All the three approaches revealed consistent problems: Praise comments were correctly categorized (80% correct vs. 20% incorrect for example in SVM) while problem detection comments tended to be confused with solution suggestion. Interestingly, problem detection was categorized as solution suggestion more than solution suggestion was categorized as problem detection. 
 5 Conclusion.
 This study has presented machine learning technologies applied for classifying peer comments in writing. As demonstrated with TagHelper, the machine learning technologies were found to be useful to categorize student comments on peer writing. Especially SVM achieved a noteworthy performance. Another important result was that the machine learning technologies, especially SVM, was good at categorizing tonal information into praise vs. non-praise. Finally, it should be noted that a hidden benefit of the text classification technologies seems to help researchers develop coding schemes precisely. Obviously, one of the benefits in using text classification technologies is automatically categorizing a large corpus of peer comments. This may be important in reciprocal peer reviewing of writing. Along with the class size, students tend to exchange an exponential amount of comments. Thus, automatic corpus coding technologies may be greatly helpful to help instructors to monitor reciprocal peer reviewing of writing in their classes. In addition, the current findings have been used to develop an intervention for student reviewers. Thus, based on the helpful comment model developed with TagHelper, student comments can be classified online before they are passed to their authors in order to help students generate constructive comments.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Machine Classification of Peer Comments in Physics</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/kwangsu-cho"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/kwangsu-cho"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/218/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/kwangsu-cho"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/219">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Using Item-type Performance Covariance to Improve the Skill Model of an Existing Tutor</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/219/authorlist"/>
		<swrc:abstract>Using data from an existing pre-algebra computer-based tutor, we analyzed the covariance of item-types with the goal of describing a more effective way to assign skill labels to item-types. Analyzing covariance is important because it allows us to place the skills in a related network in which we can identify the role each skill plays in learning the overall domain. This placement allows more effective and automatic assignment of skills to item- types. To analyze covariance we used POKS (partial order knowledge structures) to analyze item-type outcome relationships and Pearson correlation to capture item-type duration relationships. Hierarchical agglomerative clustering of these item-types was also performed using both outcome and duration covariance patterns. These analyses allowed us to propose improved skill labeling that removes irrelevant item-types, clusters related types, and clarifies the optimal temporal ordering of these clusters during practice.</swrc:abstract>
		<led:body><![CDATA[ 1.) , the probability of getting item-type B right, given A was right , the probability of getting item-type A wrong, given B was wrong cp , the minimum probability that  and ( | )P B A ( | )P A B¬  need to hold ¬ , the error of the POKS tests, which may be set differently for different tests cα A BN ∧  , the number of times that students get A right and B right* A BN ∧¬ , the number of times that students get A right and B wrong* A BN¬ ∧ , the number of times that students get A wrong and B right* A BN¬ ∧¬ , the number of times that students get A wrong and B wrong* ∗ Because the independence of observations assumption of the statistical tests was strained when considering repetitions of the same item-type for the same student, these values were normalized by dividing the each by the total so that they summed to 1. The statistical tests then assumed a number of degrees of freedom equal to the number of subjects in each pairwise comparison. This correction is overly conservative, but provides an unbiased correction for the sometimes great between-subjects variability in the N of repetitions. ( , , )CDFBinomial x n p , the cumulative density function of a binomial distribution of n trials and p success probability The idea of POKS is that if A B⇒A B⇒ perfectly, we would expect , and that the contingency table shows a lack of independence . In reality, due to noise and imperfect , we would expect the above two equalities not to hold exactly. Thus we can setup tests such that if and ( | ) 1P B A = | )B ( | )P A B¬ ¬ =1 ( | )P B A (P A¬ ¬ are above some threshold cp , we can have some confidence of A B⇒ c Therefore, for there to exist a relationship between A and B three tests must succeed. The first two tests check that and are above some threshold( | )P B A ( |P A B¬ ¬ ) p , given the allowed test error cα . The third test verifies whether the conditional probability and are different from and . (P B | )A (P A |¬ ¬ )B ( )P B (P )A¬ Test 1 returns true if ( , ,1 )A B A B A B c cCDFBinomial N N N p α∧¬ ∧ ∧¬+ − < . Test 2 returns true if ( , ,1 )A B A B A B c cCDFBinomial N N N p α∧¬ ¬ ∧¬ ∧¬+ − < . Test 3 returns true if the 2*2 contingency table of A BN ∧ , A BN ∧¬ A BN¬ ∧  and  passes a A BN¬ ∧¬ 2χ test with error rate cα . 
 3.2 Clustering based on conditional log odds.
 As we can see by examining the tests, they rely on the contingency table that is tabulated for each pair-wise item-type comparison. These contingency tables create a covariance structure that “places” each item-type in the POKS graph relative to the other item-types. By reflecting on this we can see that if we want to cluster the items based on the similarity of the required proficiencies, which would imply they require the same skills, we need a distance metric for item-types that a) captures that two items co-vary and b) can cope with the fact that two items may not be equally difficult despite having the very similar covariance structures. Requirement a means we need a distance metric that captures the structure of the contingency tables for item-type X1 as compared to the contingency tables for item-type X2. Requirement b means that this metric probably should not capture the structure of the tables relative to the outcome of performance X1 or X2. Rather, we should describe a distance metric that is computed conditionally for those cases where X1 or X2 is a success or failure. Requirement b is important for the purpose here because the tutor introduces item-types in a fixed order. This fixed order means differences in average performance between item-types may be caused by learning. However, this difference in performance between item-types that represent the same skill should not greatly alter the contingencies given the response is a success or failure. To do this comparison of the covariance structure it helps to consider the data for two item-types (X1 and X2) as being organized into two vectors of contingency tables describing these item-types relationship with all other possible item-types (Yn). If we consider that each contingency table is organized with X frequency results for A item- type and Y frequency results for B item-type, then for each Xn by Yn contingency table we individually computed 2 values: one for when Xn is a success and one for when Xn is a failure. In each of these 2 cases, the log odds of B vs. ~B frequencies is used to capture the strength of the odds B:~B on a continuous scale. Because these log odds do not capture the effect of frequency of A or ~A and only capture the relative frequency of B vs. ~B they are not reactive to learning of A that does not affect the patterns of B vs. ~B, nor are they reactive to difference in the n of observations of the B:~B results. Using this procedure we computed these 2 log odds (one for A and one for ~A) for each contingency table for each vector of contingency tables (X1 or X2). At this point we can describe vectors of log odds values for each column item-type X1 and X2 (getting 2 values conditional on A and ~A for each item Xn by Yn pair) and compute their Pearson correlation to determine the nearness of the two item-types in the knowledge space. To do this clustering we used a simple agglomerative hierarchical clustering to cluster item-types into a new grainsize which implies clustered items share the same performance requirements (skill). This new method shares similarities with correlation clustering methods that have proven useful for graph partitioning [7] and is described further in the next section. 
 3.3 Integrating duration covariance information. 
 Previous work to understand the knowledge space has focused exclusively on how performance success or failure can be used to determine ordered structures. However, besides possessing success data, we also had data on the duration of each item-type performance. This data allowed us to compute pairwise duration correlations (r values) of the item-types that correspond with the POKS tests for each pairwise item-type relationship. While it was perhaps possible to use these correlations in some joint function with the strength of the result of the POKS tests for each pair, at this point we just used these values as an additional filter on which POKS implications we accepted as significant. For this paper we choose to exclude any AÆB pairs where r < 0. More importantly the duration correlation vectors created for each item-type were themselves correlated to produce values that represented the degree of similarity in the duration relationships between item-types. This statistic for each pair of item-types was multiplied by the correlation from the outcome based (log odds vectors) correlation above, and the item-type pair with the highest correlation product is clustered in each step of the simple agglomerative clustering. Clustering continues until the correlation of pairwise correlation vectors is above the clustering coefficient. 
 4 Results.
 Figure 1 shows the POKS graph obtained from this analysis and corresponds to the groupings in Table 1 which provides additional statistics to help interpret the results. The ovals in Figure 1 represent collections (or individual) item-types which were a function of the clustering procedure (also grouped in Table1). Item-type Label indicates the following information (probability correct_Unit name_section number_Skill ID number). The table also provides the average duration and total number of database observations (Rps—repetitions in 1000s) for each item-type. Colors indicate the majority unit membership for the grouped item-types, where LCM – least common multiple unit, GCF – Greatest common factor unit, and FracRep involves a visual and written fraction representation unit. Edge labels provide the average pc value and the duration correlation r. 
 4.1 Irrelevant knowledge components.
 The analysis failed to find any covariance relationship for 17 of the item-types in the 3 units of the tutor. These knowledge components provide an example of how this method can be used to suggest proficiencies that do not covary with the other item-types in the tutor. These so-called irrelevant skills tend to be knowledge components with higher probability correct because in cases with higher probability correct there is less chance to get the examples of not A and not B that are needed to pass the 2nd binomial test. This means that these items are found to be irrelevant because they are so easy that it is less likely to detect how they influence other item-types even where such relationships might exist given a similar problem with higher difficulty. While further analysis would be necessary to determine if these skills were truly irrelevant, the method has provided us with an initial hypothesis about which skills might be removed from the tutor so that time saved to spend on item-types with stronger relationships with the other tutor content. 
 4.2 Redundant knowledge components.
 The clustering of item-types indicates that the pattern of success contingency tables and the pattern of duration correlations were similar for these item-types such that if item- types X and Y are in a cluster it indicates they have similar relationships to the other item-types. By extension we can suppose that this similar place in the covariance structure suggests that performance for these item-types is constrained by the same skill. The fact that this clustering occurs suggests that the human coders used statistically irrelevant features to code the item-types. For example consider the green ovals in Figure 1. The right oval includes a variety of item-types that might be described as understanding the denominator, while the left oval includes item-types that deal with the numerator. 
 Table 1.  Key for graph. 
 Much of this clustering may be necessary because the human coders were instructed to code in as fine a grain as practical. This instruction led to different skills being coded depending on whether  the stimulus was a vertical bar, horizontal bar, circle, square, or number line. In contrast, the clustering method lumped these skills together indicating they may be actually the same proficiency. By splitting these groups into separate skills the human coder delinked these proficiencies relative to the tutor’s automatic scheduling mechanisms. So, for example, if a student does very well on these clustered item-types as they are introduced, it will not result in less practice for the other items that our analysis suggests are in the cluster. Therefore by proposing these clusters we can address learning of the concept more efficiently because we can model transfer between item-types that are controlled by the same underlying proficiencies. Modeling transfer between item- types allows us to know when a particular concept, skill or procedure has been mastered despite the fact that we may not have given a student examples of all the item-types in the cluster. (Also note that sometimes the human coders did repeat the same skill IDs for isomorphic item-types in different sections of the same unit. As we can see in Table 1, our clustering method tended to confirm these human skill labels by clustering these item-types. E.g. skill id 33 (and others) appear twice in the same cluster indicating that the model agrees with human coders decision to label these item-types with the same skill despite the fact that they are in different sections of the same unit.) 
 Figure 1.  Graph structure described in the results section. 
 4.3 Ordering of knowledge components.
 The data comes from a tutor where the units follow a fixed order, and we can use our analysis to question the appropriateness of that order. As discussed in the introduction, we assume that introducing a prerequisite before its post-requisite will result in better learning, because each new idea will have been more adequately prepared by the scaffolding from prerequisite practice. This analysis of the optimal order is more difficult (than analysis of clustering or irrelevant skills) because the tutor repeats item-types, and learning caused by this repetition might explain why a downstream item-type performs better than an earlier item-type. However, while ideally we would include both orders of performance of any pair of item-types in our sample, it still seems safe to infer that very strong prerequisite relationships are not determined mostly by learning effects. Take for instance the position of the two green clusters (fraction concepts) relative to the GCF (greatest common factor unit)_2_31 item-type. Skill ID 31 involves a word problem in which students must produce the other factor for each of 2 products when the first factor has just been supplied by the student, e.g. “You have groups of 4 apples and 6 pears, what is the greatest number of equal sized groups of fruit you can make? (This is an ID 30 skill.) How many apples in each group? (ID 31) How many pears in each group? – (also ID 31)”. This dependence of skill ID 31 in section 2 of the GCF unit on the fraction concept clusters seems plausible since this contextualized problem involves the denominator concept of understanding that wholes can be divided and also the numerator concept that these portions must be composed of a certain count of parts. While this reasoning might normally seemed strained, the support from the graph implies that the FracRep item-types should be practiced before this contextualized GCF section if we want to respect the recommendations of the theory of part-whole training to address the prerequisite skill first. 
 5 Conclusions.
 Future work will focus on integrating this knowledge space analysis with tracking of individual skills such as is currently used in the Bridge to Algebra Tutor. By integrating the knowledge space analysis it appears that we can get a rich perspective on what student actions might deserve to be coded as independent knowledge components. As we discussed in the results, this perspective should improve the performance of the model that tracks repetition of single skills in the tutor because that model can be modified to remove irrelevant skills, made less redundant by clustering skills, and made to better conform to the theory that prerequisites should be trained before later skills. This integration may proceed as shown in work by Cen on the Learning Factors Analysis (LFA) method, which allows improvement in Cognitive Tutor models by searching a space of hypothetical skills for the combination that best fits previously collected data [8]. LFA starts with an initial cognitive model represented as a binary matrix that maps a collection of skills to each item-type (or item) and uses a set of customized item response models to evaluate the model fit produced by any given mapping of skills to item-types for a particular dataset. These binary matrices are based on the tentative judgments of human experts about the effect of the features of the item-types, and LFA can systematically incorporate those features into existing cognitive models by generating and searching for alternative skill labels as allowed for in the matrix. This method has been used by various researchers to evaluate cognitive models in geometry, physics and reading [9, 10] . However, the method still requires a domain expert to propose alternative labeling of skills along which the algorithm searches. The methods proposed in this paper show promising potential to combine the strengths of POKS, item-type clustering and LFA to answer various EDM research questions by allowing us to use POKS and item-type clustering to generate a starting or alternative binary skill matrix for LFA model search. 
 Acknowledgements.
 This research was supported by the U.S. Department of Education (IES-NCSER) #R305B070487 and was also made possible with the assistance and funding of Carnegie Learning Inc., the Pittsburgh Science of Learning Center, DataShop team (NSF-SBE) #0354420 and Ronald Zdrojkowski.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Using Item-type Performance Covariance to Improve the Skill Model of an Existing Tutor</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/p-pavlik-jr"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/p-pavlik-jr"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/hao-cen"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/hao-cen"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/lili-wu"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/lili-wu"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/219/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/p-pavlik-jr"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/hao-cen"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/lili-wu"/>
		<rdf:_4 rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/220">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Computational Infrastructures for School Improvement: How to Move Forward</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/220/authorlist"/>
		<swrc:abstract>The instructional practices common in today's schools reveal a disconnect between instruction and evidence of the effects of that instruction on student learning. In this paper, we propose the creation of computational infrastructures that will help teachers make more informed decisions in their practice. These infrastructures formalize student and teacher routines to facilitate data collection and mining, in order to create actionable information. We then show an instance of such a computational infrastructure and describe its potential for improving instruction.</swrc:abstract>
		<led:body><![CDATA[ 1. In SPACE, project assignments are comprised of ordered sets of task assignments. Each task is subject to a set of assessment criteria, each of which is related to one or more standards of goals (the standards may be State or Federal Standards or local constructs). As students (working alone or in groups) do their work in SPACE, the electronic artifacts they create (the student tasks) are related to the appropriate task template as well as to the authors themselves. Teachers' and students' assessments of work, along with information about (co-)authorship, form a kind of incidental social network, the implications of which we discuss below. The SPACE user interface makes it easy for students to find out what work they need to do and what criteria will be used to assess it. Teachers and students may easily browse the database to see the work of others and to assess that work. Aggregate representations make it simple for teachers to discover which skills need the most instructional focus. At present, these aggregations are of the most simplistic kind, showing, for each standard or assessment criterion, on a by-student, by-assignment, or by-cohort basis, the mean, standard deviation, and trend over time. Presently SPACE employs relatively simple EDM techniques, but as we discuss next, combining the structured data of a system like SPACE with advancements in EDM could dramatically increase the quality and quantity of actionable information available to teachers. 
 Figure 1: SPACE Information Architecture. 
 5  SPACE in Practice.
 SPACE was intended to help teachers enact cycles of formative instruction throughout the course of project-based Inquiry. The following example arose during a recent classroom implementation of SPACE supporting a science fair project: Students are working on different projects and they are at different stages of progress. Students submit work to be assessed by their peers and the teacher. The work can then be revised and resubmitted as needed to complete the task. Managing the student schedules is critical because the science fair represents a hard deadline that must be met. This is a lot of data for a teacher to keep track of, and students (and the teacher) can easily fall behind. Figure 2 shows a visualization of an eighth grade class midway through a project. The stages represent progress towards the science fair presentation. As an example of what these stages represent, stage one is to read some current events and find something technological that excites the student and take some notes on it (e.g. Nike’s new tennis shoe). Stage two is finding a related area of interest (e.g. materials science), and stage three is a project proposal (e.g. comparing springiness of different materials). From there stage ten and eleven are building a data table and collecting data for analysis. Finally, stage 14 and 15 is the write up and presentation of the work. At the time that this figure was generated several students were starting on stage 10. A tremendous amount of data is being generated: the student work (the pieces of work individually, but also chains of revisions), the critiques, rubric-based assessments, and logs of who’s looking at what. This data must be analyzed and presented in a way that is useful to the teacher to become actionable knowledge. Analysis and visualization techniques appraise teachers of students that are waiting for teacher feedback in order to go forward. Other visualizations indicate whether the student is ahead or behind schedule for the science fair. Looking at this visualization the teacher can know immediately which students are falling behind or need attention. The ‘w’ indicates tasks that are waiting for teacher feedback. The large ratio of ‘w’s to non-‘w’s indicates that this specific teacher is significantly behind in offering feedback, and may be overwhelmed. Moreover, the number of pink and red boxes illustrates that students are struggling to turn work in on time; the number of lagging revision required symbols illustrates that many students have been asked to revise but have not, perhaps because they are confused about what the teacher wants them to do. The representation in Figure 2 is a high-level view of the underlying data; it foregrounds punctuality and task status, while backgrounding the actual content of the work and assessments thereof. Teachers can click the column headings, author names, or project titles to see all instances of work on a task (across projects), to see information about the authors (including links to other work), or all work on the project, respectively. This representation is only one of many possible ways of aggregating project work. We have already implemented a skill-based aggregator that shows summary statistics about how students’ work (at the individual student, project, or cohort level) has been assessed, on a skill-by-skill basis, showing teachers what skills students have mastery of and which they need additional support in. Because all interfaces are massively hyperlinked, it is easy for teachers to find concrete examples of relevant work. We imagine the application of a number of information retrieval and data-mining techniques to provide additional depictions of the data. The following section describes several possibilities. 
 6 A Way Forward.
 Singley and Lam describe a number of interesting heuristics that could be helpful to practitioners trying to decide where to direct their attention [14]. Their Classroom Sentinel alerts teachers to conditions, identified through data mining, such as a student’s grade dropping significantly from past assessments, a struggling student performing above average on assessments, the student being within range to increase their letter grade if they do well on the next assignment, or ESL students performing below average on a mathematics assessment. [8] describes a framework for data driven decision-making in schools that “highlights three key components: the process by which raw data becomes useable information, the role of prior knowledge of the decision-maker, and the effect of the data-reporting tool in shaping that process”. We try here to describe, in a more concrete fashion, what infrastructure for such decision-making might be. 
 Figure 2: SPACE Project Progress View (for Cohort). 
 The data structure behind SPACE affords a number of powerful analyses each of which promises to deliver actionable information to teachers and leaders. These analyses range from discovering students' mastery of necessary prior knowledge or related activities, to the leveraging students' social networks, to recommendations of pedagogical options, each of which we now describe. The SPACE database makes it simple for teachers to connect summary statistics to concrete examples of student work. For example, the Illinois state standards for literacy state that middle school students should be able to "identify appropriate resources to solve problems or answer questions through research"; this standard is relevant to any activity where students must collect sources "from the wild" (e.g., the Internet) in order to do their work. Consequently, in a full implementation of SPACE across a school or district, there would be multiple assignments, in a variety of subject areas, that are related to the standard. Through SPACE, a teacher can see not only summary statistics about students' performances related to the standard, but also concrete examples of work. Teachers could search for all examples (in his/her own class or in others') of poor performance in selecting appropriate articles, or find out which students tend to be poor selectors. Having this rich data offers interesting opportunities for increasing the (measurement) validity of teachers' assessment practices. Ideally, there would be a high correlation between teachers' assessment of students' work with respect to some set of standards and other measures of those same students' skill with respect to those same standards. For example, if a recent assessment says that a student has trouble summarizing texts, then we'd expect that teacher assessments of that student's summaries of texts should be similarly low. Divergence between the two measures may indicate a disconnect between teacher understanding of standards and how those standards are measured. Tools like SPACE would allow teachers to take problem areas identified by standardized tests, and then comb through a student’s work to verify similar pre-existing issues. This verification process helps teachers identify and recognize problem areas for present and future students. Consequently, tools like SPACE offer the potential to allow teachers to reflect on their practice as well as make standardized tests formative rather than summative assessments. Education research has found patterns in peer groups and achievement using social network analysis [10,13]. The SPACE database also affords a number of social network analyses. For example, students' critiques of each others' work might represent an edges between students. We can use the amount of subsequent improvement in students' work as the strength of the edges. We can then analyze a network constructed in such a manner over time to understand which student’s feedback influences another student (i.e., students' whose critiques are useful to a broad spectrum of peers). This information could be highly actionable for teachers, supporting decision-making about instruction (e.g., knowing who needs help giving good critiques) and classroom management (e.g., which students to pair up so that they'll be maximally mutually supportive). CISIs have potential beyond what we have described here. Not only could they better support the daily cycles of instruction, but they can also be used to aggregate information at the school level to make decisions. For example they could assist school leaders making decisions about how to allocate discretionary support resources (e.g., teachers’ aids, additional training, supplemental money for extra teacher hours). Similar to how teachers have an increased awareness of students’ learning, leaders could spot school level problems early on (such as the teacher falling behind in the above example) and intervene to be proactive instead of reactive. 
 7 Conclusion.
 Personalizing instruction for students is demanding of teachers. Presently teachers do not have tools that support their daily instructional practice. Computational infrastructures that merge data storage, mining, and presentation can help teachers manage classroom data to make more informed and responsive decisions. Through the use of these sorts of tools, levels of instruction that previously required vast pedagogical content knowledge and heroic effort could now be much more reasonably achieved, with benefits for every student.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Computational Infrastructures for School Improvement: How to Move Forward</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/r-benjamin-shapiro"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/r-benjamin-shapiro"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/hisham-petry"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/hisham-petry"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/louis-m-gomez"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/louis-m-gomez"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/220/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/r-benjamin-shapiro"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/hisham-petry"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/louis-m-gomez"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/221">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>A Response Time Model for Bottom-Out Hints as Worked Examples</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/221/authorlist"/>
		<swrc:abstract>Students can use an educational system’s help in unexpected ways. For example, they may bypass abstract hints in search of a concrete solution. This behavior has traditionally been labeled as a form of gaming or help abuse. We propose that some examples of this behavior are not abusive and that bottom-out hints can act as worked examples. We create a model for distinguishing good student use of bottom-out hints from bad student use of bottom-out hints by means of logged response times. We show that this model not only predicts learning, but captures behaviors related to self-explanation.</swrc:abstract>
		<led:body><![CDATA[ 1. Notice that the reflection time for the second transaction is part of the logged time for the third transaction. Under the TER model, the reflection time for one transaction is indistinguishable from the thinking and entry time associated with the next transaction. Nevertheless, we need an estimate for the Think and Reflect times to understand student learning from bottom-out hints. The full problem, including external factors, is illustrated in Table 2, which shows a series of student transactions on a pair of problem steps, along with hypothetical, unobserved student cognition. Entries in italics are observed in the log while those in normal face are unobserved, and ellipses represent data not relevant to the example. The time the stu- dent spends thinking and reflecting on the bottom-out hint is about 6 seconds, but the only observed durations are 0.347, 15.152, and 4.944. In a case like this, the log data’s ob- served response times includes a mixture of Think and Reflect times across multiple steps. 
 Table 3: TER Model With Estimators. 
 Unfortunately, while the reflection time is important for properly estimating HINTt, it is categorized incorrectly. The reflection time for transaction t is actually part of the logged time for transaction (t+1). Teasing those times apart requires estimating the student’s time not spent on the hint. The first piece of our model separates out two types of bottom-out hint cognition: Think and Reflect. Thinking is defined as all hint cognition before entering the answer; reflecting is all hint cognition after entering the answer. Let Think time be denoted Kt and Reflect time be denoted Rt. We define HINTt = Kt + Rt. The task then reduces to estimating Kt and Rt. As shown earlier, this can be difficult for an arbitrary transaction. However, we focus only on bottom-out hints. Table 3 provides an example of how bottom-out hints differ from other transactions. Note the absence of a Reflect time Rt−1 in the bottom-out case. Except for time spent on answer entry and time spent off-task, the full time between receiving the hint and entering the answer is Kt. A similar, but slightly more complicated result applies to Rt. For now, assume off-task time is zero - it will be properly addressed later. Let the answer entry time be denoted Et. Let the total time for a transaction be Tt. Then the equation for HINTt becomes 
 FORMULA_1.
 where Tt and Tt+1 are observed in the log data. The first term consists of replacing Kt with measured and unmeasured times from before the answer is submitted. The second term consists of times from after the answer is submitted. If we have an estimate for Et, we can now estimate Kt. Similarly, if we have an estimate for Kt+1 and Et+1, we can estimate Rt. Constructing reliable estimates for any of the above values is impossible on a per transac- tion basis. However, if we aggregate across all transactions performed by a given student, then the estimators become more reasonable. There are two other important points regard- ing the estimators we will use. First, response times, because of their open-ended nature, are extremely prone to outliers. For example, the longest recorded transaction is over 25 minutes in length. Thus, we will require our estimators be robust. Second, some students have relatively few (≈ 10) bottom-out hint transactions that will fit our eventual criteria. Thus, our estimators must converge quickly. Now we need some new notation. We will be using the s subscript, where s represents a student. We will also use the Eˆs notation for estimators and the m(Et) notation for medians. You can think of m(Et) as approximating the mean, but we will always be using the median because of outliers. Es, the per student estimator, will represent some measure of the ”usual” Et for a student s. Also let A be the set of all transactions and As be the set of all transactions for a given student. Let A1s be the set of all correct answer transactions by a student s where the transaction immediately follows a bottom-out hint. Similarly, let A2s be the set of all transactions that follow a transaction t ∈ A1s. For convenience, we will let T 1s = mt∈A1s(Tt) be the median time for transactions t ∈ A1s and T 2s = mt∈A1s(Tt+1) be the median time for transactions t ∈ A2s. These two types of transactions are generalizations of the last two transactions shown in Table 3. This gives an equation for our estimator ˆHINTs, ˆHINTs = (T 1s − Es) + (T 2s − (K2s + Es)) (4) Here, K2s = mt∈A2s(Kt) is the thinking time that takes place for transaction t ∈ A2s. Consider Eˆs, the median time for student s to enter an answer. It always takes time to type an answer, but the time required is consistently short. If we assume that the variance is small, then Eˆs ≈ mint∈As(Et). That is, because the variance is small, Et can be treated as a constant. We use the minimum rather than a more common measure, like the mean, because we cannot directly observe Et. Instead, note that if Kt ≈ 0, then the total time spent on a post-hint transaction is approximately Et. Thus, the minimum time student s spends on an answer step is a good approximation of mint∈As(Et). In practice, the observed Eˆs is about 1 second. With Eˆs, we can now estimate Kt for t ∈ A1s. To isolate the reflection time Rs, we need an approximation for K2s , the thinking time for transactions t ∈ A2s. Unfortunately, K2s is difficult to estimate. Instead, we will estimate a value related to K2s . The key observation is, if a student has already thought through an answer on their own, without using any tutor help, they presumably engage in very little reflection after they enter their solution. To put it mathematically, let Ns be the set of transactions for student s where they do not use a bottom-out hint. We assume that Rt ≈ 0, ∀t ∈ Ns. We can now use the following estimator to isolate Rs, 
 FORMULA_2.
 where the change from line 6 to line 7 derives from the assumption Rt ≈ 0, ∀t ∈ Ns. This is the last estimator we require: Rs is approximately m(Tt −m(Tv)(u∈Ns,v=u+1))t∈As . 
 Table 4: Indicator Correlations in the Control Condition. 
 That is, we use the median time for the first transaction on a step where the prior step was completed without worked examples. This approach avoids directly estimating K2s and estimates the sum (K2s + Es) instead. There is still the problem of off-task time. We have so far assumed that off-task time is approximately zero. We will continue to make that assumption. While students engage in long periods of off-task behavior, we assume that for most transactions, students are on-task. That implies that transactions with off-task behaviors are rare, albeit potentially of long duration. Since we use medians, we eliminate these outliers from consideration entirely, and thus continue to assume that on any given transaction, off-task time is zero. A subtle point is that the model will not fit well for end-of-problem transactions. At the end of a problem there is a ”done” step, where the student has to decide to hit ”done”. Thus, the model no longer accurately represents the student’s cognitive process. These transactions could be valuable to an extended version of the model, but for this study, all end-of-problem transactions will be dropped. 
 5 Results.
 We first run the model for students in the control condition. These students were not required to do any formal reasoning steps. The goal is to predict the adjusted pre-post gain, max( (post−pre) (1−pre) , (post−pre) (pre) ). We will not use the usual Z-scores because the pre-test suf- fered from a floor effect and thus the pre-test scores are quite non-normal (Shapiro-Wilks: p < 0.005). Two students were removed from the population for having fewer than 5 bottom-out hint requests, bringing the population down to 18. The results are shown in Table 4. The first result of interest is that none of the indicators have statistically significant corre- lations with the pre-test. This suggests that they measure some state or trait of the students that is not well captured by the pre-test. The second result of interest is that all three indicators correlate strongly with both the post-test and learning gain. Notably, HINTs, our main indicator, has a correlation of about 0.5 with both the post-test and the learning gain. To the extent that HINTs does distinguish between ”good” versus ”bad” bottom-out hint behaviors, this correlation suggests that the two types of behavior should indeed be distinguished. It’s possible that these indicators might only be achieving correlations comparable to time- on-task or average transaction time. As Table 5 shows, this is clearly not the case. 
 Table 5: Time-on-Task Correlations in the Control Condition. 
 Table 6: Correlations in the Experimental Condition. 
 All three hint time indicators out-perform the traditional time-on-task measures. Nevertheless, these results still do not show whether the indicator HINTs is actually mea- suring what it purports to measure: self-explanation on worked examples. For that, we use the experimental condition of the data. In the experimental condition, students are asked to justify their correct solutions by providing the associated theorem. This changes the basic pattern of transactions we are interested in from HINT-GUESS-GUESS to HINT- GUESS-JUSTIFY-GUESS. We can now directly measure Rs using the time spent on the new JUSTIFY steps. Rs is now the median time students spend on a correct justification step after a bottom-out hint, subtracting the minimum time they ever spend on correct jus- tifications. We use the minimum for reasons analogous to those of Eˆs - we only want to subtract time spent entering the reason. In this condition, there were sufficient observations for all 19 students. The resulting correlations are shown in Table 6. There is almost no correlation between our indicators and the pre-test score, again showing that our indicators are detecting something not effectively measured by the pre-test. Also, the correlations with the post-test and learning gain are high for both Rs and HINTs. While Rs by itself has a statistically significant correlation at p < 0.10, Ks and Rs combined demonstrate a statistically significant correlation at p < 0.05. This suggests that while some students think about a bottom-out hint before entering the answer and some students think about the hint only after entering the answer, for all students, regardless of style, spending time thinking about bottom-out hints is beneficial to learning. The corollary is that at least some bottom-out hints are proving beneficial to learning. Thus far, we have shown that the indicator HINTs is robust enough for strong correlations with learning gain despite being measured in two different ways across two separate condi- tions. The first set of results demonstrated that HINTs can be measured without any direct observation of reasoning steps. The second set of results showed that direct observation of HINTs was similarly effective. Our data, however, allows us access to two other interesting questions. First, does prompting students to explain their reasoning change their bottom- out hint behavior? Second, do changes in this behavior correlate with learning gain? 
 Table 7: Changes in Behavior in the Experimental Condition. 
 To answer both questions, we look at the indicators trained on only the first 20% of each student’s transactions. For this, we use only the experimental condition because, when 80% of the data is removed, the control condition has too few remaining students and too few observations. Even in the experimental condition, only 15 remaining students still have more than 5 bottom-out hint requests that meet our criteria. The results are shown in Table 7, with ∆HINTs representing the difference between HINTs trained on the first 20% of the data and HINTs trained on the full data. To answer the first question, the change in HINTs is not statistically different from zero. The prompting does not seem to encourage longer response times in the presence of bottom- out hints, so this mechanism does not explain the experimental results of Aleven et. al.’s study[2]. However, some of the students did change their behaviors. As shown in Table 7, students who increased their HINTs times demonstrated higher learning gain. The evidence is substantial that HINTs measures an important aspect of student reasoning. 
 6 Conclusions and Future Work.
 In this study, we presented evidence that some bottom-out hint use can be good for learning. The correlations between our indicators and pre-post learning gain represent one form of evidence; the correlations between changes in our indicators and pre-post learning gain represent another. Both sets of results show that thinking about bottom-out hints predicts learning. However, extending our results to practical use requires additional work. Our indicators provide estimates for student thinking about bottom-out hints. However, these estimates are aggregated across transactions, providing a student level indicator. While this is useful for categorizing students and offering them individualized help, it does not provide the level of granularity required to choose specific moments for tutor interven- tion. To achieve that level of granularity, a better distributional understanding of student response times would be helpful, as would an indicator capable of distinguishing between students seeking worked examples versus engaging in gaming. Exploring how the distri- bution of response times differs between high learning bottom-out hint students and low learning bottom-out hint students would go a long way to solving both problems. That issue aside, our indicators for student self-explanation time have proven remarkably effective. They not only predict learning gain, they do so better than traditional time-on- task measures, they are uncorrelated with pre-test scores, and changes in our indicators over time also predict learning gain. These indicators achieve this without restrictive assump- tions about domain or system design, allowing them to be adapted to other educational systems in other domains. Whether the results transfer outside of geometry or to other systems remains to be seen, but they have so far been robust. The inclusion of two conditions, one without justification steps and one with justification steps, allowed us to show that the indicators do measure something related to reasoning or self-explanation. We estimated the indicators for the two conditions in different ways, yet both times, the results were significant. This provides a substantial degree of validity. However, one direction for future work is to show that the indicators correlate with other measures of self-explanation or worked example cognition. One useful study would be to compare these indicators with human estimates of student self-explanation.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>A Response Time Model for Bottom-Out Hints as Worked Examples</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/benjamin-shih"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/benjamin-shih"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/richard-scheines"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/richard-scheines"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/221/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/benjamin-shih"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/richard-scheines"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/222">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Integrating Knowledge Gained From Data Mining With Pedagogical Knowledge</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/222/authorlist"/>
		<swrc:abstract>Discovering knowledge from raw data is one of the goals of data min- ing. Yet, it is not always clear how this knowledge is used in educational com- puting systems and how exactly it is integrated with other knowledge like the pedagogy used. We present a case study where the use of the data mining re- sults was initially described, to a large degree, at the implementation level, thus largely ignoring the nature of the different kinds of knowledge involved. Based on Clancey’s heuristic classification model [7], the description is raised to a con- ceptual level, the knowledge level. This results in an explicit and well-defined integration of knowledge discovered with data mining techniques, pedagogical knowledge and linguistic knowledge. Such a knowledge-level description leads to an improved understanding of the system and its effects on the learners.</swrc:abstract>
		<led:body><![CDATA[ 1. CoMPASS with the concept map supporting navigation on the left and the content (concept ‘work’ as it is used in the context of the simple machine‘ pulley’) on the right. 
 We have used the relationship strength to determine the spatial proximity of the concepts. Thus the stronger the relationship between the two concepts, the closer they are spatially in the concept map. In CoMPASS, students can easily switch views to go to a related topic. This provides global coherence, because students can see what other topics they can go to that could be related to a particular topic. In addition, they can also view a particular concept from multiple perspectives as described below. For example, a student setting up an experiment with a pulley might be interested in learning about ’work’ in the context of a lever instead of pulley as shown in Figure 1. Thus, the student can navigate within a context (e.g., pulley) or across (e.g., from pulley to lever). Learning in a subject area, such as science, involves understanding the rich set of relationships among important concepts, which may form a web or a network. Revisiting the same material at different times, in rearranged contexts, for different purposes, and from different conceptual perspectives is essential for attaining the goals of advanced knowledge acquisition [22]. The alternative views that CoMPASS offers can help students to study science concepts and phenomena in depth by visiting them in multiple contexts. 
 3 Scaffolding with Prompts.
 A next step is to add adaptive support with textual prompts that help students directly, especially when they have some problems, and indirectly also teachers who cannot attend to all students in the classroom at all times. The prompts are supposed to scaffold the students. Since the concept of scaffolding has been somewhat overused [17], we briefly describe it. Scaffolding in the context of learning has originally been defined as an “adult con- trolling those elements of the task that are essentially beyond the learner’s capacity, thus permitting him to concentrate upon and complete only those elements that are within his range of competence” [27]. Scaffolding has been linked to the work of Soviet psycholo- gist Lev Vygotsky, although he never used the term scaffolding. According to Vygotsky, a novice learns with an expert, and learning occurs within the novice’s Zone of Proximal Development (ZPD). ZPD is defined as the “distance between the child’s actual develop- mental level as determined by independent problem solving and the higher level of potential development as determined through problem solving under adult guidance and in collabo- ration with more capable peers” [25]. Enabling the learner to bridge this gap between the actual and the potential depends on the resources or the kind of support that is provided. Instruction in the ZPD can therefore be viewed as taking the form of providing assistance or scaffolding, enabling a child or a novice to solve a problem, carry out a task or achieve a goal “which would be beyond his unassisted efforts” [27]. Proper scaffolding requires a computer-based learning environment like CoMPASS to support, among other things, (a) continuous assessment of the learner needs to be used to calibrate the support; (b) scaffolding fading away over time and the learner taking control of the task; and (c), the learner needing to be actively involved in the learning process [15,23]. The implications for the prompts are therefore: (a) the prompts must be adapted to the student’s current understanding and progress, i.e., they must be adaptive, context sensitive and individualized; (b) the prompts should be formulated and presented (or not!) so that the student is not “bothered” by them when there is no need for support anymore; and (c), the prompts should be formulated such that they result in active reflection and they are not just corrective suggestions to be followed mindlessly. Adaptive support requires modeling users as in, for instance, adaptive hypermedia sys- tems where mostly explicit user models are used by the system to adapt presentation and navigation support to each individual user [4]. However, this is simply not feasible given how CoMPASS is being used. Only sparse user data is available and there is no time to collect detailed user information with questionnaires or multiple-choice tests. We basically have to rely on a few clicks to detect how a student is progressing. Fortunately, earlier work on data mining the navigation data collected from the CoM- PASS users had revealed that students using CoMPASS can be assigned to categories that can be associated with the students’ approach to learning and understanding of the mate- rial [19]. Since this paper’s focus is on integration of the discovered knowledge and not on the discovery process itself, we just briefly summarize the data mining methods used. To find the learner categories, each student’s clickstream was converted into a navigation matrix N describing the number of transitions Ni, j from concept ci to concept c j and then pruned using the Pathfinder algorithm [21]. The resulting matrices, one for each user, were then clustered using the k-Means algorithm [10]. The students in these clusters were then an- alyzed to see what educational characteristics they had in common. For instance, as de- scribed in [19], the students in one cluster showed that they focused on the relevant (as determined by an expert) concepts but also visited related concepts. Such students tended to do well. In another cluster, students apparently had no well-defined focus and explored concepts also in other topics. Yet another group showed a random behavior indicating that they were not aware of the conceptual structure of the domain. 
 Figure 2. A rule described at the implementational level. 
 Based on these results, we developed rules to generate adaptive prompts [16]. These rules use some simple characteristics of the realtime navigation data, i.e., the clickstream, to detect behavior associated with the clusters found during data mining. An example of such a rule is shown in Figure 2. Of course, this is not the implementation of the rule itself, but it is described in terms of concepts at the level of the implementation, especially the condition. The justification is not used by the system and only serves as a comment to the writer of the rule. This approach sounds reasonable and is described in more general form in Figure 3. However, as the figure shows, the role that the pedagogical knowledge plays and how it connected to the classifications generated by the data mining methods is conceptually not very clear. The reason is that the approach is described at the implementational level instead of the knowledge level. Thus, modifications to the data mining approach, to the pedagogical approach and to what kinds of text prompts to use will have to happen at the implementational level. 
 Figure 3. Text prompt generation algorithm. 
 4 Integrating Data Mining with Pedagogical Knowledge. 
 One of the pitfalls of system design is to make decisions at the implementational level when they should be made at the conceptual level, although, of course, implementational con- straints need to be considered. For instance, in the early AI days, expert system developers argued about forward versus backward chaining, instead of focussing on what tasks the experts solved and with what problem solving methods. Fortunately, the discussion soon moved from the implementational level to the conceptual, or, knowledge level [26]. This type of work benefited from earlier research by Clancey on classification of the reasoning that goes on in expert systems [7]. Clancey [7] describes the simple “heuristic classification” inference structure in Fig- ure 4 that provides the basis for many problem solving methods used by experts. 
 Figure 4. Heuristic classification. 
 For instance, from a set of symptoms (data) a doctor abstracts to a class of symptoms (data abstraction) which then requires a certain type of treatment (solution abstraction) which is found by applying medical knowledge (heuristic match). Using contextual information about the patient and treatment, the type of treatment can be refined, e.g., the dosage can be adjusted (refinement). More direct and simpler symptom-to-treatment reasoning is not as good, since it does not take advantage of the different types of knowledge (classification, refinement, heuris- tic medical knowledge) and it would result in a much less effective representation of the knowledge. Adding new knowledge would be messy since it would not be clear how ex- actly it should be integrated and used. Just reacting to symptoms before one is able to classify the type of a problem would also result in more mistreatment. If new medications or symptom detectors are introduced, it is clear how they are going to be integrated in the heuristic classification scheme. Figure 5 shows the heuristic classification scheme applied to the generation of adaptive prompts. The direct link from the realtime navigation data to the text prompts (see Figure 3) has been replaced by a conceptual structure integrating the various types of knowledge involved. It should not be a surprise that the heuristic classification scheme is such a good match. After all, the learner’s navigation behavior is the symptom and the text prompt the treatment for the learner. In Figure 5, there are three types of knowledge explicitly represented. The knowledge discovered with the data mining methods is represented by the learner categories. Peda- gogical knowledge is used to decide what kind of textual interventions should be used. And finally, linguistic knowledge is used to create the appropriate text. The latter is especially important if several interventions need to be combined into one phrase, or past prompts need to be taken into account. Applying the problem solving method in Figure 5 results in the rule set shown in Fig- ure 6. There are now three steps instead of one. First, the student’s navigation behavior is still categorized the same way as in the original version, but this time mapped explic- itly to one or more of the learner categories discovered via data mining of the off-line data collected in the past. Since the categories are the result of the data mining process, once improved data mining results are available—and we are working on them—these categories can be modified. 
 Figure 5. Text prompt generation at the conceptual level using the heuristic classification scheme. The dotted line refers to Figure 3. 
 Second, based on the learner categories and the used pedagogy, the kind of feedback deemed most useful for such a learner is suggested. Although we intend to use as simple rules as shown in Figure 6, a much more complicated reasoning process could be involved, however, using pedagogical knowledge only. Third, the treatments are collected and trans- lated into a proper prompt. For instance, if the first rule (categorization) in Figure 6 applies to two concepts, the second linguistic rule will be applied. We will use a relatively simple yet quite powerful template-based approach to generate the natural language output [8,20]. This will also allow us to take previous prompts into consideration and avoid repeating the same prompt over and over even if the student does not improve. In our approach, Clancey’s heuristic match (see Figure 4) is composed of two steps. The refinement step is the same as in the old case where the necessary variables in the template are bound based on the context. In the original formulation of how the prompts were generated, all three kinds of knowl- edge were mixed into each rule. Theoretically as well as practically, this is a problem. From a theoretical point of view, it is quite unclear what types of knowledge are involved and how. For instance, the importance of the linguistic knowledge was originally overlooked. From a practical point of view, the modular approach makes it clear what to change, be the change either due to modification in the pedagogical approach or due to improved data mining or text generation methods. This approach is not only suitable for the specific situation in CoMPASS. An obvi- ous place to apply the approach described in this paper is in the context of association rules [9, 12]. These rules capture associations like beer ⇒ diapers between variables of items in shopping baskets [2]. Based on our experience in CoMPASS, it will be useful to always carefully consider and make explicit what type of knowledge such rules capture. Looking at the current literature, it seems, that this is generally not done in an explicit and rigorous way. Such association rules are normally judged by some mathematical definition of interestingness [1, 3, 14] which is perfectly fine for finding the rules. However, the rules also need to be used in a meaningful way and that is where our approach may be useful. 
 Figure 6. A set of rules based on the conceptual description shown in Figure 5. 
 5 Conclusions.
 We have presented a case study of our own research showing that making the different kinds of knowledge including the ones gained from data mining can have great benefits. It is clear what modifications need to be made if pedagogy, data mining techniques, or other parts are being changed. This is especially useful if weak points need to found in the educational software. It may not be what the prompts say, but how they say it. This is similar to the difficulty students have with word problems where often difficulties reflect students’ language problems but not necessarily their math problems [24]. Although this case study presented a specific problem and solution, the idea of making the problem solving and the knowledge involved explicit, is a general one and should al- ways be done be that based on Heuristic Classification [7], KADS [26], Generic Tasks [6] or another method to model knowledge and problem solving methods [13]. We have used the heuristic classification because it is simple, yet powerful enough. But is this approach more than just proper system design? Well, not really. However, it does matter at what level we design, experiment with, modify and understand a system, and take advantage of various kinds of knowledge. This is crucial if we work on complex systems supporting learners where it surely is not good enough if “it works.” We also must understand why it works. 
 Acknowledgments.
 This material is based upon work supported in part by the NSF under Grants #0437660 (IERI) and #0434624 (NSDL). Opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Integrating Knowledge Gained From Data Mining With Pedagogical Knowledge</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/roland-hubscher"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/roland-hubscher"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/sadhana-puntambekar"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/sadhana-puntambekar"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/222/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/roland-hubscher"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/sadhana-puntambekar"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/223">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Developing a Log-based Motivation Measuring Tool</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/223/authorlist"/>
		<swrc:abstract>The purpose of this study is to develop a conceptual framework and a tool for measuring motivation of online learners. The study was carried out in three phases, the first of which was the construction of a framework, based on an extensive literature review. Phase two consisted of identifying variables computable from log file data, associate with the framework and compatible with previous empirical research. For this purpose, an empirical study was designed and a specific learning environment focusing on vocabulary for adults was chosen. Log files of a large population (N=2,162) were collected and variables were identified using Learnograms, a visual representation of learning variables over time. This phase resulted in seven explicitly defined variables, along with a mechanism to calculate them from the raw log files. The third phase included preprocessing of the dataset (reducing it to 674 cases) and application of hierarchical clustering of the variables. This phase resulted in three clusters interpreted to fit the three dimensions of motivation defined in the framework. A discussion of this study and further research is provided.</swrc:abstract>
		<led:body><![CDATA[ 1. Previous research on motivation recognition based on learner-computer interaction. 
 {1} The research was based on captured screen activity. 
 Within this framework, the two objectives of this study are: a) To identify variables related to the three motivation dimensions, which are computable from data stored in the system log files; b) To cluster these variables, based on empirical data, for classifying them according to the three motivation dimensions. 
 3 Methodology.
 3.1 Procedure.
 The study was carried out in three consecutive phases using different methodologies: Phase I – Constructing the Research Framework. This literature-based phase was used to conceptualize the terms to be used in our motivation research. Within the framework, three dimensions were defined (Engagement, Energization, Source); see previous section. Phase II – Identifying Variables. In order to choose and define motivation-related variables, Learnograms – visual representations of learning variables over time – were used as the main research tool (as described in [13]). Learnograms presenting students' activity (N=5) in an online vocabulary course for adults (see section  3.2) were observed, in order to identify the relevant computable variables. The compatibility of the variable to previous empirical research in this field was taken into consideration, as well as their association to our framework. At the end of this phase, seven variables were identified. Phase III – Classifying the Variables According to the Motivation Dimensions. An empirical study for the evaluation of the identified variables was conducted (with the same learning environment used in phase I). Log files of a large population (N=2,162) for one month (April 2007) were collected and preprocessed. Students using the researched system belong to different courses (varied by length, intensity, starting date and proximity to the exam), however this logged segment was analyzed regardless the student's learning stage. A filter was applied for keeping students with at least 3 active sessions (N=1,444). Algorithms for calculating the variables were formally written and implemented using Matlab. The dataset was preprocessed and the final set of cases to be analyzed was defined (N=674). Finally, Hierarchical Clustering of the variables was applied using SPSS, with Pearson Correlation Distance as the measure and Between-groups Linkage as the clustering method. 
 3.2 The Learning Environment.
 A simple yet very intensive online learning unit was chosen as the research field. This fully-online environment focuses on Hebrew vocabulary and is accessible for students who take a face-to-face preparatory course for the Psychometric Entrance Exam (for Israeli universities). The online system is available for the participants from the beginning of the course and until the exam date (between 3 weeks and 3 months in total). The system includes a database of around 5,000 words/phrases in Hebrew and offers varied instructional strategies: a) Memorizing, in which the student browses a table of the words/phrases along with their meanings; b) Practicing, in which the student browses the table of the words/phrases without their meaning. The student may ask for a hint or for the explanation for each word/phrase; c) Searching for specific word/phrase; d) Gaming; e) Self testing, in the form of the exam the students will finally take. Throughout the learning process, the student may mark each word/phrase as "well known", "not-well known" or "unknown". This information is stored and being used by the system. 
 3.3 Log File Description.
 The researched system logs the students' activity, thus each student is identified by a serial number. Each row in the log file documents a session, initiating by entering the system and ending with closing the application window. For each session, the following attributes are kept: starting date, starting/ending time, number of words marked as "known" at the beginning/end of the session, ordered list of actions and their timestamps. 
 4 Results.
 4.1 Motivation-related Variables (Phase II).
 The authors have examined the Learnograms of a few students (N=5), searching for interesting patterns and irregularities, while considering learning behavior which may be related to motivation. Seven variables were identified and calculated (see Table 2). 
 4.2 Classifying the Variables (Phase III).
 The variable distributions were examined over the 3-sessions filtered dataset (N=1,444), see Figure 1. Three of the variables had a significant 0-values noise: wordMarkPace, examPC, gamePC, thus cases with 0-value in them were cleaned for focusing on the positive-value cases. Since the variables were skewed in the final dataset (N=674), we used transformations of log (timeOnTaskPC, avgSession, wordMarkPace, examPC, gamePC) and square-root (avgActPace, avgBtwnSessions). 
 Table 2. Motivation-related variables. 
 Figure 1. Distribution of the variables before cleaning and transformation were applied (N=1,444). 
 The clustering process is described by a dendrogram (from the Greek dendron "tree", -gramma "drawing") presented in Figure 2. The vertical lines determine which variables/clusters were grouped together and at which stage of the algorithm (from left to right). For example, the first coupled variables were timeOnTaskPC and avgSession, and next examPC and gamePC were grouped. The resulting clusters appear in Table 3, their relation to the motivation dimensions is given in the Discussion below. 
 Figure 2. Dendrogram of the hierarchical clustering process. 
 Table 3. The resulted clusters and their mapping to the motivation dimensions. 
 5 Discussion.
 In this study, an empirically-constructed tool was developed for log-based measuring of online learners' motivation. Motivation is measured by three dimensions – Engagement, Energization, and Source – and by seven computable variables corresponding to these dimensions (see Table 3). The classification of the clustered variables to the three dimensions is based on previous research in this area. The variables timeOnTask and avgSession, which form the first cluster, might be related to the extent of Engagement, as it was previously suggested that working time might be a measure for attention or engagement [3, 17]. examPC and gamePC - grouped together in the second cluster - reflect the student's Source of motivation; it may be reasonable to hypothesize (inspired by, e.g., [9, 15]) that students who frequently tend to take self exams (related to performance-goal orientation) have extrinsic motivation to learn, while those who tend to game applications (related to learning-goal orientation) are intrinsically motivated. The variables avgActPace and avgBtwnSessions are also clustered together with the previous two, but their closeness to Source of motivation is yet to be established. The variable wordMarkPace, indicating the word marking speed, forms the third cluster. According to a diagnosis rule found in de Vicente and Pain [5], fast speed of activity together with high quality of performance (when staying in similarly-difficulty exercises) suggests increasing motivation. Since an increase in the number of words marked is an indication of the student's perceived knowledge (i.e., a reflection of the performance), wordMarkPace might be related to the direction of motivation, i.e., Energization. The tool developed in this study enables to measure online learners' motivation by using solely information stored in log files. However, there are three limitations to this innovative tool. First, variables were identified based on a specific learning environment; it might be useful for similar systems, but for different environments (varied by, e.g., learning domain, instruction modes available) these variables should be converted, and their clustering should be re-examined. Secondly, the classification to the motivation dimensions within the framework has not been validated yet, as well as their actual scales; it is within the authors' agenda to continue in the direction of validation. Third, the tool might not be complete; we only focused on seven variables, however others might be considered. Identifying these variables based on a segment of the learning makes it possible to employ this tool during the learning process; that way, intervention when needed might be possible, and changes in motivation may be analyzed. Further to the developed tool, the process used in this study – i.e., constructing a literature-based conceptual framework, using Learnograms for identifying variables, clustering and classifying these variables within the framework - is of great importance, since it is a procedure which might be transferable to other domains (e.g., anxiety, self- regulation) for developing measuring tools. Measuring the online learner's motivation has a major role in the instruction-learning cycle. Monitoring the learner's motivation might enable the instructor to interfere when needed (e.g., when student's motivation is decreasing), and should help in developing of intelligent tutoring systems which react not only to the learner's cognitive behavior but also to her or his affective situation. The overall objective of this underlying approach is to increase the efficiency of the learning process.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Developing a Log-based Motivation Measuring Tool</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/arnon-hershkovitz"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/arnon-hershkovitz"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/rafi-nachmias"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/rafi-nachmias"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/223/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/arnon-hershkovitz"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/rafi-nachmias"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/224">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Mining and Visualizing Visited Trails in Web-Based Educational Systems</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/224/authorlist"/>
		<swrc:abstract>A data mining and visualization tool for the discovery of student trails in web-based educational systems is presented and described. The tool uses graphs to visualize results, allowing non-expert users, such as course instructors, to interpret its output. Several experiments have been conducted, using real data collected from a web-based intelligent tutoring system. The results of the data mining algorithm can be adjusted by tuning its parameters or filtering to concentrate on specific trails, or to focus only on the most significant paths.</swrc:abstract>
		<led:body><![CDATA[ 1.  Results showing routes in text mode and in the graph visualization window. 
 In Figure 1, each node represents a web page, and the directed edges (arrows) indicate how the students have moved between them. The tool’s graph visualizations are generated using the CLOVER framework, described in greater detail in [3]. Edge thickness varies according to edge weight; this allows users to quickly focus on the most important edges, ignoring those that have very low weights. In addition to line widths, numerical weights are also available. This information can be useful to a learning designer in different ways. First, it can be used as a limited auditing tool, providing a deeper understanding of the learning paths effectively followed by the students. Additionally, comparing this information with expected a priori paths allows the designer to refine the sequencing strategy. The results in the graph can show information that was not know in the first place, e.g. which activities are the most difficult, which are easier than expected (shown as more common transitions), etc. 
 3 Experimental Results.
 This study uses real data collected from a web-based intelligent tutoring system [9] for the domain of Operating Systems. Although the original log file contains sessions from 88 students that used the system in 2006, the study covers only the subset of “good users” (those with more than two sessions). The study covers data from 67 students, with 754 sessions (using 25 minute timeouts) and 1121 records in total. We have carried out several experiments focused on HPG’s sensibility to its parameter values in order to obtain different configurations of the graph (number of nodes, links, routes, and average route length).  Results with varying parameters are displayed in Table 1. 
 Table 1.  HPG: Comparison varying alpha and cut-point parameters. 
 Support and confidence thresholds give the user control over the quantity and quality of the obtained trails, while α modifies the weight of the first node in a user navigation session. In Table 1, the support must be set very low in order to obtain routes with α = 0. This is due to the fact that there are few start nodes. It shows that students have started their sessions in different nodes, and none of these have a significantly higher probability. This changes as α increases, since there will progressively be more visited nodes. The number of routes, nodes and links is increased as time support is decreased. On the other hand, the number of resulting nodes, links, routes and average route lengths is greatly increased when the confidence value is decreased. This effect is more evident on links and routes. This can be traced to the fact that the confidence threshold prunes the intermediate transactions that do not have a derivation probability above the cut-point. It must be noted that the user of the HPG algorithm can use both the alpha, support and confidence thresholds, and the three available filters, in order to obtain a suitable number of trails. The learning designer must work with the course lecturer in order to tune these parameters to a particular community of learners. Then, combining the information on the table with that displayed in the graph, the instructor can focus on the most visited routes in order to make decisions on the organization of the educational web space, or recommend paths and shortcuts to learners. 
 4 Conclusions.
 This paper has described a data mining and information visualization tool that aids authors and instructors to discover the trails followed by students within web-based educational systems. The resulting networks are then visualized using a graph representation with edges of varying thickness, which is more compelling to non- specialized users than textual output. Future plans include the addition of other sequential pattern mining algorithms such as AprioriAll and PrefixSpan. Our goal is to use the tool to provide personalized trails to students, delivering on the promise of personalized learning within adaptive e-learning systems. 
 Acknowledgments. 
 The authors gratefully acknowledge the financial subsidy provided by the Spanish Department of Research under TIN2005-08386-C05-02 and TIN2007- 64718, and the British Teaching and Learning Research under grant RES-139-25-0381.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Mining and Visualizing Visited Trails in Web-Based Educational Systems</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/c-romero"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/c-romero"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/sergio-gutierrez"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/sergio-gutierrez"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/manuel-freire"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/manuel-freire"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/s-ventura"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/s-ventura"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/224/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/c-romero"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/sergio-gutierrez"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/manuel-freire"/>
		<rdf:_4 rdf:resource="http://data.linkededucation.org/resource/lak/person/s-ventura"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Can we Predict which Groups of Questions Students will Learn from?</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225/authorlist"/>
		<swrc:abstract>In a previous study ([4]), we used the ASSISTment system to track student knowledge longitudinally over the course of a schools year, based upon each student using our system about a dozen times during the course of the year. This result confounded learning from the computer system with students learning from their sitting their normal class.  In this work, we look to see if students were reliably learning from their time spent with the computer in a single day. Our result suggests that students performed better later in the same computer session on similar skills, which indicates students are learning from using ASSISTments. However, learning is rather uneven across groups of skills. We test a variety of hypotheses to explain this phenomenon and found that the automated approaches we tried were unable to account for the variation. However, human expert judgments were predictive as to which groups of skills were learnable.</swrc:abstract>
		<led:body><![CDATA[ 1. A sample GLOP that addresses the skill "Area". 
 If students tend to perform better on later opportunities of items in a GLOP, it indicates that they may have learned from the instructional assistance provided on items by the ASSISTment system that they worked on earlier by answering the scaffolding questions or by reading hint messages. There is controversy over whether same-day learning opportunities should be used as evidence of learning. For example, Beck [1]  thought repeated trials were not indicative of learning. He chose not to use later encounters on the same day in the Reading Tutor since performance on those encounters is not a reflection of student knowledge but just retrieved from short term memory. Our domain (mostly 8th grade multi-step math problems) is more complex than reading and the items in a GLOP usually have different surface features. Solving these problems is not simple retrieval of an answer from a previous question. And even if it wasn't more complex, our later day trials are horribly confounded by classroom instruction due to low density of usage (every other week). In this paper, we chose to analyze the response data on the same day to eliminate the confound of learning happening because of classroom instruction between two ASSISTment sessions. 
 2.2 Sample of the data we used for analysis.
 We collected data for this analysis from Oct. 31, 2006 to Oct. 11th, 2007. 2000+ 8th grade students participated in the study. We defined participation in a GLOP as answering two or more questions in it, and excluded students who participated in less than five GLOPs to make sure each student has at least 10 data points. We ended up with a data set of 42,086 rows, with each row representing a student’s attempt at an item. 777 students entered into our final data set, and each student on average worked on 54 items across 14 GLOPs. Table 1 shows a small sample of our data. In particular, Table 1 shows two students’ performance on two GLOPs, 16, and 3 (partly). We use the column “correct?” to indicate whether the student answered the question correctly or not. The value will be 1 where he succeeded; otherwise, it is set to be zero. The first student worked on three problems (i.e. had 3 opportunities to learn) from GLOP 16 on April 2nd, 2007 starting from 9:39AM. He failed the first two but managed to solve the last one. 
 Table 1. Sample data showing two students’ performance on two GLOPs. 
 3 Research Question 1: Do students learn from ASSISTments?.
 We first attempted to determine whether the system effectively teaches. To answer the first research question if students are learning from ASSISTments, we ran a logistic regression to study the relationship between student performance (i.e. their responses to items) and the number of opportunities the student has on a GLOP. In our method, the dependent variable is student response to a question and we account for the difference of student math proficiency by including the student as one of the predictor variables. Similarly, we include the question as another predictor with regard to the fact that questions in one GLOP may vary in difficulties. The regression formula is 
 FORMULA_1. 
 Logistic regression model. 
 Where ijp  is the probability that the student i will answer question j correctly Opportunity# indicates how many opportunities the student i has on a particular GLOP. The model is very similar to LFA models except that skills are not included as factors since we are investigating generalized learning over all GLOPS. We ran a multinomial logistic regression treating student and question as factors and opportunity as a covariate. The regression coefficient estimated by the model, corresponding to the number of learning opportunities (γ ), is .03 (p < .001). This result suggests that in general, students performed reliably better as they have more chances of practicing on the same GLOP. This result suggests that in general, students performed reliably better as they have more chances of practicing on the same GLOP. The coefficient in the logistic regression model indicates that students will improve by 0.03, on a logit scale, for each practice opportunity. This learning corresponds to approximately a 0.8% improvement in performance for each problem practiced, a rather small effect. In Massachusetts, MCAS test scores are categorized into four performance levels (namely warning, need improvement, proficient, and advanced). According to the results of 2006 MCAS test, students need to earn 13 more points (24% of the full score) to jump from need improvement to proficient which is required by the federal movement based on NCLB standards to graduate from high school. Theoretically, if students can gain 0.7% for each learning opportunity, they will fulfill the 24% improvement by solving 31 problems in ASSISTments. It should be noted that there may be a selection effect in this experiment in that better students are more likely to do more problems in a day and therefore more likely to contribute to this analysis. Also there is a limitation with the model that all GLOPs are assumed to produce the same amount of learning, which may not be true as we will show later. A positive answer to the first question allows us to claim that students are learning from working in ASSISTments and the learning results are generalized across the 40 GLOPs. Then, we stepped further to explore if all of the GLOPs are equally effective at promoting learning. The answer is “no”, which is not surprising anyway since the items in different GLOPs vary on several aspects (e.g. focusing on various skills; built by authors with differing teaching experience using various teaching strategies, etc.). In summary, out of the 40 GLOPs, the amount of learning per opportunity is statistically reliably higher than zero on 11 of them. 2 GLOPs caused marginally reliable learning and 16 caused unreliable learning. And there is non-reliable “un-learning” for the remaining 11 GLOPs, suggesting that not much learning occurred when students worked on these GLOPs. 
 4 Research Question 2: Why students learned or failed to learn?.
 Now that we have shown that learning varies among GLOPs, we will explore the reasons for this variation. We are not only interested to know which category each GLOP falls in and but also curious why. Particularly, we want to investigate why students did not show learning on certain GLOPs. Our four hypotheses are: 1. H1: Learning transfer from harder items to easier items, or students tend to learn more by doing harder items than by doing easier items. Presumably, if a student learned to solve a hard item, he then should be able to do better on an easier item that requires similar skills.  However, the converse is not necessarily true. 2. H2: Knowledge transfer occurs within GLOPs of items that use similar skills. We can never know exactly how a student internally represents a problem and what the exact skills a student applied to solve a problem. But if a GLOP is well-focused in what it covers, presumably students should show more learning within it. 3. H3: The “learnability” of the skills required by GLOPs varies. Our statistics show that each ASSISTment provides about 2 minutes of instruction. It can be hard to teach some skills effectively, for instance, symbolization articulation, in such a short period. Such skills require deep understanding and more practice to be able to apply and transfer, whereas some other skills such as area are more teachable since students only need to be reminded to apply the area formula. 4. H4: The efficacy of instructions has an impact on learning results. We can easily imagine that some GLOPs have better teaching efficacy than others. The quality of the scaffolding questions and hint messages can differ from one item to another as authors used a tutoring strategy that are more, or less, effective than others. In this paper, we will test the first two hypotheses and leave the last two as future work. We plan to invite more content experts to help us identify the learnability of the related skills and to evaluate the quality of the ASSISTments by looking closely at the scaffolding questions and hint messages. 
 4.1 Do students learn more from harder items or easier items?.
 Noticing learning varies among GLOPs, the first thing we did is to explore the relationship between the amount of learning and the easiness of a GLOP (measured by the average difficulty of items in the GLOP). We calculated the rank-order correlation and got a coefficient of .333 (p = .036, N=40), which indicates that students learned more on harder GLOPs than on easier ones. We asked ourselves: why is this? A quick answer is that there is more room to grow for harder items. Or, maybe students just learn more from harder items than easier items. Beck [1]  introduced an approach called learning decomposition to analyze what type of practice was most effective for helping students learn a skill. The approach is a generalization of learning curve analysis, and uses regression to determine how to weight different types of practice opportunities relative to each other. In this paper, we apply learning decomposition to our data set to investigate how students acquire math skills: will their practice on harder items produce more learning? To test our first hypothesis, we added two columns to our data set. One column, entitled “easier_before_current”, represents how many items the student has seen in the same GLOP are easier than the current item. The other column, entitled “harder_before_current”, indicates how many items were seen that are harder than the current one. We measure the easiness of the items using the item parameter given by a one-parameter Item Response Theory model (i.e. Rasch model1). The Rasch model was trained over data collected in the system from Sept., 2004 to Jan., 2008, including responses to 2,700 items from more than 14,000 students. We include the two columns as covariates in the regression model. 
 FORMULA_2.
 Learning Decomposition Model. 
 Where eγ  and hγ  represents the coefficients for the two new covariates respectively. The model was fitted in SPSS 14.0. We noticed that the coefficients of the two covariates of easier_before_current and harder_before_current are very close to each other ( eγ  = .032, and hγ = .033). The coefficient for easier_before_current is fractionally but not reliably lower (p=.966), which suggested that students learn as much from easier items as from harder items, and thus our first hypothesis is rejected. 
 4.2 Does more learning occur in GLOPs that are more focused?.
 H2 is different than H1 in that it believes that transfer occurs within GLOPs that have similar difficulty questions (and therefore address similar skills based on our assumption). To test H2, we want to investigate the relationship between the amount of learning that happened in each GLOP and the cohesiveness of the GLOP in term of item difficulty and the skills that are needed to answer the items. We used two approaches to quantify the cohesiveness of the GLOPs. The first metric is an automated measure that comes from a computer modeling process based on the assumption that if two skills, A and B, are better modeled by a single skill, then practice on either A or B symmetrically transfers to the other. During the modeling process, for each GLOP, we compared the BIC of two models.  The first model treated each question as having a separate difficulty. The second model treated all questions as having the same difficulty, and thus had number_of_questions_in_GLOP-1 fewer parameters. Presumably, if the cohesiveness of a GLOP is high, we should expect the second model to fit better on our data as measured by Bayesian Information Criteria (BIC) (or any model fitting criteria that penalizes for model complexity). We followed the same procedure and calculated the difference of BIC values between two models for each of the GLOPs. The second metric is based on our subject matter expert’s ranking of the cohesiveness of the GLOPs. As requested by us, our subject matter expert set the rating from 1 to 5. 
 {1} In the Rasch model, the probability of a specified response is modeled as a logistic function of the difference between the person and item parameter. In educational tests, item parameters pertain to the difficulty of items while person parameters pertain to the ability or attainment level of people who are assessed. 
 A fit of 1 or 2 means that the items are very different. A 3 means there are some flaws in the selection, a 4 means there are just a few inconsistencies and a 5 means they fit very well. According to the ranking of the expert, 18 GLOPs got a fit of 5, 10 were given a fit of 4, 7 GLOPs got 3 and the remaining 5 GLOPs scored 2. After obtaining the two metrics, we continued to analyze the relationship between the cohesiveness of the GLOPs and the amount of learning that happened in each of them. First, we calculated the rank-order correlation between the automated metric and the amount of learning (given by Equation II) but did not find a significant relation (r = .13, p = .94). We then discretized coherence into 3 coherence bins: high, medium and low and performed a one-way ANOVA to explore whether there were any differences in the amount of learning, but found no main effect (F = .676, p = .515). After that, we did the same analysis using the expert ranking of the cohesiveness. The rank-order correlation between fit and amount of learning is equal to .322 (p = .045). Yet the ANOVA shows no main effect of fit (F = 1.573, p = .213). Further more, instead of using five groups, we merged all GLOPs with fit less than 5 into one category named “non-perfect-fit” as a contrast to the ones with “perfect-fit” and ran an independent sample t-test to compare the mean between the two categories. The result suggested that there is statistically reliably more learning happening in GLOPs of perfect fit (t = 2.311, p = .030). To complete the third side of the triangle of learning/automated coherence metric/expert ranking, we also computed the correlation between our two metrics of fit/cohesiveness and found out that they do not correlate with each other (r =-.198, p=.22), which means that an automated measure and an expert's judgment differ. In conclusion, H2 was supported by the expert’s judgment but not by the result of data mining. 
 5 Future work and Conclusions.
 In terms of caveats and recognized limitations, we want to first acknowledge that we don’t have control group to compare the learning result against to. Also, if student performance systematically varies over time apart from learning, our model is not able to account for it. For instance, if students experienced a ramp up effect of doing better over time, this could explain away our results. Similarly, if students get fatigued over a class period we would be underestimate the learning effect. As a future work, we want to look to see how the items would be grouped by some automated method such as Q-matrix algorithm or LFA. In conclusion, we presented evidence that suggests there is learning within ASSISTments. More interestingly, we found that the learning differed across the groups of items. We tested a variety of hypotheses to explain this phenomenon and found that the automated approaches we tried were unable to account for the variation.  However, human expert judgments were predictive as to which groups of skills were learnable. The contribution of the paper lies in two aspects. First, we looked at when learning occurs in an intelligent tutoring system and examined a variety of hypotheses on why learning happens. While these hypotheses seemed intuitive, they were not supported by our analysis. Second, student modeling research typically accounts for the amount of learning due to a practice opportunity, but generally does not try to take into account of learning outside the tutor (such as classroom instruction, homework, etc.). Using this type of analysis that focuses on within-session learning, we isolated the effect to those caused by our tutor. 
 Acknowledgement.
 This research was made possible by the U.S. Department of Education, Institute of Education Science (IES) grants, “Effective Mathematics Education Research” program grant #R305K03140 and “Making Longitudinal Web-based Assessments Give Cognitively Diagnostic Reports to Teachers, Parents, & Students while Employing Mastery learning” program grant #R305A070440, the Office of Naval Research grant # N00014-03-1-0221, NSF CAREER award to Neil Heffernan, and the Spencer Foundation. All the opinions, findings, and conclusions expressed in this article are those of the authors, and do not reflect the views of any of the funders.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Can we Predict which Groups of Questions Students will Learn from?</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/mingyu-feng"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/mingyu-feng"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-e-beck"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-e-beck"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/mingyu-feng"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-e-beck"/>
		<rdf:_4 rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/226">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Mining Student Behavior Models in Learning-by-Teaching Environments</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/226/authorlist"/>
		<swrc:abstract>This paper discusses our approach to building models and analyzing student behaviors in different versions of our learning by teaching environment where students learn by teaching a computer agent named Betty using a visual concept map representation. We have run studies in fifth grade classrooms to compare the different versions of the system. Students’ interactions on the sys- tem, captured in log files represent their performance in generating the causal concept map structures and their activities in using the different tools provided by the system. We discuss methods for analyzing student behaviors and linking them to student performance. At the core of this approach is a hidden Markov model methodology that builds students’ behavior models from data collected in the log files. We discuss our modeling algorithm and the interpretation of the models.</swrc:abstract>
		<led:body><![CDATA[ 1.1 Learning by teaching: The Betty’s Brain system.
 The Betty’s Brain system is illustrated in Fig. 1. The teaching process is implemented as three primary activities:  (i) teach Betty concepts and links using a concept map representation [6]; (ii) query Betty to find out how she an- swers questions using what she has been taught; and (iii) quiz Betty on a set of predefined questions generat- ed by the mentor agent to see how she performs. Betty uses qualitative reasoning me- thods to reason through chains of links to answer questions, and, if asked, explains her reasoning using text and animation schemes. She al- so provides feedback that reflects the students’ teaching behaviors. The goal is to get the students to adopt metacognitive strategies in their learning tasks [11]. Students reflect on Betty’s answers and her explanations, and revise their own knowledge as they make changes to the concept maps to teach Betty better. 
 1.2 Experimental Design.
 Our participants were 56 students in two 5th grade science classrooms taught by the same teacher. Data for three students was dropped from the main study, and three more were dropped from the transfer study due to excessive absences. Students were assigned to one of three conditions using stratified random assignment based on standardized test scores. The students first created concept maps on river ecosystem concepts and causal relations in the main phase (seven 45-minute sessions) of the study. Depending on their assigned group, students utilized one of three versions of the system: a) a learning by teaching (LBT) version in which students taught Betty, b) a self-regulated learning by teaching (SRL) version in which students taught Betty and received metacognitive prompts from Betty, and c) an intelligent coaching system (ICS) version in which students created a map for themselves with guidance from the mentor agent. The ICS system served as our control condition [3]. After an eight-week delay, students participated in the transfer 
 Figure 1:  Betty's Brain System with Query Window.
 phase (five 45-minute sessions) in which they learned about a new domain, the land- based nitrogen cycle. During this phase, all students used a stripped-down version of the LBT system in which all of the feedback provided by Betty or the mentor was removed. 
 1.3 Results.
 We scored the students’ final main and transfer concept maps to identify correct inclusions of concepts and links based on the resources that were provided to the students. Table 1 shows the average concept map scores by condition for the two phases of the study. Students who taught developed more complete and interconnected concept maps than students who created maps for themselves. The differences in map scores are statistically significant (SRL > LBT, ICS; LBT > ICS; p < 0.05) in the main phase, and the difference between SRL and ICS persisted during the transfer phase. 
 Table 1. Concept map score: main and transfer phases. 
 We also performed preliminary analyses of students’ behavior sequences to shed light on their learning processes [1]. We found that students who generated better concept maps used balanced learning strategies: they read resources, built and edited their concept maps, asked queries to probe the correctness of their maps, and used quiz questions in equal measure to learn about the domain. On the other hand, students who generated low scoring concept maps adopted a myopic learning strategy that overly focused on getting their quiz answers correct. They relied mostly on the quiz questions, and did not seem to read resources or probe their maps by asking queries very often. 
 1.4 Model Selection.
 To investigate this relation between learning performance and the use of strategies by group, it became important to go beyond frequency counts or proportions of individual activities, and examine how these activities came together as larger behavior patterns and strategies. To this end, we found the hidden Markov models (HMMs) to be the most ap- propriate, as they allow us to identify some of the students’ general behavior patterns from sequences of their interactions with the system.. 
 2 A Data Mining Approach to Analyzing Student Behaviors.
 Our approach to analyzing student behaviors in the main and transfer phases of the study involves four steps that appear in most data mining applications [12]: (i) devise a logging system that records student interactions with the system; (ii) perform data cleaning by parsing the generated log files and splicing the information into desired activity sequence data that will form the input to the HMM generating algorithm; (iii) construct the HMM models; and (iv) interpret generated models as student learning behaviors and compare models across conditions. We describe each of these steps in greater detail below. 
 2.1 Generating the Raw Data: The Logging System.
 The raw data corresponds to actions performed by students on the system and the res- ponses provided by Betty and the mentor agent. The agents and the student interact by communicating through the system environment agent. For example, if the student asks Betty a question, the request is broadcast to the environment agent, who routes it to other agents. The left side of Fig. 2 illustrates the message passing that takes place in the sys- tem. The signal first broadcast to the environment agent is routed to the teachable agent, who makes a request to the environment agent to use the current concept map to answer the question. This raw data is then processed in real-time and stored in log files as shown in the right side of Fig. 2. At the end of a session, the logs are sent to a server and consol- idated into a session by session sequence for each student into a database. 
 Figure 2: Events and messages being turned to log files. 
 2.2 Parsing the Log Files.
 In this study, we derive students’ behavior patterns by analyzing the sequence of their in- teractions with the system over multiple sessions. To simplify the interpretation task we lumped analogous student actions into one aggregate activity. 
 Table 2: Student Activities and Related Actions. 
 For example, all of the map creation and modification activities, i.e., adding concepts and links, deleting concepts and links, and editing nodes and links, were combined into one aggregate activity called Edit Map (EM). All student activities were expressed as the eight activities summarized in Table 2. Examples of the resultant sequences are shown in Fig. 3 below. 
 Figure 3: Parsed Data for 3 students in session 1. 
 2.3 Constructing the HMMs.
 The first step in interpreting this behavior data was to generate hidden Markov models. A hidden Markov model consists of hidden states that are not directly visible, and are go- verned by three sets of parameters: initial probability vector π, transition probability ma- trix, A, and output probability matrix, B [7]. By representing concise models of student activity patterns, a hidden Markov model has the potential of providing us with a global aggregated view of how students approach the learning task [3]. The algorithm that constructs HMMs given a set of observation sequences derives an op- timal set of these parameters (π, A, B) that maximizes the likelihood of the input se- quences. Further, simpler models are easier to interpret (Occam’s razor principle), so we apply an algorithm developed by Li and Biswas [5] that uses the Bayesian information criterion (BIC) to trade off simplicity of the model against information provided by the model.  BIC, defined as log(L) – d/2log(N), uses the log likelihood of the model (log(L)), model size (d), and the number of observations (N)  to find the model that strikes a bal- ance between high likelihood and low complexity [5]. Finding the optimal HMM parameters from data is an optimization problem. Two com- mon iterative convergence optimization schemes are the Baum-Welch [7] and the seg- mental K-Means [4] algorithms. In this paper, we use the segmental K-Means algorithm in conjunction with BIC for iterative segmentation and optimization steps to achieve the optimal model parameters, which include (π, A, B) and the number of states in the model, d. The segmentation step uses the Viterbi algorithm for sequential decoding, while the optimization step finds a new set of model parameters as dictated by the K-Means me- thod [4].  A chief advantage of the K-Means algorithm is its faster execution time gained by setting a restricted optimization objective. In the future, the faster speed may allow on- line computation of the behavior models to provide guided feedback as the student works on the system. A concern, however, for the segmental K-Means algorithm is the likelihood of its con- vergence to local maxima. In this work, we ran the algorithm one hundred times with random initializations (by sampling the initial parameter values from uniform distribu- tions), all of which converged to the same configuration. We also compared the BIC values generated by the Baum-Welch and the segmental K-Means algorithms, and found that the K-Means algorithm produced consistently better results (see Fig. 4). While these empirical results do not conclusively dispel the fact that our solutions may converge to local maxima, they nevertheless show the algorithm to be quite robust. The parsed activity sequences were used to derive two sets of three hidden Markov mod- els for the three conditions using the above algorithm. 
 3 Analysis of the HMMs.
 The behavior sequence models for the ICS, LBT, and SRL groups in the main and trans- fer study created using our HMM algorithm are shown in Fig. 5. Each model is made up of a set of states, the activity patterns (the output probability) associated with each state, and the transition probabilities between states. For example, the model predicts that students in the ICS condition RQ(75%)CE(25%) state requested the quiz 75% of the time, and asked for a continued explanation 25% of the time. The transition probability associated with a link between two states indicates the likelihood of the student transitioning from the current state to the indicated state. For example, the HMM model states student in the ICS condition in state RQ(75%)CE(25%) of the main phase would demonstrate an 6% likelihood of transition- ing to state EM, a 19% likelihood of remaining in the same state, and 71% likelihood of transitioning to state QT. Likelihoods less than 2% were not represented in the figure, ex- plaining why these numbers do not sum to 100%. HMMs are so named because their states are hidden. That is, they are not directly observed in the input sequences, but pro- vide an aggregated description of the students’ interactions with the system. Sequences of states may be interpreted as the students’ learning behavior patterns. We investigate fur- ther by interpreting these models in terms of cognitive learning behaviors of the students. In looking at these HMMs, we find several interpretable patterns that present themselves through high intrastate transition probabilities and low interstate transition probabilities. For example, we see that the transition probabilities from states with Request Explanation (RE) to Continue Explanation (CE) are strong (≥49%). Also, we see that these states are quite isolated, as the transition probabilities into these two states from other states are typically small (only 7% in the transfer SRL model). We combine these observations with knowledge of patterns relevant to interactive metacognition to find three patterns: basic map building, map probing, and map tracing [3]. Basic map building is a pattern characterized by editing the map, submitting the map for a quiz, and occasionally referring to the reading resources. The pattern reflects a basic and important metacognitive strategy. Students work on their maps, check the map by taking a quiz to see if there are flaws, and occasionally refer to the readings. Map probing is defined by students asking questions of their map to check for specific re- lations between two concepts (e.g., if fish increase, what happens to algae?). This pattern exhibits a more proactive, conceptually driven strategy, because students are targeting specific relations rather than relying on the quiz to identify errors. Students also need to formulate their own questions to do so. 
 Figure 4: K-Means and Baum-Welch-generated BIC values for the ICS Model. 
 Figure 5: HMM Models for the three conditions in the main and transfer phase. 
 Map tracing pattern reflects students asking Betty or the mentor (depending on the sys- tem) to explain the reasoning step by step.  When Betty or the mentor initially answers a question, they state that a change in one entity causes a change in another entity and high- light the paths they followed to reach their answer.  To follow the details of the inference chain, students had to ask Betty or the mentor agent to explain their reasoning. The agents did so by hierarchically decomposing the chain of inference; for each explanation request, they showed how a particular path within the larger chain contributed to the final answer. Receiving more details about the reasoning process is particularly useful when maps become complex, and there are multiple paths between two concepts. To build reduced versions of HMMs that incorporate these patterns, we first built aggre- gate states that represented the patterns of its individual behaviors. For instance, Edit Map, Request Quiz, Quiz Taken, Quiz Denied, and Resource Access were combined into the basic map building state; Ask Query was treated as map probing state; and Request and Continue Explanation were combined into a map tracing state. The transitions were then constructed in accord to a proportional weighing of the individual behavior’s statio- nary probabilities. 
 3.1 Initial Analysis.
 Our preliminary analysis consisted of examining the prevalence of each behavior in the resultant stationary probabilities. The derived stationary probability values are listed in Table 3. In a sense, this analysis is equivalent to the frequency count analysis that we have performed in other studies [3], and indicates an estimate of the relative time spent in each state. Similar results in both studies help to validate our methods and results. 
 Table 3: Grouped Stationary Probabilities. 
 In the main phase, we see that the differences in stationary probabilities among the groups are quite pronounced. For example, we see that there exists a significant drop-off in the probabilities of the students’ edit map behaviors between successive conditions. Meanwhile, we see proportional increases in activities belonging to higher-level patterns, such as requesting explanation, and continuing explanation. The students’ use of continue explanation is especially pronounced. In the transfer phase when the students operate in a common environment, we see that the differences become smaller. In all three groups, we see a great spike in the number of re- source accesses relative to the main phase. At the same time, we observe a decrease in the occurrence of some of the higher-level patterns. This may be due to the students learning about a new domain with a simpler expert map that contains fewer interdependences be- tween concepts, and being given few sessions than in the main phase (five versus seven). This also could be due to the students internalizing the reasoning mechanism, therefore, a reduced need to perform such activities in the transfer phase [3]. 
 3.2 Analysis of the HMM Patterns.
 Our next level of analysis consisted of examining the interactions among the metacogni- tive states and their transitions in our models (Fig. 6). These interactions inform us about students’ typical learning behavior patterns by condition that we have identified. In the main phase, we find that the students in the ICS group tend to stay mainly in the basic map building state, while the SRL students tend to stay more in the higher-level states once they get there. For example, the self-loop vector for the map tracing state is much larger in the SRL group (23%) than in the ICS or the LBT groups (9% and 5% per- cent, respectively). Also, while the differences between ICS and LBT seem to be small, the ICS students seem spend most of their effort in basic map building, while the LBT students do spend a little more time in map probing, a higher level metacognitive activity. In the transfer phase, the difference between the ICS and the LBT group becomes harder to discern. However, like the main phase, the LBT students seem more likely to enter map tracing state than the ICS students (5% as opposed to 3%), but are more likely to leave once they get there. However, unlike in the main phase, the LBT students now seem to be more confined to the basic map building state than the ICS students (83% as opposed to 81%). However, the SRL students still perform more map probing than the other groups. 
 4 Conclusions and future work.
 Our data mining approach to building HMM models of student behaviors from log files have been very revealing. They have helped us establish that learning by teaching pro- vides better opportunities for learning even among 5th grade students. Further, metacogni- tive prompts while learning enable students to develop higher level learning strategies that they retain even when the feedback prompts are removed. In the future, we will fur- ther refine our data mining techniques and algorithms to set up a framework for designing adaptive learning environments, where the learning support and feedback provided to students will be guided by the information derived from the student behavior models. We will also work further towards developing a more quantitative way of analyzing and comparing the models (these may involve using distance metrics and more comprehen- sive cognitive learning patterns). 
 Figure 6: HMM Patterns showing ICS, LBT and SRL behaviors in the main and transfer study. 
 Acknowledgements.
 This work has been supported by a Dept. of Education IES grant #R305H060089 and NSF REESE Award #0633856. The authors wish to acknowledge the help provided by John Wagster and Rod Roscoe in the data collection, data analysis, and data interpretation tasks.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Mining Student Behavior Models in Learning-by-Teaching Environments</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/hogyeong-jeong"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/hogyeong-jeong"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/gautam-biswas"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/gautam-biswas"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/226/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/hogyeong-jeong"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/gautam-biswas"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/227">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Do Students Who See More Concepts in an ITS Learn More?</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/227/authorlist"/>
		<swrc:abstract>Active engagement in the subject material has been strongly linked to deeper learning. In traditional teaching environments, even though the student might be presented with new concepts, it is possible for the student to remain passive to such an extent that it is detrimental to learning. This research explores whether experiencing new concepts in an ITS necessarily equates to learning. Initial analysis of data mining student models in SQL-Tutor, a CBM tutor, shows a strong positive correlation between the number of constraints seen and the number of constraints learned. This global trend is mitigated at an individual level, possibly due to individual differences in learning style and behavior. The number of constraints not learned remains relatively constant for all students; however, the proportion of constraints not learned is inversely proportional to the constraints seen. The author suggests deeper analysis into the factors that might cause variability amongst individuals from this population trend.</swrc:abstract>
		<led:body><![CDATA[]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Do Students Who See More Concepts in an ITS Learn More?</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/moffat-mathews"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/moffat-mathews"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/tanja-mitrovic"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/tanja-mitrovic"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/227/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/moffat-mathews"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/tanja-mitrovic"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/228">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>An open repository and analysis tools for fine-grained, longitudinal learner data</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/228/authorlist"/>
		<swrc:abstract>We introduce an open data repository and set of associated visualization and analysis tools. The Pittsburgh Science of Learning Center’s “DataShop” has data from thousands of students deriving from interactions with on-line course materials and intelligent tutoring systems. The data is fine- grained, with student actions recorded roughly every 20 seconds, and it is longitudinal, spanning semester or yearlong courses. Currently over 110 datasets are stored including nearly 18 million student actions. Most student actions are “coded” meaning they are not only graded as correct or incorrect, but are categorized in terms of the hypothesized competencies or knowledge components neede to perform that action. Researchers have analyzed these data to better understand student cognitive and affective states and the results have been used to redesign instruction and demonstrably improve student learning.</swrc:abstract>
		<led:body><![CDATA[ 1. 
 Figure 1. An example problem, “Making Cans”, from Carnegie Learning’s Cognitive Tutor 2005. 
 In the “Making Cans” example shown in Figure 1, a student completes a problem where she is asked to find the area of a piece of scrap metal left over after removing a circular area (the end of a can) from a metal square. The student enters everything in the worksheet except for the row labels, and column and ‘Unit’ labels for the first three columns.  In addition to providing students with feedback and instruction, the tutor records the student’s actions and tutor responses, and stores them in a log file, which is imported and analyzed by DataShop. The DataShop logging format differs from existing standard formats in that it attempts to capture student-tutor interaction history at a fine-grained level, while also providing context for such interactions; the format does not attempt to describe, a priori, learning resources and how they’re transferred (e.g., LOM, SCORM) or test content (e.g., IMS- QTI). In this way, the format is essentially descriptive, not prescriptive. The DataShop logging model is represented by the following constructs [16]: • Context message: the student, problem, and session with the tutor • Tool message: represents an action in the tool performed by a student or tutor • Tutor message: represents a tutor’s response to a student action Below we see example context, tool, and tutor messages in the DataShop XML format. In this example, the student attempted problem “MAKING-CANS” in the “PACT- AREA” lesson of the Geometry tutor.  Looking at the tool and tutor message pair, we see the student correctly entered “200.96” as the answer. Tool and tutor messages are traditionally paired with each other (by context message), allowing DataShop to interpret the student action and the tutor’s response in conjunction.  These pairs are then stored as a single tutor transaction in the database.  Table 1 below illustrates how actions from the Making Cans example are interpreted and stored as tutor transactions. A tutor transaction stores details such as the student(s), session, time, problem, problem subgoal (step), attempt number, student input, tutor response, number of hints, conditions assigned to the problem step, as well as knowledge components (skills).   Unpaired tool messages can be used to represent untutored actions, such as a student starting audio playback, and are stored in the repository as well. 
 Table 1. A simplified tutor transaction excerpt from the “Making Cans” example. 
 Multiple tool and tutor messages are typically logged for a single problem-solving activity.  Problem-solving activity is broken down into “steps” which represent completion of possible subgoals or pieces of a problem solution.  Students often make multiple attempts at a step or get instructional help on a step and each of these attempts or help requests are stored as a separate tutor transaction in the database. In the “Making Cans” example, we see the student attempted the “(SCRAP-METAL- AREA Q1)” step three times (transaction numbers 2, 3 and 6 in Table 1).  We can ascertain from the transactions that the student was unsuccessful in her first two attempts, providing an answer of “32” and “4”, both labeled as incorrect by the tutor.  On the third attempt, the student successfully completed the problem step, providing an input of 13.76 (as can be seen in Figure 1). To allow for fast and easy visualization and analysis of data, tutor transactions are aggregated into a student-step rollup table.  This “denormalized” table aggregates steps by student, problem, and step and is used by many of the DataShop tools, such as the Performance Profiler and Learning Curve.  An example of how the “Making Cans” tutor transactions are aggregated by student-step is depicted in Table 2. The student-step roll-up table stores an array of useful step information, some of which is depicted above.  In the “(SCRAP-METAL-AREA Q1)” step in the “Making Cans” example, we can see that the three tutor transactions are now rolled into a single step entry (line number 9 in Table 2).  “Opportunity count” is two since the student saw the “Compose-Areas” knowledge component twice.  “Total incorrects” is two, since she made two incorrect attempts.  “Assistance score”, which consists of total hints added to total incorrects, is two.  “Error rate”, whether the first attempt was an incorrect action or hint request, is 1 (or 100%) because the student’s first attempt was an error. 
 Table 2. Data from the “Making Cans” example, aggregated by student-step. 
 Each step in a problem requires the student to know something—a relevant concept or skill—to perform the step correctly. This small unit of knowledge is termed a “knowledge component”, a key notion in the PSLC’s theoretical framework (learnlab.org/research/wiki). To document this required concept or skill, a tutor author labels steps with a hypothesized knowledge component(s) required for correct completion of the step.  In the “Making Cans” example, we see the knowledge component “Compose-Areas” assigned to the correct transaction (row 6 of Table 1) for the “(SCRAP-METAL-AREA Q1)” step. A knowledge component codes for a general student capability to accomplish steps in tasks.  Knowledge component modeling, the process of assigning knowledge components to steps, bolsters the usefulness of intelligent tutor data by providing additional context for a step.   A step can have zero, one or multiple knowledge components associated with it.  Steps that have assigned knowledge components are used to produce a variety of “learning curves”.  Figure 2 below depicts error rate learning curves generated by DataShop. In this graph, error rate, or the percentage of students that asked for a hint or made an incorrect attempt on their first attempt on steps associated with the knowledge component, is shown on the y-axis. The x-axis (“Opportunity”) indicates the nth time (e.g., 4 is the 4th time) a student has (in theory) used (or tutored on) a knowledge component to solve a step in a problem. Each unique step in a problem is distinct from other problem-solving steps. For example, in Table 2, “(POG-AREA Q1)” and “(POG- AREA Q2)” are unique steps—they correspond to different questions in problem. Because they both exercise the “Circle-Area” knowledge component, they are counted as distinct opportunities for the student to demonstrate whether he or she has learned “Circle-Area” (and if not, get instruction on it). 
 Figure 2. Error Rate Learning Curve with predicted values from a Geometry Area dataset. 
 The solid curve represents the actual values, each point an average across all students and knowledge components for the given opportunity.  The dashed curve represents the predicted curve values, based on the Learning Factor Analysis (LFA) algorithm [5]. Built-in statistical models measure student proficiency, knowledge component difficulty, and knowledge component learning rates. This algorithm allows for search and comparison of alternative knowledge component or cognitive models.  DataShop supports users in entering multiple hypothesizes about how student knowledge and learning may be decomposed. 
 2.2 Importing and Exporting Learning Data.
 Data may be imported into the DataShop repository through XML or a tab-delimited text file format.  Logging to DataShop XML provides the richest and most complete data.  If logging via XML, tutors can send messages directly to the DataShop logging server in real time.  Logs are automatically processed on a nightly basis, making them available for analysis or export through the web application.  Alternatively, a computer tutor can write XML to files on the local hard disk (for example, if the tutor is running off-line) and then send the data to the logging server at a later time.  Data in a pre-existing log format can also be converted to DataShop XML and then imported into the repository.  This procedure has worked well for data collected by other tutoring systems including Andes (www.andes.pitt.edu), math Cognitive Tutors (carnegielearning.com), REAP (reap.cs.cmu.edu), and Assistments (assistment.org). The tab-delimited format of a transaction table can alternatively be used to import from a preexisting source. DataShop offers various data export options through the web application each delivered in a tab-delimited text file.  These include transaction and student-step level exports (as illustrated in Tables 1 & 2), and a student-problem aggregate export. 
 2.3 Analysis & Visualization Tools.
 The DataShop web application provides several tools to assist with analyzing and visualizing repository data.  These tools can be used in conjunction to jump-start data analysis: one can determine if students are learning by viewing learning curves, then drill down on individual problems, knowledge components, and students to analyze performance measures. The following DataShop tools are available: • Dataset Info: provides dataset metrics, contextual information, quick statistics (number of students, transactions, knowledge components, etc.) as well as papers, files, a problem table, and exporting and importing knowledge component models. • Performance Profiler: multi-purpose tool that visualizes student performance across various dataset-specific domains (problem, step, curriculum level, knowledge component and student) and measures of performance (error rate, assistance score, average number of incorrects, average number of hints, and residual error rate). • Error Report: presents each student’s first attempt at a problem or knowledge component, including if he or she was correct, the number of students or observations, and the text of the student’s answer. • Learning Curve: visualizes student learning changes over time.  Learning curve types include error rate, assistance score, correct step time, and others. The Learning Factors Analysis model [6] provides predicted values for error rate learning curves. 
 3 Uses of PSLC’s DataShop.
 As indicated above, many recent analyses of data from DataShop have been performed in a variety of domains.  A number of other studies have used, tested or extended the analysis techniques employed in DataShop including investigations in reading [10], Physics [12], and Geometry [15].  Often analyses have been targeted at finding ways to improve student learning.  In some cases, the work has been taken full circle such that an analysis led to an instructional redesign that was demonstrated to improve student learning beyond that realized by the original instruction. We provide a couple examples. Cen, Junker, and Koedinger [6] performed a learning curve analysis using the Learning Factors Analysis (LFA) algorithm based on data from the Area unit of the Geometry Cognitive Tutor.  They noticed that while students were required to over-practice some easy target knowledge components or skills (see square-area in Figure 2), they under- practiced some harder skills (see trapezoid-area in Figure 2).  Based on observation and further analysis, they created a new version of the geometry tutor by resetting parameters that determine how often skills are practiced.  They ran a classroom experiment where students in a course were pre- and post-tested and randomly assigned to use either the previous or the new tutor version.  Students using the new version took 20% less time to finish the same curriculum units (because over-practice was eliminated) and learned just as much as measured by normal, transfer, and long-term retention tests. A second demonstration of a datamining project that “closed the loop” is work by Baker et al. [3], who had done formal observations of student behavior in computer labs while working through lessons of a middle school math Cognitive Tutor.  Among a number of categories of off-task or otherwise disengaged behavior, he found that “gaming the system” had the largest correlation with poor learning outcomes.  Gaming refers to student behavior that appears to avoid thinking and learning through systematic guessing or fast and repeated requests for increasing help.  Baker used machine learning techniques to build a “detector” capable of processing student log information, in real time, to determine when students were gaming.  The detector became the basis for an intervention system, a “meta tutor”, designed to discourage gaming and engage students in supplementary instruction on topics they had gamed.  A controlled experiment demonstrated student-learning benefits associated with this adaptive selection of supplementary instruction for students observed to be gaming. 
 4 Discovering better cognitive and affective models of student learning. 
 An important general use of this kind of data is to drive the development of more precise computational models of human cognition, motivation, and learning. The work on gaming is just one example of using interaction log data to assess and remediate student motivation and other detectors of student engagement are possible. With respect to cognitive and learning assessment, we have been pursuing a strong hypothesis that the correct representation of knowledge (facts, skills, concepts, strategies, integrative models or schemas, meta-knowledge, etc.) in a domain is an empirical question.  Why is this a strong claim?   First, many do not believe knowledge is decomposable, for instance, Barab and Squire say “learning, cognition, knowing, and context are irreducibly co-constituted and cannot be treated as isolated entities or processes” [4].  Second, most designers of instruction, like textbook authors, assume that the instructional designers determine the knowledge decomposition, the target concepts and skills, and students learn these knowledge components as they are taught.  In contrast, the PSLC takes the position that the nature and grain size of mental knowledge representation is driven as much or more by the student and the explicit and implicit learning mechanisms in which they and their brains engage. Others, too, have emphasized that students do not learn knowledge in pieces as they are taught [7]. If the nature of human knowledge representation is an empirical question, then we need both vast and detailed educational data and associated data processing algorithms to answer this question for all domains of academic learning. In addition to the LFA technique mentioned above, which employs the “smooth learning curve” criteria [13], a number of algorithms have been created for empirically evaluating knowledge representations against student performance data including the rule space [18] and knowledge space [8] approaches.  The collection and use of on-line learning data will further drive such developments.  As noted in a major national report “psychometric validation of [on-line] assessments is needed so they can be compared with conventional assessments, and complement and ultimately supplant them” [1]. 
 5 Conclusion.
 We described PSLC’s DataShop, an open repository and web-based tool suite for storing and analyzing click-stream data, fine-grained longitudinal data generated by online courses, assessments, intelligent tutoring systems, virtual labs, simulations, and other forms of educational technology. In contrast to other types of educational data such as video and school-level data, data in DataShop includes a rich set of semantic codes that facilitate automated analysis and meaningful interpretation. The PSLC DataShop uniform data format is an initial attempt to develop a common standard that we hope will be useful to field if not as is, then in driving better or more useful common standards.  In addition to being a source for learning data, it is also a place where researchers can deposit data and then get help from other researchers who can perform secondary analysis on this data. DataShop allows free access to a wide variety of data sets and analysis tools.  These tools help researchers visualize student performance, difficulties, and learning over time.  Such analyses can lead to demonstrably better instructional designs.  The data can also drive improved models of student cognition, affect, and learning that can be used to improve on-line assessment and on-line learning. We take as a premise that the human brain constructs knowledge based a variety of input sources (e.g., verbal, visual, physical) and in a fashion and at a grain size that may or may not conform to the structure as conceived by an instructor or domain expert.  In other words, the nature and content of human knowledge representation is a deep and important scientific question, like for instance, the nature of the human genome.  To answer this question requires a vast collection of relevant data, associated analysis methods and new theory. 
 Acknowledgement.
 Research supported by the National Science Foundation award number SBE-0354420.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>An open repository and analysis tools for fine-grained, longitudinal learner data</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/kyle-cunningham"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/kyle-cunningham"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/alida-skogsholm"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/alida-skogsholm"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/brett-leber"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/brett-leber"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/228/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/kyle-cunningham"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/alida-skogsholm"/>
		<rdf:_4 rdf:resource="http://data.linkededucation.org/resource/lak/person/brett-leber"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/229">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Mining the Student Assessment Data: Lessons Drawn from a Small Scale Case Study</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/229/authorlist"/>
		<swrc:abstract>In this paper we describe an educational data mining (EDM) case study based on the data collected during the online assessment of students who were able to immediately receive tailored and elaborated feedback (EF) after answering each of the questions in the test. Our main interest as domain experts (i.e. educators) is in studying (by employing any kind of analysis) how well the questions in the test and the corresponding EF were designed or tailored towards the individual needs of the students. The case study itself is aimed at showing that even with a modest size dataset and well-defined problems it is still rather hard to obtain meaningful and truly insightful results with a set of traditional data mining (DM) approaches and techniques including clustering, classification and association analysis.</swrc:abstract>
		<led:body><![CDATA[]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Mining the Student Assessment Data: Lessons Drawn from a Small Scale Case Study</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/mykola-pechenizkiy"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/mykola-pechenizkiy"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/toon-calders"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/toon-calders"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/ekaterina-vasilyeva"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/ekaterina-vasilyeva"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/p-de-bra"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/p-de-bra"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/229/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/mykola-pechenizkiy"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/toon-calders"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/ekaterina-vasilyeva"/>
		<rdf:_4 rdf:resource="http://data.linkededucation.org/resource/lak/person/p-de-bra"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/230">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Mining Data from an Automated Grading and Testing System by Adding Rich Reporting Capabilities</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/230/authorlist"/>
		<swrc:abstract>Programs that perform automated assignment grading can generate a great deal of meaningful data not only for the student, but for the instructor as well.  Such tools are often used in computer science courses to assess student programming work. In the process of grading, a large amount of intermediate information is gathered. However, in most cases this information is not used beyond assigning scores, so the potential of learning more about the course is lost. At the same time, continuous collection of data over a large number of submissions across many courses presents an interesting but untapped resource for educational data mining.  One solution to this problem is to implement a reporting tool for making use of this intermediate data to create meaningful interpretations. This paper describes how an automated grading system, Web- CAT, has been extended to provide a reporting mechanism that uses the intermediate data that is gathered during assessment of students’ programs. Our implementation of the reporting tool makes use of the Business Information Reporting Tool (BIRT) developed for the Eclipse IDE.</swrc:abstract>
		<led:body><![CDATA[]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Mining Data from an Automated Grading and Testing System by Adding Rich Reporting Capabilities</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/anthony-allevato"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/anthony-allevato"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/matthew-thornton"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/matthew-thornton"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/stephen-h-edwards"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/stephen-h-edwards"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/manuel-a-perez-quinones"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/manuel-a-perez-quinones"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/230/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/anthony-allevato"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/matthew-thornton"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/stephen-h-edwards"/>
		<rdf:_4 rdf:resource="http://data.linkededucation.org/resource/lak/person/manuel-a-perez-quinones"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/231">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Data Mining Algorithms to Classify Students</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/231/authorlist"/>
		<swrc:abstract>In this paper we compare different data mining methods and techniques for classifying students based on their Moodle usage data and the final marks obtained in their respective courses. We have developed a specific mining tool for making the configuration and execution of data mining techniques easier for instructors. We have used real data from seven Moodle courses with Cordoba University students. We have also applied discretization and rebalance preprocessing techniques on the original numerical data in order to verify if better classifier models are obtained. Finally, we claim that a classifier model appropriate for educational use has to be both accurate and comprehensible for instructors in order to be of use for decision making.</swrc:abstract>
		<led:body><![CDATA[ 1.  Moodle Data Mining Tool executing C4.5 algorithm. 
 In order to use it, first of all the instructors have to create training and test data files starting from the Moodle database. They can select one or several courses and one Moodle table (mdl_log, mdl_chat, mdl_forum, mdl_quiz, etc.) or create a summary table (see Table 1). Then, data files will be automatically preprocessed and created. Next, they only have to select one of the available mining algorithms and the location of the output directory. For example, in Figure 1, we show the execution of the C4.5 algorithm over a summary file and the decision tree obtained. We can see that the results files (.tra and .test files with partial results and .txt file with the obtained model) appear in a new window (see Figure 1 down  in the right hand corner). Finally, instructors can use this model for decision making concerning the suitability of the Moodle activities in each specific course and also to classify new students depending on the course usage data. 
 4 Experimental Results.
 We have carried out some experiments in order to evaluate the performance and usefulness of different classification algorithms for predicting students’ final marks based on information in the students’ usage data in an e-learning system. Our objective is to classify students with equal final marks into different groups depending on the activities carried out in a web-based course. We have chosen the data of 438 Cordoba University students in 7 Moodle courses (security and hygienee in the work, projects, engineering firm, programming for enginnering, computer science basis, applied computer science, and scientific programming). Moodle (http://moodle.org) is one of the most frequently used free Learning Content Management Systems (LCMS). Moodle keeps detailed logs of all activities that students perform in a data base. Information is available about the use of Moodle activities and resources (assignments, forums and quizzes). We have preprocessed the data in order to transform them into a suitable format to be used by our Moodle data mining tool. First, we have created a new summary table (see Table 1) which integrates the most important information for our objective (Moodle activities and the final marks obtained in the course). Using our Moodle mining tool a particular teacher could select these or other attributes for different courses during the data preprocessing phase. The Table 1 summarises row by row all the activities done by each student in the course (input variables) and the final mark obtained in this course (class). 
 Table 1.  Attributes used by each student. 
 Secondly, we have discretized all the numerical values of the summary table into a new summarization table. Discretization divides the numerical data into categorical classes that are easier for the teacher to understand. It consists of transforming continuous attributes into discrete attributes that can be treated as categorical attributes. Discretization is also a requirement for some algorithms. We have applied the manual method (in which you have to specify the cut-off points) to the mark attribute. We have used four intervals and labels (FAIL: if value is <5; PASS: if value is >=5 and <7; GOOD: if value is >=7 and <9; and EXCELLENT: if value is >=9). In addition, we have applied the equal-width method [13] to all the other attributes with three intervals and labels (LOW, MEDIUM and HIGH). Then, we have exported both versions of the summary table (with numerical and categorical values) to text files with KEEL format [1]. Next, we have made partitions of whole files (numerical and categorical files) into pairs of training and test files. Each algorithm is evaluated using stratified 10-fold cross- validation. The dataset is randomly divided into 10 disjointed subsets of equal size in a stratified way (maintaining the original class distribution). In each repetition, one of the 10 subsets is used as the test set and the other 9 subsets are combined to form the training set. In this work we also take into consideration the problem of learning from imbalanced data. We say data is imbalanced when some classes differ significantly from others with respect to the number of instances available. The problem with imbalanced data arises because learning algorithms tend to overlook less frequent classes (minority classes), paying attention just to the most frequent ones (majority classes). As a result, the classifier obtained will not be able to correctly classify data instances corresponding to poorly represented classes. Our data presents a clear imbalance since its distribution is: EXCELLENT 3.89%, GOOD 14.15%, PASS 22.15%, FAIL 59.81%. One of the most frequent methods used to learn from imbalanced data consists of resampling the data, either by over-sampling the minority classes or under-sampling the majority ones, until every class is equally represented [3]. When we deal with balanced data, the quality of the induced classifier is usually measured in terms of classification accuracy, defined as the fraction of correctly classified examples. But accuracy is known to be unsuitable to measure classification performance with imbalanced data. An evaluation measure well suited to imbalanced data is the geometric mean of accuracies per class (g-mean), defined as 
 FORMULA_1.
 
 where n is the number of classes, hitsi is the number of instances of class i correctly classified and instancesi is the number of instances of class i. In our work, we have used random over-sampling, a technique consisting of copying randomly chosen instances of minority classes in the dataset until all classes have the same number of instances, and we use the geometric mean to measure the quality of the induced classifiers. Finally, we have used three sets of 10-fold data files: the original numerical data, the categorical data and the numerical rebalanced data. We have carried out one execution with all the determinist algorithms and 5 executions with the nondeterministic algorithms. In Table 2 we show the global percentage of the accuracy rate and geometric means (the averages of 5 executions for nondeterministic algorithms). We have used the same default parameters for algorithms of the same type (For example, 1000 iterations in evolutionary algorithms and 4 labels in fuzzy algorithms). We have used these 25 specific classification algorithms due to they are implemented in Keel software, but there are some other classification techniquess such as bayesina networks, logistic regression, etc. The global percentage of those correctly classified (global PCC) shows the accuracy of the classifiers (see Table 2). More than half of the algorithms obtain their highest values using original numerical data, and the other algorithms obtain them using the categorical data. This can be due to the nature and implementation of each algorithm which might be more appropriate for using numerical or categorical data. As we have seen above, it is easier to obtain a high accuracy rate when data are imbalanced, but when all the classes have the same number of instances it becomes more difficult to achieve a good classification rate. The best algorithms (with more than 65% global PCC) with original data (numerical) are CART, GAP, GGP and NNEP. The best algorithms (with over 65% global PCC) using categorical data are the two decision tree algorithms: CART and C4.5. The best algorithms (with over 60% global PCC) with balanced data are Corcoran, XCS, AprioriC and MaxLogicBoost. It is also important to note that no algorithm exceeds 70% global percentage of correctly classified results. One possible reason for this is due to the fact that we have used incomplete data, that is, we have used the data of all the students examined although some students who did not do all the course activities did do the final exam. In particular, about 30% of our students have not  used the forum or have not done some quizzes. But we have not eliminated these students from the dataset because it shows a real problem about the students’ usage level of e-learning systems. So, we have used all the data although we know that this fact can affect the accuracy of the classification algorithms. 
 Table 2.  Classification results (Global percentage of correctly classified / Geometric Mean). 
 The geometric mean tells us about the effect of rebalancing on the performance of the classifiers obtained, since the geometric mean offers us a better view of the classification performance in each of the classes. We can see in Table 2 that the behavior depends to a great extent on the learning algorithm used. There are some algorithms which are not affected by rebalancing (Kernel, KNN, AprioriC, Corcoran, AdaBoost and LogitBoost): the two decision tree methods (CART and C4.5) give worse results with rebalanced data (C4.5) but most of the algorithms (all the rest,  17 out of 25) obtain better results with the rebalanced data. Thus we can see that the rebalancing of the data is generally beneficial for most of the algorithms. We can also see that many algorithms obtain a value of 0 in the geometric mean. This is because some algorithms do not classify any of the students correctly into a specific group. It is interesting to see that it only happens to the group of EXCELLENT students (EXCELLENT students are incorrectly classified as GOOD and PASS students). But in education this is not very dramatic after all since the most important thing is to be able to distinguish perfectly between FAIL students and PASS students (PASS, GOOD and EXCELENT). On the other hand, in our educational problem it is also very important for the classification model obtained to be user friendly, so that teachers can make decisions about some students and the on-line course to improve the students’ learning. In general, models obtained using categorical data are more comprehensible than when using numerical data because categorical values are easier for a teacher to interpret than precise magnitudes and ranges. Nonetheless, some models are more interpretable than others: - Decision trees are considered easily understood models because a reasoning process can be given for each conclusion. However, if the tree obtained is very large (a lot of nodes and leaves) then they are less comprehensible. A decision tree can be directly transformed into a set of IF-THEN rules that are one of the most popular forms of knowledge representation, due to their simplicity and comprehensibility. So, C4.5 and CART algorithms are simple for instructors to understand and interpret. - Rule induction algorithms are normally also considered to produce comprehensible models because they discover a set of IF-THEN classification rules that are a high- level knowledge representation and can be used directly for decision making. And some algorithms such as GGP have a higher expressive power allowing the user to determine the specific format of the rules (number of conditions, operators, etc.). - Fuzzy rule algorithms obtain IF-THEN rules that use linguistic terms that make them more comprehensible/interpretable by humans. So, this type of rules is very intuitive and easily understood by problem-domain experts like teachers. - Statistical methods and neural networks are deemed to be less suitable for data mining purposes. This rejection is due to the lack of comprehensibility. Knowledge models obtained under these paradigms are usually considered to be black-box mechanisms, able to attain very good accuracy rates but very difficult for people to understand. However, some of the algorithms of this type obtain models people can understand easily. For example, ADLinear, PolQuadraticLMS, Kernel and NNEP algorithms obtain functions that express the possible strong interactions among the variables. Finally, in our educational problem the final objective of using a classification model is to show the instructor interesting information about student classification (prediction of marks) depending on the usage of Moodle courses. Then, the instructor could use this discovered knowledge for decision making and for classifying new students. Some of the rules discovered show that the number of quizzes passed in Moodle was the main determiner of the final marks, but there are some others that could help the teacher to decide whether to promote the use of some activities to obtain higher marks, or on the contrary, to decide to eliminate some activities because they are related to low marks. It could be also possible for the teacher to detect new students with learning problems in time (students classified as FAIL). The teacher could use the classification model in order to classify new students and detect in time if they will have learning problems (students classified as FAIL) or not (students classified as GOOD or EXCELLENT). 
 5 Conclusions.
 In this paper we have compared the performance and usefulness of different data mining techniques for classifying students using a Moodle mining tool. We have shown that some algorithms improve their classification performance when we apply such preprocessing tasks as discretization and rebalancing data, but others do not. We have also indicated that a good classifier model has to be both accurate and comprehensible for instructors. In future experiments, we want to measure the compressibility of each classification model and use data with more information about the students (i.e. profile and curriculum) and of higher quality (complete data about students that have done all the course activities). In this way we could measure how the quantity and quality of the data can affect the performance of the algorithms. Finally, we want also test the use of the tool by teachers in real pedagogical situations in order to prove on its acceptability. Acknowledgments. The authors gratefully acknowledge the financial subsidy provided by the Spanish Department of Research under TIN2005-08386-C05-02 projects. FEDER also provided additional funding.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Data Mining Algorithms to Classify Students</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/c-romero"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/c-romero"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/s-ventura"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/s-ventura"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/pedro-g-espejo"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/pedro-g-espejo"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/cesar-hervas"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/cesar-hervas"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/231/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/c-romero"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/s-ventura"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/pedro-g-espejo"/>
		<rdf:_4 rdf:resource="http://data.linkededucation.org/resource/lak/person/cesar-hervas"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/232">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Data-driven modelling of students' interactions in an ILE</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/232/authorlist"/>
		<swrc:abstract>This paper presents the development of two related machine-learned models which predict (a) whether a student can answer correctly questions in an ILE without requesting help and (b) whether a student’s interaction is beneficial in terms of learning. After presenting the rationale behind the development of these models, the paper discusses how the data collection was facilitated by the integra- tion of different versions of the ILE in realistic classroom situations. The main focus of the paper is the use of the ICS algorithm of WEKA to derive Bayesian networks which provide satisfactory predictions. The results are compared against decision trees and logistic regression. The application of these models in the ILE and how their potential educational consequences were taken into account are outlined followed by a discussion of future lines of research.</swrc:abstract>
		<led:body><![CDATA[ 1.1 Context.
 WaLLiS has been described in detail in [12] and in relation to other studies in [13]. Briefly, it is a web-based environment that hosts contents which include theory or example pages that present the material, as well as interactive and exploratory activities. The overall en- vironment of WaLLiS follows a design that is similar to systems referred to as advanced eLearning environments, as they combine features of content-based approaches with adap- tive educational strategies from Intelligent Tutoring Systems (ITS). Accordingly, apart from the usual components of the system that deliver the material and the tree-based navi- gation of the content (typical in many eLearning systems), WaLLiS incorporates a feedback frame at the bottom of the window where adaptive feedback is provided to the students. Despite the fact that several studies with the system established its effectiveness [12], some of the students are interacting with it in ways which are not necessarily beneficial to their learning. It is often the case that the approach followed in this kind of situations is to redesign the system in ways that will prevent any undesirable behaviour [3]. However, this may introduce new problems. For example, in early versions of WaLLiS hint and solution requests were not permitted without first attempting to answer the question. This however, led students to answer randomly just to ‘game the system’ [3] into allowing them to request hints or solutions. Similar results from designing preventative approaches are described in [14]. Even though newly introduced behaviours can always be dissuaded, as discussed in [3], this leads to an ‘arms race’ where students are developing harmful (in terms of their learning) behaviours and designers are trying to stop them. On the other hand, it seems that a measure of ‘desirable’ interaction could empower the system with an indication of the benefit of the interaction which could be used to guide feedback provision without repeatedly redesigning the system’s interaction model. In addition, related literature [7, 15, 19] and a combination of qualitative research and statistical analysis [11, 16] indicate that part of the evidence that human tutors employ, in order to diagnose student affective characteristics (e.g. confidence, effort), comes from students’ help-seeking behaviour and particularly help requests for items on which the tutors, based on the quality of previous interactions with the item under question, estimate that a student’s request for help is superfluous. This suggests that a first step in predicting affective characteristics and developing a model of beneficial interaction is to be able to predict if a student could answer correctly without any need for help. As already mentioned, rather than employing arbitrary models based on intuition, or even expert elicitation, the development of the models was data-driven. The assumption behind learning models from data is that differences in learning style, in affective charac- teristics and other preferences are reflected in students’ interactions with the system. 
 1.2 Datasets.
 The collection of as realistic data as possible was facilitated by the iterative design method- ology behind the WaLLiS project and the integration of the ILE in the teaching and learn- ing of various courses of the School of Mathematics of the University of Edinburgh and in particular, Geometry Iteration and Convergence (GIC); a second year module undertaken by honour students. With the lecturers’ agreement, the course was used as a means of conducting studies. Materials were developed for one of the last concepts taught in GIC; conic sections. The main reason for choosing this particular part of the course was that the materials taught were unknown to the students in advance and they constitute a rather individual unit. In addition, it was possible to establish indicators of prerequisite knowl- edge and opportunities to deliver part of the course solely through WaLLiS. Moreover, one of the activities (converting a conic section into its standard form), which is used for most of the analysis in relation to help-seeking and students’ performance, was presented using a different method from course textbooks. This helped establishing that any performance results are reasonably (if not solely) attributed to the interaction with the system and not other external factors. In particular, with the collaboration of the lecturer, certain questions on the students’ final exam were designed to test long-term retention. Following an iterative design and after several successful pilot tests, three datasets were particularly useful for the machine learning analysis described in this paper. GIC03 was the first dataset collected from a formal application of WaLLiS in classroom as the sole means of teaching conic sections. The main reason behind this data collection was to perform a qualitative analysis of the way students interact and perceive the system and not to fo- cus on learning outcomes. 126 students interacted with the system. GIC04 (133 students) and GIC05 (115 students) aimed particularly at collecting post-test results. Learning gains could be assessed by averaging (a) the students’ marks on an assessment they had to com- plete right after their interaction and (b) their mark on a specially designed final exam. It is evident that data collection under realistic conditions entails several challenges that result in ignoring some data, and it is worth mentioning them. Due to the way the datasets were collected (i.e. remotely over the net and not during a lab study), data can be quite noisy. The methods used for data-collection [10] are subject to bandwidth availability, appropriate security settings and other client and server-side concerns. In addition, some students did not give their consent for their data to be recorded. Data from students who did not attend the familiarisation session, and from others who have taken the course in the past were also ignored since their behaviour was quite different. After this data cleaning process the GIC03, GIC04, and GIC05 contain 106, 126 and 99 students respectively. 
 2 Predicting the necessity of help-requests.
 Knowing whether a student needs help or not in a given educational situation is quite complex. In the context of educational technology this information is particularly crucial for Intelligent Tutoring Systems (ITS) [1] and definitely not a unique issue to research here. Because of its complexity, different researchers address it in different ways depending on the special characteristics of the system under consideration and the overall context. For example, in the CMU tutors (e.g., [2]) the problem is approached as an attempt to estimate the probability that a skill has been mastered (knowledge tracing [6]). Similarly, [5, 9, 17] describe systems where Bayesian networks are used to predict students’ knowledge during their interaction. The approach presented here is different. The model predicts students’ necessity to ask for help on an item given their previous interaction and it is learned based on data of all students’ interactions with previous applications of the system in classroom. As discussed in the previous Section the GIC datasets were collected from studies where students have no previous knowledge of the material. Therefore, it does not seem too bold to assume that students who do not ask for help and answer a question correctly with the first attempt have learnt either from carefully reading the material in the system or from the interaction with the related items. In other words, all other characteristics of a student being equal, similar interactions should have enabled students to answer without the need for help. The opposite is not necessarily true as individual differences between students and affective characteristics influence whether a student requests help or not. Initial investigations with the GIC03 dataset as a learning set and the GIC04 as a testset, supported the claim that a machine learning algorithm (such as bayesian networks) could be used to automatically predict with reasonable accuracy whether a student’s help-requests are necessary. It was decided to focus the prediction only on help requests prior to the first attempt to answer a question. Further attempts are quite complex and depend on students’ understanding of the feedback, whether they read it or not and several other factors, which add noise to the prediction. Given the above assumptions and in order to learn a more accurate model from the data both the GIC03 and GIC04 datasets were used as a training set. In an attempt to have a simple model and a method that could be generalised to other courses of WaLLiS or other ILEs, only few aspects of the interaction were considered as features for the learning task. These should be available across courses in WaLLiS and are quite common in ILEs. Accordingly, vectors were constructed that contain the following variables: (a) time spent on related pages (trp) (b) time spent on attempt (tsa) (c) student previous knowledge (prev) (d) a rule-based measurement of the degree of ‘completeness’ of the goals of interactions on related pages1 (rel) (e) difficulty of the item (diff ) and (f) the type of the answer required (mcq, blank, matrix) (answertype). The boolean class learned represents whether the student seems to be able to answer correctly without any help. Its value therefore, is FALSE when students provided com- pletely wrong answers (not from the usual misconceptions), or answered wrongly very quickly2 demonstrating, in a sense, that they only answer in order to ‘game’ the system into providing feedback. The value of the class is TRUE when a student’s answer was cor- rect or partially correct. Students who asked for help without an attempt were not included since there are many explanations behind this request. Using these data for the machine learning would not necessarily provide additional instances that demonstrate whether a stu- dent really needed help or not. All the above restrictions resulted in a set of 1230 instances (the class of 429 of which was FALSE). The next step was to choose the exact modelling method. Preliminary investigations with cross-fold validation suggested that from all the approaches attempted (decision trees, Bayesian network, classification via regression) the Bayesian network and the decision tree were the most accurate ones with no significant differences. The Bayesian network (BN) approach was preferred mainly because the na- ture of the prediction is highly probabilistic. In addition, a BN is the perfect candidate for employing its outcomes in a larger evidence-based probabilistic framework. In WEKA [20], learning a BN is considered as a learning task of finding an appropriate classifier for a given dataset with a class variable and a vector of attributes [4]. The learning is a two stage process of first finding an appropriate network structure and then learning the probability tables. There are several approaches for learning the structure of the network. Conditional independence test based structure learning approaches stem from the need to uncover causal structure in the data [4] and consider the task as an attempt to learn a network structure that represents the independencies in the distribution that generated the data. 
 {1} This was based on intuition and expert knowledge elicitation from the course lecturer. 
 
 {2} The time to answer was discretized following a technique similar to the one presented in [8]. The number of breakpoints was chosen empirically in an attempt to maintain the proportionality of a normal distribution and the notion of the fuzzy linguistic variables (“very quickly”, “quickly” etc.). Accordingly, the breakpoint for “very quickly” was z <=−1.28. 
 Figure 1. Bayesian network predicting. 
 Figure 2. Accuracy, Kappa statistic and recall values for two different techniques. 
 Although directed edges in a network do not necessarily represent causal effects, the ICS algorithm [18] as implemented in WEKA [20] starts from a complete undirected graph for each pair of nodes, it considers subsets of nodes that are neighbours to the pair. If an independence is identified, the edge between the pair is removed from the network structure and the arrows are directed accordingly (i.e., from each node of the pair to the node that justified the removal of the link). In order to direct any remaining arrows, common sense graphical rules are applied (see [18] for details). The conditional independence tests of ICS left out the variable answertype from the model as irrelevant. Feature selection (FCBF [22]) also confirmed the relevance of all variables apart from answertype. The final model learned appears in Figure 1. To evaluate the result, the GIC05 dataset (with 590 instances) was employed as a testset (see accuracy report in Figure 2). Further investigation with the data showed that splitting them and considering a different model for every item improves the results substantially (an average of 68.367% accuracy for all items). The main reason behind this, is the fact that some of the variables do not play the same role in every item (for example, the influence of the related items page is not always the same on subsequent items) and therefore, one model cannot accommodate all the items. This process simplified the models considerably and therefore, these separate models were preferred for the actual implementation. After the implementation of the BN, further investigation with the data revealed that logistic regression is slightly more accurate in certain cases for predicting the need for help (on average it has accuracy 68.92% against the testset and for the model that combines all items 69.89%). Although, as in any model, further investigation and research could improve its accuracy, the model was considered adequate for implementation and further testing. The prediction was employed as a feature in subsequent research related to affec- tive characteristics (see [13]) and plays a particular role as a feature in the machine-learned model described in the next section. The application of the model and how the results could be improved and automated are further discussed at Section 4. 
 3 Predicting the benefit of students’ interactions.
 Similar to the prediction of unnecessary help-requests, the problem of measuring the bene- fit of students’ interactions in terms of learning is also quite complex and not unique to the research here. Consistent with the choices described in the previous section, the approach taken was to develop a model based on data from all students’ interactions with previous applications of the system, correlated with their answers in post-test questions linked to 
 Table 1. Features considered for learning the model of beneficial interaction. 
 1. Help frequency. 2. Error Frequency 3. Tendency to ask for help rather than risk an error ( help errors+help as defined in [21]) 4. No need for help but help requested (according to Section 2) (true/false) 5. Answertype - the type of the answer required (mcq, blank,matrix,checkbox) 6. Previous attempts in items related to the current skill 
 If this was the student’s first opportunity to practice this skill, −1. If no previous attempt was successful, 0. Otherwise, a measure of the degree of completeness of the goals of the related item (if there was no related item on the system the standardised score of their exam in the prerequisite of this skill) 
 7. Time in standard deviations off the mean time taken by all students on the same item. 8. Speed between hints – The Mahalanobis distance of the vector of times between hints from the vector of mean times taken by all students on the same hints and item3. 9. Accessing the related example while answering (true/false) 10. Self-correction (true/false) 11. Requested solution without attempt to answer (true/false) 12. Reflection on hints (defined as the time until next action from hint delivery) (calculated similarly to 8 using again the Mahalanobis distance). 13. The number of theoretical material lookups that the student followed when such a lookup was suggested by the system (-1 if no lookups were suggested) specific items in the system. In order to decide the features for the machine learning a combination of qualitative and exploratory analysis was performed (for details see [11]). 
 Based on the results and driven by the predictive power that similar features had in other related research (e.g., [1, 3]) the variables that appear in Table 1 were considered important. The boolean class learned represents whether a student answered correctly the related post-test question. To achieve a mapping between the actions in the system and the answers in the post-test question the answers are assessed across 4 basic skills that have a direct correspondence with the steps of questions in WaLLiS . In the cases where students did not answer parts of the questions, the missing answers are considered as wrong (i.e. the boolean variable is FALSE). In addition, in average 8 students in every dataset did not interact with certain steps or whole items in WaLLiS and therefore their data were excluded. In fact, most of these 26 students did not attempt to answer the post-test question and the few who did provided wrong answers. This resulted in 472 instances from GIC04, 352 from GIC05. For similar reasons as the ones described in the previous section, BNs were preferred. Informal comparisons with decision trees established that they had similar accuracy. 
 {3} The Mahalanobis distance is used in the place of the traditional Euclidean distance. It utilises group means and variances for each variable as well as the correlations and covariance of the data set. It is usually used as a metric to test whether a particular instance would be considered an outlier relative to a set of group data. Formally, the distance of a vector x = (x1,x2, . . . ,xn)T from another vector, y = (y1,y2, . . . ,yn)T is defined as FORMULA_1 where Σ is the covariance matrix. 
 Table 2. Variables after feature. 
 Table 3. Classification accuracy and Kappa statistic for Bayesian networks and tree induction to predict beneficial interaction. 
 Whilst implementing a model based on decision trees would have increased the flexibility when providing feedback, it is not clear if communicating to the students the reasons behind the ineffective interaction, would have any effect, particularly if one takes into account that in more than 30% of the cases the system could be wrong. In addition, in future implementa- tions, this prediction could be used as part of the evidence for a holistic framework. To learn the BN the ICS algorithm of Weka was employed again and to facilitate the algorithm’s search feature selection is also employed in advance to remove irrelevant and redundant features. Although (as expected) the same more or less accuracies and structure was learned over the complete set of features, simpler models are always preferred. In fact, the simplified model achieved better accuracy on a 10-fold cross validation check and slightly better accuracy on the test set. By removing redundant features the remaining ones were easier to comprehend. This allows a more sensible ordering of the variables, which can effect the search for the structure of the ICS algorithm. Finally, the process with feature selection was significantly faster. In this case, since all the analysis was performed offline, and the models were implemented prior to their integration with the system, this is not really relevant. However, if the techniques reported here are automated to enable the system to learn while more students work with it, online speed will become a more critical factor. The list of reduced variables is shown in Table 2 and the final model in Figure 3. Its accuracy report, as well as comparisons with decision trees are presented in Table 3. Logistic regression was tested again after the implementation of the BN. It provides an accuracy of 70.34% against the testset and although it not a significant improvement it is definitely worth considering in the future. The next section describes how the two models described were employed when redesigning WaLLiS and future work for improving them. 
 4 Application and Future Work.
 As discussed in the Introduction the necessity behind the development of the two models was established through qualitative research aiming to improve WaLLiS by taking into ac- count students’ affective characteristics. In particular, as presented in [13], the two models are interrelated as the prediction of the necessity of help requests appears in rules related to affective factors (particularly effort) but also the model of beneficial interaction seems to have the potential to model tutors’ decisions and feedback. 
 Figure 3. Bayesian Network for predicting beneficial interaction. 
 The immediate benefit of the two models was to empower the system with a measurement of desirable interaction on the basis of which feedback, interventions and suggestions for studying further material can be provided. The two models were implemented (using JavaBayes4) as part of a diagnostic agent the outcomes of which are taken into account by the system’s feedback mechanism in order to adapt its actions. Accordingly, when students are asking for suggestions on what to study next, the prediction of beneficial interaction is employed assisting the system to prioritise the available items for the student. In other cases students may have just completed an item but because of the way they interacted with it, the model predicts a low benefit of their interaction. The system then suggests they try the exercise again. The prediction is also employed when students are asking for sugges- tions within an item rather than a specific hint on a step. If the prediction is high, a positive comment is provided followed by an encouragement to complete the remaining items (if any) before moving on to the next activity. Otherwise, they are reminded of the goals of the exercise they are interacting with and are encouraged to complete the current item first. When requesting specific hints in steps, the prediction for the necessity of help-requests is used but it does not play a direct role. In other words, it does not prevent students for asking help but it plays an indirect role in the model of beneficial interaction. Future work will focus into improving the models. The separation of the models by items seems to be against the long-term goal of coming up with one model that could be used in other lessons. On the other hand, the methodology for building it can be used in other contexts especially if it is automated allowing the system to learn and improve itself while it is used rather than when offline. Also, it was discussed that logistic regression seems to provide better accuracy and therefore future work will investigate its implemen- tation. Logistic regression is not only more straightforward to implement but it can also provide the probabilistic framework needed to deal with the uncertain nature of the pre- dictions. In addition, it is worth observing that the prediction from the model of beneficial interaction can in its turn be used as a feature in the model for the necessity of help re- quests in the place of the rel variable thus avoiding the use of the subjective rule-based measurement and relying to the more valid model learned from data. The development of the models introduced a qualitatively different interaction. There- fore, future work will focus on evaluating the different decisions and the impact they may have in students’ learning. The design choices for the feedback mechanism are already influenced by the accuracy and the probabilistic nature of the prediction. As also discussed in [1, 3], The approach taken should not be too intrusive (e.g., interrupting students’ work in order to provide feedback) nor preventative (e.g., preventing them from asking help). In particular, if one takes into account that in around 30% of the cases the model could be wrong it is obvious, but paramount, to use these predictions in a way that has the least negative educational consequences. The question is how to strike a balance between an approach that utilises the predictions from the models in an informative way and a more preventative approach that may be required in some cases. In the cases where commu- nicating this information with the student becomes problematic, models such as the ones developed here could have other applications. For example, the prediction of the benefit of the interaction could be used in open-learner modelling or in classroom environments to provide useful information for teachers on the basis of which they can act. Finally, it is worth considering in more detail the evaluation of the models, since they influence the judgements on the validity of the results. In the case of the models presented here, an average of 70% was considered satisfactory because of the design choice in rela- tion to not following a preventative approach. A suggestion of repeating an exercise, even when given under false evidence, is probably not that problematic compared to not allowing students to request help just because the system thinks (sometimes wrongly) that their re- quest is superfluous. Therefore, in Educational Data Mining, it is worth taking into account the nature of the data and the ‘cost’ of true or false positives rather than evaluating them out of context. Given the availability of data that include students’ performance, future work will focus on taking more informed decisions about the models and the appropriate actions of the system in terms of being detrimental to students’ learning. Acknowledgments The work presented here is part of the author’s PhD research, partially funded by The University of Edinburgh. The author would like to thank Antony Maciocia for the general support throughout this research and in particular for the access to the GIC classrooms that made the data collection possible. Also, Ryan Baker and the members of the WEKA mailing list for discussions related to the data mining tools employed.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Data-driven modelling of students' interactions in an ILE</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/manolis-mavrikis"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/manolis-mavrikis"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/232/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/manolis-mavrikis"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/233">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Reinforcement Learning-based Feature Selection For Developing Pedagogically Effective Tutorial Dialogue Tactics</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/233/authorlist"/>
		<swrc:abstract>Given the subtlety of tutorial tactics, identifying effective pedagogical tactical rules from human tutoring dialogues and implementing them for dialogue tutoring systems is not trivial. In this work, we used reinforcement learning (RL) to automatically derive pedagogical tutoring dialog tactics. Past research has shown that the choice of the features significantly affects the effectiveness of the learned tactics. We defined a total of 18 features which we classified into four types. First, we compared five feature selection methods and overall upper-bound method seems to be most efficient. Then we compared the four types of features and found that temporal situation and autonomy related features are significantly more relevant and effective to tutorial decisions than either performance or situation related features.</swrc:abstract>
		<led:body><![CDATA[ 1. A Learned Policy Based On Five Features On KC22. 
 Based on the size of the exploratory corpus we collected in the first stage, we decided that no more than six features should be used. Previous research involving RL and feature selection in dialogue systems either focused on selecting features with certain characteristics [2,7,8] or investigated a relatively small number of features [10,11]. Therefore, in this study, we proposed four general RL-based feature selection methods. 
 2 Background.
 Past research on using RL to improve spoken dialogue systems has commonly used Markov Decision Processes (MDP’s). An MDP [8,9] describes a stochastic control process and formally corresponds to a 4-tuple (S,A,T,R), where S = {si}i=1..m, is a finite set of process states; A={ak}k=1..m is a finite set of actions; T : S × A × S → [0, 1] is a set of transition probabilities between states that describe the dynamics of the modeled system; for example: Pt(si|sj, ak) is the probability that the model would transition from state sj to state si by taking action ak at time t; and R : S × A × S → R denotes a reward model that assigns rewards to state transitions and models payoffs associated with such transitions. The goal of using MDPs is to determine the best policy π*: the set of actions the model should take at each state si to maximize its expected cumulative utility (V-value), which can be calculated from the following recursive equation: 
 FORMULA_1.
 As long as a proper state space, action space and reward function are set up, an MDP allows one to automatically derive and compute the best policy. For dialogue tutoring systems, deriving effective tutorial tactics from tutoring dialogues can be naturally cast in the MDP formalism: for the state space, each si can be viewed as a vector of features representing the tutoring dialogue context, the student’s knowledge level and so on. Action space corresponds to tutoring actions, e.g. elicit or tell; the reward function corresponds to students’ learning gains. For tutoring dialogues, the reward is a delayed reward because for each state the reward is not known until students have completed the tutoring and taken the post-test. In this work, we used an MDP package that was designed for Tetreault & Litman’s studies since it has proven to be both reliable and successful [10,11]. In previous studies, Tetreault & Litman primarily investigated methods for evaluating whether certain features would improve policy effectiveness. There are two main differences between our study and theirs: firstly, they used a previously collected corpus that was not exploratory with respect to tutorial tactics to train an MDP model in that the tutor often used only one type of action in many dialogue states, which severely limited the types of questions that they could investigate[10,11]; while we use a more exploratory corpus by training students on a dialogue tutoring system in which multiple actions can often be taken and random tactical decisions were made.  Thus it is better suited for creating an MDP. Secondly, they did not need to address the problem of general feature selection methods since they only used five features while we had to select up to six of 18. To evaluate the learned policies, we use three criteria: Expected Cumulative Reward (ECR) and lower-bound and higher-bound of the 95% confidence interval. ECR is the average reward one would expect in the MDP and it is calculated by normalizing the V-value of each state by the number of times it occurs as a start state in a dialogue and then summing over all states [11]. The confidence interval represents how reliable the ECR of a learned policy is [10]. The wider it is, the less reliable the policy’s ECR is. For example, for a learned policy A derived from feature 2 alone on definition of spring potential energy (KC22) is “if the percent of elicit so far is less than 49.82%, tutor should elicit otherwise the tutor should tell.”; A has ECR = 3.02 (range [-100, 100]) with a 95% confidence interval= [- 2.71, 8.45], which means there is a 95% chance that the ECR of the learned policy is between a lower-bound of -2.71 and an upper-bound of 8.45. In Figure 1, also on KC22 but involves five features: 1, 2, 4, 15 and 16. It has ECR = 44.29 with a 95% confidence interval= [23.49, 50.51], which is much more effective than policy A because even its lower-bound is much higher than policy A’s upper-bound. Sometimes we encounter situations in which the ECR for A is the same as for B; but the confidence interval of A is much narrower than that of B. By only using the three criteria described above, policy A and B cannot be compared. Therefore, we define the hedge of a learned policy as: 
 FORMULA_2.
 By using the hedge, we can say that policy A is better than policy B since the hedge of A is higher than the hedge of policy B. 
 3 Experiment.
 The domain chosen for this study is work and energy covered in college physics. The procedure was as follows students: (1) read a short textbook, which describes the major principles and concepts; (2) take a pre-test; (3) work through seven open-ended training problems with a dialogue tutoring system (Cordillera [14]);  and (4) take a post-test that is identical to the pre-test. In the stage one, 64 college students who had not taken any college physics completed the experiment, receiving payment for their participation. Students needed 8-15 hours to complete the procedures and usually required 4-6 sessions of about 2 hours each. Thus, the collected corpus comprises 64 human-computer tutoring dialogues and each dialogue is an extended interaction with one student that covers seven different college-level physics problems. The number of state- action pairs in each of the 64 collected tutorial dialogues varies from 700 to 900. All training problems, and all pre- and post-tests problems were selected from 127 quantitative and qualitative problems collected from various physics literature. In order to solve these 127 problems, 32 unique knowledge components (KCs) were identified as necessary. A KC is “a generalization of everyday terms like concept, principle, fact, or skill, and cognitive science terms like schema, production rule, misconception, or facet” [14]. For example, KC221 is both a concept and a principle while KC232 is a fact. KC22 consists of both procedural knowledge and declarative knowledge while KC23 is mainly declarative knowledge and thus learning these two KCs clearly involves different cognitive skills. Therefore, for different KCs, we expect that different features should be considered when making a tactical decision and different tactical decisions should be derived. In order to learn KC-specific tutorial tactics, students’ pre- and post-test scores were also calculated per KC. It turned out our training, pre- and post-problems covered 27 of the 32 possible KCs. Three of the 27 KCs showed up in the tutoring dialogue but were not associated with any action decision points; five KCs coincided only once or twice with decision points; and one KC did not appear in the pre- and post-tests. Therefore, we were left with 18 KCs for which it is possible for us to derive tutoring tactics. Comparisons of pre- and post-test scores indicated that students did learn during their training with Cordillera: their post-test scores were significantly higher than their pre-test scores: t(126)= 3.36, p= 0.001. Similar to Tetreault & Litman’s work, we used students’ normalized learning gains (NLGs) for each KCi as the delayed reward function, which is defined as: 
 FORMULA_3.
 {1} If an object and a spring are in a system, then their spring potential energy is 0.5* k*d^2, where k is the spring constant and d is the displacement of the object relative to the equilibrium position of the spring. {2} The unit for energy is the Joule. 
 For each KCi, the 64 students were split into two groups by the median value of their NLG on it, so the better-performing students’ dialogues were given a positive reward of +100, while the other half were assigned a negative reward of -100. The rewards were assigned in the final dialogue state. Additionally, we annotated our tutoring dialogues and action decisions based on which KCs a tutor action or tutor-student pair of turns covered; Table 1 shows an example. Here lines 1, 5, 6, 7, 9 and 11 are tutor turns, the action type and their target KCs are listed on the right. For example, in the first utterance is an elicit action regarding KC22 while the fifth is a tell action directly stating KC22. Lines 2 and 12 are student responses and they are both correct (as indicated by the ‘+’); row 2 is about KC22 while row 12 is about KC27. 
 Table 1. Examples of Tutorial Dialogue with KC Labels. 
 4 Methods.
 The four feature selection approaches we propose in this paper are fairly straightforward and share the same procedure, which consists of the three phases described below. Phase 1: For each of 18 features in the state space, use MDP to get a single- feature-policy. Phase 2: Sort all of the features based on the learned single-feature-policies from high to low by one of the following measures: – ECR – Lower-bound – Upper-bound – Hedge Phase 3: Start with the first feature in the sorted feature list, add one feature at a time to the MDP and learn a new policy.  Repeat this process repeat 5 times. Based on the sorting criteria in phase 2, we named our four feature selection methods: ECR, lower-bound, upper-bound, and hedge respectively. Since these values were calculated from the single-feature-policies learned using MDP in phase 1, the four methods are RL-based. We expect them to be more effective than a random selection. To test our expectations, we created 120 random policies by running the MDP package on randomly selected features (20 rounds for each randomly selected feature set, where each set contained between one and six features). Therefore, for each KC and each feature set size, we learned one tutoring tactic for each RL-based method plus 20 for random feature selection. This gave us (1*4+20)*6 =144 policies. For each KCi, we selected one policy that had the highest ECR, lower-bound and upper-bound from the 144 learned policies and named it the “best policy”. To quantitatively evaluate how much less effective a learned tutoring tactic is than the best policy, we defined a normalized ECR (NECR) for a learned tutoring tactic as: 
 FORMULA_3.
 Max_ECR(KCi) and Min_ECR(KCi) are the maximum and minimum ECR among all 144 of the learned policies for KCi. C is a constant with C=1 for each of the four RL-based methods and C=20 for random feature selection. The maximum NECR for a learned policy is 1 if the learned policy is the best one and the minimum is 0 if the learned policy is the worst one. 
 5 Results.
 In order to evaluate the feature selection methods and how the feature effectiveness, we have two main goals. First, we will compare the four RL-based feature selection methods against random feature selection; second we will investigate which features seem to be more important for deriving the best tutoring tactics for deciding to elicit/tell across all KCs. 
 5.1 Comparing four RL-based methods against random feature selection 
 Table 2. Comparing the Average NECR of Five Selection Methods for Increasing Feature Set Sizes. 
 NECR is defined as how much a learned tutoring tactics is less effective than the best policy. Table 2 shows the average NECR given the number of selected features and feature selection method across all 18 KCs. As expected, random feature selection has the worst average NECR regardless of the number of features involved. Overall, if the number of features ≤3, then the ECR approach is the best feature selection method; but if the number of features is between 4 and 6, then the upper-bound method is the best. As the number of features involved increases, the effectiveness of the learned policies for elicit/tell tends to become better, except for upper-bound, which has a better average NECR when there are five features than when there are six. Overall, using the upper-bound method to select five features seems to be the most effective method across all KCs on elicit/tell action decision. On the other hand, across all 18 KCs the number of times that each method found the best policy is: fourteen times for random, three for upper-bound, two for ECR, one for hedge and none for lower-bound method. The total did not add up to 18 KCs because for KC1, three methods, ecr, hedge, and upper-bound all found the same best policy. Therefore, although random feature selection has the worse average NECR than other four RL-based methods, it is an effective way to find best policies. However, note that the random feature selection method was repeated 120 times for each KC and so it has a total of 120*18=2160 chances to find the 14 best policies; while the upper-bound method was applied only 6 times for each KC and thus has a total of 108 chances. Additionally, because our state space is still relatively small, we expect that the performance of random selection would decrease significantly as the number of features in the state space increases. However, for the four RL-based feature selection methods, increasing the number of features would not decrease their effectiveness since they do not directly depend on the number of features in the state space. Moreover we compared the best policy learned for each KC by the upper-bound method and those learned by random selection. Over all 18 KCs, the upper-bound policies with just 108 attempts were only 9.46% less effective than random feature selection policies with 2160 attempts. These results indicate that that in education, features that may result higher learning gains should always be always be considered by the tutor when making decisions. This is likely due to the fact that in the worst case a student will simply not learn rather than lose information so the cost of incorporating superfluous feature is low.. 
 5.2 Frequency of Features in Best Policies. 
 Figure 2. The Frequency of Each Feature Shown In Best Policies. 
 Figure 2 shows the frequency with which each feature appears in the best policies.  This frequency differs significantly among the four feature types: F(3)= 7.47, p=0.003. There is no significant difference between the three autonomy and five temporal situation related features. When combined they are significantly more frequent than either the performance or situation related features: t(12)= 2.74, p=0.18 and t(10)= 4.26, p=0.002 respectively. Consistent with previous research based on analyzing human tutorial dialogue, autonomy related features seemed to be more relevant in deriving effective tutorial tactics. Additionally, we found that temporal situation related features were also relevant, even more so than the performance related ones when deciding whether to elicit or tell. This was not indicated in previous literature on human tutorial dialog analysis. One possible explanation for this was that in most of the prior literature, temporal situation related factors were often not considered. 
 6 Conclusions and Future Work.
 In this paper, we described our work on applying RL methods to derive effective tutoring tactics for elicit/tell. We showed that deriving effective tutoring tactics from tutoring dialogues can be cast in the MDP formalism. Additionally, we proposed four RL-based domain-general feature selection methods. We found the upper-bound method to be more effective than the others. One of our goals for future work is to investigate how to still get reasonable policies without annotating individual KCs in the dialogues. The annotation process is prohibitively time- consuming and it is not unusual for domain experts to disagree [14]. Another of our goals for future work is to determine how to learn one reasonable policy for all KCs without sacrificing too much of the expected effectiveness. Another two important issues are how to avoid the expensive initial data collection and how to combine the new data with the existing data so that we can learn even more powerful policies. 
 Acknowledgments.
 We would like to thank the NLT group and Diane J. Litman for their comments. Support for this research was provided by NSF grants #0325054.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Reinforcement Learning-based Feature Selection For Developing Pedagogically Effective Tutorial Dialogue Tactics</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/min-chi"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/min-chi"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/pamela-jordan"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/pamela-jordan"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/kurt-vanlehn"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/kurt-vanlehn"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/moses-hall"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/moses-hall"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/233/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/min-chi"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/pamela-jordan"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/kurt-vanlehn"/>
		<rdf:_4 rdf:resource="http://data.linkededucation.org/resource/lak/person/moses-hall"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/234">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>The Composition Effect: Conjunctive or Compensatory? An Analysis of Multi-Skill Math Questions in ITS</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/234/authorlist"/>
		<swrc:abstract>Multi skill scenarios are common place in real world problems and Intelligent Tutoring System questions alike, however, system designers have often relied on ad-hoc methods for modeling the composition of multiple skills. There are two common approaches to determining the probability of correct for a multi skill question: a conjunctive approach, which assumes that all skills must be known or a compensatory approach which assumes that the strength of one skill can compensate for the weakness of another skill. We compare the conjunctive model to a learned compositional function and find that the learned function quite nearly converges to the conjunctive function. We can confidently report that system designers can implement the AND gate to represent the composition function quite accurately. Cognitive modelers may be interested in the small compensatory effect that is present. We use a static Bayesian network to model the two hypotheses and use the expectation- maximization algorithm to learn the parameters of the models.</swrc:abstract>
		<led:body><![CDATA[ 1.1 About the ASSISTment tutoring system.
 ASSISTment is a web based tutoring and assessment system for 6th-10th grade math. The tutor started in 2004 in only a few 8th grade math classrooms and, in 2008,  is now used by 300-500 students per day. The items in the tutor are all based upon publically released state test problems from the Massachusetts Comprehensive Assessment System (MCAS). 
 1.2 About the Dataset.
 Our dataset was from logged student use of the ASSISTment system during the 2005-2006 school year in which 8th grade math students ages 13-14 answered questions on the tutor two or three times per month at their school’s computer lab. The students were given randomly chosen problems from a pool of around 300. The random selection of problems gave us a random sampling of skill data throughout the year. Our dataset contained 441 students with 46 average responses per student. Only a student’s first response to a question was considered. The number of single skill questions was 184 with 62 double skill questions and 16 triple skill questions. The majority of questions are text entry while the others are multiple-choice. We would like to note that skills were tagged to questions by subject matter experts from a skill set of 106 [10]. However, the number of skills that have data points is 84. Table 1 shows the attributes we have for each of the question responses and an example of what the response data looks like. 
 Table 1. Sample of the question response dataset. 
 1.3 Bayesian Networks.
 We used a static Bayesian model to represent skill tagging to question nodes and to make inferences on the probability of answering a given question correct or incorrect. Bayesian networks [9] is a powerful machine learning method that we used for making posterior inferences based on binary response data; 1 for correct 0 for incorrect. The EM algorithm [2] can be used with Bayesian networks to learn the priors of latent variables and the conditional probability tables (CPT) of random variable child nodes. Exact inference with Kevin Murphy’s Bayes Net Toolkit for MATLAB was used with EM to learn the parameters of the networks. Inferring the probability a student will answer a question correctly (Q=correct) is a function of the believed prior on the skill(s) associates with the item (S=known) together with the guess and slip parameters of the question. The equation is shown below: 
 FORMULA_1.
 A guess parameter dictates the probability that the student will get an item correct even if she does not have the required knowledge. A slip parameter dictates the probability that the student will get an item incorrect even if she has the required knowledge. Learning the general parameters of single and multi skill questions will tell us if questions with more skills are harder to guess. 
 2 The Conjunctive Model.
 The AND Gate Conjunctive model is the most common approach to skill composition in ITS. The principle behind it is that all skills involved must be known in order to answer the question correctly. The topology of this model is similar to a deterministic input noisy “AND” (DINA) model [7] except that our AND has no noise (no p-fail). The Bayesian belief network is represented by the directed acyclic graph in Figure 2. 
 Fig. 2 Directed acyclic graph representing the AND gate Bayesian topology. 
 The network consists of three layers of nodes with equivalence classes used to share conditional probability tables among nodes. This lets us learn a generalized guess/slip for all nodes of a given equivalence class instead of a parameter per node, which could not be accurately learned given the size of our dataset and would also not answer the research question of how multi skill questions differ from single skill questions. The first layer consists of latent skill nodes. All the skill nodes share a single equivalence class, this was done to simplify the EM procedure. The equivalence class learns a single prior for all skills but does not constrain the individual skill performance estimations from differing. The second layer consists of the AND gates which assert that all parent skills must be known in order for the child question to be answered correctly. The last layer consists of the question nodes. All single skill questions are grouped by an equivalence class. All double skill and triple skill questions have their own equivalence class as well. We will eventually be learning a total of three sets of guess/slip values and a prior. 
 2.1 Methodology.
 The way in which we will approach the research question “how much harder are multi skill questions” is by learning the conditional probability tables of the Bayesian network. By learning the parameters of our model we can observe how skill knowledge determines the probability of correct for a given question. How guess and slip vary with the number of skills involved is one way of investigating the composition effect. To learn parameters in the AND model we chose to learn the single skill guess and slip first. By learning these parameters first we can establish a baseline assumption for question guess and slip that is gathered from single skill question data that does not introduce the complex issue of credit- blame that comes in to effect with multi skill questions. The skills’ prior equiv class was set at 0.50 and the starting value of the single skill equiv class was set at ad-hoc values; 0.15 guess and 0.10 slip that have been used in previous conjunctive model work [8]. After the guess and slip parameters have been learned for the single skill equivalence class we move on to learning the double skill and triple skill equivalence classes at once. The single skill parameter values are locked in place and the prior is reset again to 0.50 before the second EM learning begins. After this second step completes we now have three sets of guess and slip values as well as a prior for the skills. 
 2.2 Results.
 The results from the AND model parameter learning shows that the probability of guess decreases linearly as the number of skills increases; from a 24.24% guess with a single skill questions down to a 16.06% guess with a 3 skill question as shown in Figure 3. Surprisingly the slip rate, or probability of making a mistake, also goes down as the number of skills increase. This suggests that while multi skill problems are more difficult to guess, they are also more difficult to slip on. 
 Fig. 3 Results of AND model parameter learning. 
 The difficulty of a problem can be described by the probability of answering the question correctly. However, the probability of answering a question correctly is dependent on the probability of knowing the skill or skills involved. Figure 4 shows how problem difficulty differs with skill knowledge for single, double and triple skill questions. Also note that the guess values from Figure 3 are the intercepts of the left most vertical axis in Figure 4 and the slip values are the right most vertical intercepts. Data for the Figure 4 graph was generated by setting the probability of all skill nodes to zero and then asking the Bayes net to infer the posterior probability of correct for a single, double and triple skill question and recording the results. All skill nodes were then incremented by 0.01 and the steps were repeated up to a probability of 1. 
 Fig. 4 Comparison of the difficulty of single, double and triple skill questions. 
 3 The Learned Compositional Model.
 The learned compositional model topology looks similar to the AND model except that there is no layer of gate nodes and the skills are connected directly to the question nodes as seen in Figure 5. 
 Fig. 5 Directed acyclic graph representing the compositional Bayesian topology. 
 The fundamental difference between the AND model and the learned compositional mode is that only three parameters, a guess and slip and prior, are learned in the AND model since the composition function was captured by the AND gates + guess/slip. In the learned compositional model, however, the composition function and the guess/slip parameters are captured in one complex CPT. A guess and slip value will still be learned for the single skill equivalence class since there is no composition with a single skill. However, four parameters will be learned for the double skill equivalence class and eight parameters for the triple skill class. The increase in parameters is due to the CPT needing to expand with the increased number of parent nodes. Example CPTs for single and double skill questions are shown in Figure 6. 
 Fig. 6 Example CPTs for single and double skill questions. 
 In both CPTs of Figure 6 the 0.15 represents the guess parameter which is the probability the question is answered correctly (P(Q=T)) given the skill is not known (S1=F); 0.85 is simply the complement of the guess parameter.  Observe that in the double skill CPT there is a row where S1=T and S2=F and another row where S1=F and S2=T. Why might the P(Q=T) of these two rows differ? Because, for example, S1 could represent the “harder skill”. If the composition function is compensatory, knowledge of only the more difficult skill could results in a P(Q=T) of greater than 0.50 while knowledge of only the easier skill could result in a P(Q=T) of less than 0.50. In the next section we describe how the network topology was organized to capture the notion of a “harder” skill. We found that knowing the harder skill is not much better than knowing the easier skill, suggesting against a compensatory compositional function. 
 3.1 Methodology.
 The methodology for learning parameters in the learned compositional model was very similar to the AND model with the exception of an initial step required to order the skill nodes. This ordering was done to capture relative difficulty among skills so that a compensatory function, which requires the notion of skill difficulty, could potentially be learned. The default order of skills in the network was alphabetical. Because this ordering has no substantive meaning we decided to order the skills by difficulty with the most difficult skill appearing first (node 1) and the least difficult appearing last (node 106). We used the metric of skill prior to represent the difficulty of a skill. In order to attain the priors on all the skills we let a separate prior be learned for each of the 106 skills during an initial parameter learning of single skill questions. This step was done solely to get a skill order. The learned guess/slip values were discarded. After the skill priors were attained, the network was reordered and the single equivalence class for skill priors was reestablished before the “real” first phase of EM parameter learning was run. This reordering gave extra power to the results and allowed us to ask composition questions such as, “does knowing only the harder skill increase the probability of answering a question correctly over knowing only the easier skill?” 
 3.2 Results.
 Results of the compositional model parameter learning indicate that the learned composition function is conjunctive. Evidence against a compensatory function can be drawn from Table 2 which shows that knowing one skill only slightly increases the probability of answering a double skill question correctly over knowing no skills. 
 Table 2. Learned double skill CPT for the learned compositional model. 
 The table also shows that knowing only the harder skill does not help significantly over only knowing the weak skill. For double skill questions the learned guess is 0.17 and 0.06 slip, nearly the same as the AND model. To further compare and verify the learned compositional model’s similarity to the AND model we generated a graph similar to Figure 4. 
 Fig. 7 Comparison of the AND model and learned compositional model. 
 Figure 7, above, shows that the lines from the AND model and learned compositional model overlap. The similarity of the behavior of these functions, arrived at through two different analytic approaches, favors the AND gate as being a very close approximation to the composition function. 
 3.3 Further analysis: deriving the composition function.
 The values in Table 2, estimated by our model, determine how likely a student is to respond correctly to a multi-skill question on the basis of her knowledge of the two associated skills.  For example, a student who knows the harder skill but does not know the easier skill has a 23% chance of responding correctly to the question.  These parameters values are affected by two components:  the effect of composition and the likelihood of slipping or guessing.  Unfortunately, it is impossible to simultaneously model both effects separately since the model is underdetermined.  Both the guess/slip and composition effects are latent, and therefore during the parameter estimation phase of EM there are an infinite number of simultaneous solutions.  Therefore, we will reuse the slip and guess values from the AND model (guess=0.1923 and slip=0.0639, from Figure 3) as estimates of the effect of slipping and guessing.  We then partial those out (analogous to a partial correlation) of the table by using the following equation: P(correct) = (1-P(known)) * guess + P(known) * (1-slip). In this formula, P(known) refers to the probability the student knows how to solve the problem accounting for the composition effect; P(correct) is the value in Table 2, and slip and guess are 0.1923 and 0.0639, respectively.  By solving for P(known), we can compute the effect of composition:  that is, when a student knows neither, one or both of the two skills, how much effective knowledge does she bring to bear on the problem?  Solving for P(known) for each entry in Table 2 yields Table 3. 
 Table 3. Compensatory model with guess/slip factored out. 
 Table 3 represents the composition function.  Although some of the values are impossible in terms of being probabilities, they are only (close) approximations since we were forced to use slip and guess values from a related analysis.  In spite of these shortcomings, Table 3 is quite interpretable:  it is extremely similar to an AND gate. When a student knows neither skill she has, effectively, zero knowledge. When she knows both skills her knowledge is approximately 1. When she only knows 1 of the skills, she has a slight amount of knowledge, but still fairly close to 0. Replacing these numbers with an AND gate would produce largely similar results, as can be seen in Figures 4, 5 and 6. Therefore, composition is well-modeled as an AND gate.  Furthermore, we see no evidence that it is necessary to use a leaky-AND gate [4] to model composition. 
 4 Contributions.
 We have shown that the more skills involved in a question the harder it is to guess the correct answer. We have also shown that the probability of slipping goes down as well with more skills. We speculate that the reason for decreased slip is that students who are believed to know multiple skills are less likely to make a mistake. Another possibility is that multi skill questions demand more concentration and thus a student is less likely to make a careless mistake due to not paying attention. We also found that knowing the more difficult skill in a multi skill question does not help much over knowing only the less difficult skill or over knowing neither skill. We have investigated the composition function and found that it is approximated very well by the AND gate + guess/slip. While cognitive modelers may be interested in the slight compensatory effect seen in Table 3, ITS developers can have confidence in using an AND assumption for accurate assessment when dealing with multi skill items. 
 Acknowledgements.
 We would like to thank the Worcester Public Schools and all of the people associated with creating the ASSISTment system listed at www.ASSISTment.org including investigators Kenneth Koedinger and Brian Junker at Carnegie Mellon. We would also like to acknowledge funding from the U.S. Department of Education, the National Science Foundation, the Office of Naval Research and the Spencer Foundation.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>The Composition Effect: Conjunctive or Compensatory? An Analysis of Multi-Skill Math Questions in ITS</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/zachary-a-pardos"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/zachary-a-pardos"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-e-beck"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-e-beck"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/carolina-ruiz"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/carolina-ruiz"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/234/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/zachary-a-pardos"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-e-beck"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/carolina-ruiz"/>
		<rdf:_4 rdf:resource="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/235">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Analytic Comparison of Three Methods to Evaluate Tutorial Behaviors</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/235/authorlist"/>
		<swrc:abstract>We compare the purposes, inputs, representations, and assumptions of three methods to evaluate the fine-grained interactions of intelligent tutors with their students.  One method is conventional analysis of randomized controlled trials (RCTs).  The second method is learning decomposition, which estimates the impact of each practice type as a parameter in an exponential learning curve. The third method is knowledge tracing, which estimates the impact of practice as a probability in a dynamic Bayes net.  The comparison leads to a generalization of learning decomposition to account for slips and guesses.</swrc:abstract>
		<led:body><![CDATA[ 1.1 Randomized controlled trials analysis.
 The high-level strategic idea of RCTs is that randomizing assignment to treatments allows the strong causal inference that significant differences in outcome are due to differences in treatment.  In RCTs, participants are randomly assigned to receive one of several different interventions. RCT analysis aggregates and compares the outcomes under each condition, to assess the effectiveness of different interventions. For example, Project LISTEN’s Reading Tutor [3] chooses randomly among multiple ways to help the student learn a given word. To compare their effectiveness using RCT analysis, the Reading Tutor randomly chooses for each student how to teach or practice a given word. For each such randomized trial, we measure its outcome, e.g., how well the student reads the word at the next encounter of it.  By comparing the aggregated outcomes for each intervention, we can statistically estimate how effective they are relative to one another. RCT analysis is instantiated by a statistical test or model to estimate the effects of treatment and possibly other variables.  Common examples include t-test and ANOVA. The test or model is implemented as the computation of a standard statistical formula, typically in a statistical package such as SPSS. 
 1.2 Learning decomposition.
 The strategic idea of learning decomposition is to distinguish among different types of exposure in fitting a model of learning to students’ performance data, in order to obtain empirical estimates of the relative impact of different types of practice or instruction. Prior work [4-6] instantiates this idea in terms of a particular model form, namely an exponential learning curve, by expressing the amount of exposure as a function of the amount of exposure of each type, namely a linear combination of them. Alternative model forms would produce alternative instantiations.  One plausible alternative to an exponential learning curve is a power law.  Power laws are often used to fit performance data averaged over multiple participants, but exponential curves tend to fit individual performance data better than power law curves do [7].  A more complex alternative [8] is based on a richer theoretical model of learning and forgetting over time, but must be expressed recursively instead of in closed form, and has more parameters to fit. The instantiation of learning decomposition used in this paper generalizes the classic exponential learning curve to distinguish the effectiveness of m different types of practice, as shown in Equation 1: 
 FORMULA_1.
 In the equation, performance measures a learning outcome, such as error rate, help requests, or response time:  the lower the value, the better the student learned.   The variables ti  (i=1…m) represent the amount of type i practice that the student has had, as measured by the number of practice opportunities of that type.  The free parameters A, b, and βi’s are estimated from observations of student performance.  Here A represents the student’s initial performance without any prior practice, and b is the learning rate. Finally, the free parameters βi (i=2…m) represent the impact of type i practice relative to type 1 practice, whose impact β1 we define to be 1 as a baseline for comparison. For example, consider how learning decomposition can apply to our previous example of comparing different tutorial interventions to teach student a word.  The performance measure can be word reading time.  The variable ti counts the number of times the student received intervention of type i.  The estimate of each βi measures the effectiveness of intervention type i compared to the baseline. For instance, if β2 = 2, it means that on average a type 2 intervention is twice as helpful as a type 1 intervention. Implementation of learning decomposition refers to how the model is fit to the data.  For example, our implementation uses SPSS to perform unconstrained non-linear regression using the Levenberg-Marquardt procedure. 
 1.3 Knowledge tracing.
 The general idea of knowledge tracing is to model a student’s performance and changing knowledge state during skill acquisition, and to use the model to update an estimate of this state based on successive observations of student performance.  Atkinson [9] proposed a Markov model relating knowledge to performance.  Corbett and Anderson [10] used a simple 2-state model – the state of not knowing a given skill, and the state of knowing the skill. An instantiation of knowledge tracing specifies a particular model of learning.  We represent the two knowledge states in Corbett and Anderson’s model as a hidden node in a dynamic Bayes network (DBN).  The value of this node is true if the student knows the skill at a given step, and false if not.  The node is hidden, so its value cannot be observed directly.  Instead, knowledge tracing maintains the probability Pr(Ki) that the student has learned that skill at time step i.  It uses observations of the student’s performance to update this probability each time the student encounters an opportunity to use the skill. We extend this basic knowledge tracing model to incorporate and compare the efficacy of different types of tutorial interventions. Figure 1 shows the graphical representation of the extended model. 
 Figure 1.  Knowledge tracing model extended with “Tutor Intervention” node. 
 From the graph we can see that the model is a DBN with 3 nodes at each time step i.  The binary valued hidden node Ki represents whether the student knows the skill at time i. Pr(Ki) is a probabilistic estimate of this binary student knowledge variable.  Pi represents the student’s observed performance (e.g. correct or incorrect) on that skill at time i. Using a DBN for knowledge tracing lets us generalize its original formulation [10] by including additional nodes.  For instance, Chang et al. [11] added a node to represent help requests.  To evaluate interventions, we include tutor intervention Ti as a discrete variable to represent which tutorial intervention is made at time i.  Links in the model encode conditional dependencies between variables. 
 A model is described by the following parameters: knew:  Probability that the student already knew the skill prior to any instruction prob_Ti:  Probability that the intervention is of type i. learn_Ti:  Probability of acquiring the skill from an intervention of type Ti, i.e. P(Ki+1=true | Ki= false, Ti) forget_Ti:  Probability of losing a known skill conditioned on an intervention of type Ti, i.e. P(Ki+1=false | Ki= true, Ti) guess:  Probability of answering correctly without knowing the skill, i.e. P(Pi=true| Ki= false) slip:  Probability of answering incorrectly despite knowing the skill, i.e., P(Pi=false| Ki= true). 
 The problem of comparing the effects of different types of tutorial behaviors then reduces to comparing the values of the learn_Ti and forget_Ti parameters for the different Ti’s corresponding to those types of behaviors. An implementation of this model includes an off-line training procedure to learn the model parameters from a corpus of performance data, and a runtime update procedure to revise the estimate of the student’s knowledge based on observed performance at step n. The BNT-SM implementation of knowledge tracing [12] uses BNT’s EM procedure to fit the model.  The update procedure can be implemented by a general Bayes net inference procedure, or by a procedure to compute specific formulas derived from the model. 
 1.4 Dimensions of comparison.
 Basic questions about RCTs, learning decomposition, and knowledge tracing include: What outputs are these methods designed to produce? What inputs do they require? What models are they based on? What are their underlying assumptions? Sections 2-5, respectively, compare the three methods with respect to these questions. 
 2 Intended output.
 The three methods differ in the purpose they are designed to achieve, that is, what outputs they compute. RCT analysis compares trial outcomes to identify factors that predict or affect outcomes, primarily treatment condition.  Thus it is a natural way to compare interventions.   It can estimate student ability that affects outcomes by including student identity as a factor in a statistical test, but such assessment does not exploit the randomized treatment assignment.  Thus RCT analysis evaluates interventions more than students.  Moreover, this evaluation analyzes an entire set of trials simultaneously, so even if it estimates student ability as a factor, it is not designed to update this estimate incrementally based on sequential observations of student performance. Learning decomposition can also fit student parameters such as initial performance and learning rate, but its primary purpose is to compare the relative impact of different types of practice.  Its performance prediction for how a student will do at the Nth encounter of a skill depends only on how much prior practice of each type he or she got on that skill – not on how well he or she performed on it previously – unless encounters are treated as different types based on their immediate outcomes. Learning decomposition could incorporate information about prior performance by treating successful and unsuccessful encounters as two different types of practice.  This possibility might in fact be interesting to explore.  However, it does not escape the fact that simply counting the number of encounters of different types ignores order and recency effects.  Thus the resulting model would predict the same performance after 5 correct responses followed by 5 incorrect responses as it would predict after 5 incorrect responses followed by 5 correct responses.  However, learning decomposition can model some recency effects by treating spaced and massed practice as different types [4]. Knowledge tracing is specifically designed to update, at each practice opportunity, a tutor’s estimate of an individual student’s mastery of the skill(s) it exercises. Conditioning this update on practice type makes it possible to evaluate how each type of practice affects learning.  Based on the latest knowledge estimate (plus the slip and guess parameters), the tutor can predict how well the student is about to perform, and plan accordingly – for example by picking an easier problem to prevent a likely imminent failure. Knowledge tracing makes a more informed prediction of performance than learning decomposition does, because the prediction reflects performance during prior practice, not just the amount of practice.  For example, suppose the data set includes sequences of N-1 practice opportunities by two different students on the same skill, with the same sequence of practice types, but that one sequence consists of successes and the other sequence consists of failures.  Knowledge tracing will predict higher performance after the successes than after the failures, because its prediction is conditioned on observed performance.  In contrast, learning decomposition – unless it includes any student- specific parameters or distinguishes past encounters by performance -- will predict the same performance in both cases, because its prediction is based solely on the number and type of practice opportunities. Knowledge tracing updates its estimate of student knowledge based on sequential observations of student performance, and is sensitive to their order – but not their timing. Learning decomposition can address this limitation to some extent by treating massed and spaced trials as different types of practice.  Analogously, knowledge tracing can condition the parameters learn and forget based on the time elapsed between successive encounters of a skill.  For both methods, this ad hoc refinement models temporal effects as discrete, for example by classifying a student’s successive encounters of a skill as occurring on the same or different days [4].  A more complex method [8] models continuous temporal effects based on a deeper theory of memory. 
 3 Information input.
 The three methods differ in what data they input, that is, which observations they consider. RCT analysis compares only observed outcomes, so it simply ignores trials whose outcomes were unobserved, undefined, or masked.  For example, a student’s performance in reading a word is unobserved when the Reading Tutor reads it, undefined when the Reading Tutor gives unrequested help on the word before accepting it, and masked by recency effects if the student has seen the word earlier the same day. Learning decomposition analyzes trials both as outcomes and as practice.  It excludes trials as outcomes where performance is unobserved, undefined, or masked, but in each case the encounter counts as practice. Knowledge tracing represents outcomes and practice as the same performance nodes in a dynamic Bayes net, and tolerates missing and partial observations.  For example, credit for a word is undefined if masked by tutor-initiated help, but the word encounter still updates the estimated probability that the student has learned the word. 
 4 Model form:  representation, computation, and extension.
 The three methods differ in how they are represented, applied, and extended. RCT analysis has no hidden variables to estimate, no initialization conditions to be sensitive to, and no local minima to get stuck on.  An appropriate statistical test to compare outcomes between different subsets of trials is practically instantaneous in a standard statistical package such as SPSS, even with many thousands of trials.  Extending the analysis involves adding outcome variables to test, and features to disaggregate by or include as factors in statistical tests such as ANOVA. Learning decomposition estimates parameters that represent the impact of each mode of practice in an exponential model of performance over time.  Non-linear regression in SPSS 11.0 took only about one minute to fit hundreds of models (one for each word) to thousands of word encounters in our empirical comparison of evaluation methods [1]. Extending models means adding parameters to further distinguish types of practice or other influence on performance, e.g. effect of length on word reading. Knowledge tracing, generalized to distinguish different practice types, estimates parameters that represent the impact of each type of practice on a hidden knowledge state in a dynamic Bayes net, and the effect of this knowledge on observed student performance.  BNT-SM [12] takes about 10 hours to train and evaluate models on a data set that learning decomposition takes only a minute to fit.  Extending the model means adding nodes to represent observations, and links to represent hypothesized causal influences. 
 5 Underlying assumptions.
 RCT analysis treats trials as separate and does not attempt to model the causal effects of one trial on the outcome of another, such as diminishing effects of successive trials on the same skill, or transfer effects from practice on one skill to performance on another [13]. At most it accounts for statistical dependencies among related trials by using tests with the appropriate number of degrees of freedom.  For example, instead of treating all trials on a story word as independent, we can average outcomes for each type of practice over all the students who received that type of practice on the word. In contrast, both learning decomposition and knowledge tracing assume particular models of how performance improves with practice.  On the surface, they look very different. Knowledge tracing can be expressed as a dynamic Bayes net that incrementally updates estimates of a hidden skill, while learning decomposition is expressed as a closed-form exponential function that predicts performance directly. Although their surface form differs markedly, the mathematics of these two methods is closely related at a deeper level in a way that is useful to elucidate because it not only reveals their underlying similarities, but shows how to bridge some of their differences. In particular, starting from a Bayesian model of knowledge tracing we can derive learning and performance curves that we can relate to learning decomposition. 
 5.1 Derivation of learning decomposition from knowledge tracing.
 Knowledge tracing estimates the probability Pr(Kn) that the student knows a given skill at time step n, according to a dynamic Bayes net model.  For brevity we will abbreviate Pr(Kn) as Kn.  The parameters of this model include the knew probability K0 that the student already knew the skill prior to instruction, the learn probability L of acquiring the skill from a step, the forget probability of losing a skill, the guess probability g of answering correctly without knowing the skill, and the slip probability s of answering incorrectly despite knowing the skill. We are interested in how Kn changes over time according to this model.  The probability of knowing the skill at step n given that the student did not know it at step n-1 is L.  If we assume zero probability of forgetting, the probability (1 - Kn) of not knowing the skill at step n is the probability of not knowing the skill at the previous step, times the probability of not learning it, or (1 - Kn-1)×(1 – L).  Consequently the ratio (1 - Kn) / (1 - Kn-1) is the constant (1 – L), and the probability (1 - Kn) can be expressed in closed form as (1 - K0) × (1 – L) n.  That is, ignorance at step n requires not knowing the skill in advance, followed by not learning it. This formula expresses the prior probability of (not) knowing the skill at time n; it is not conditioned on any observed student performance.  Observed performance affects our estimate of student skills, but this effect is evidentiary, not causal:  according to the model, student performance does not influence student knowledge.  In short, even without any observation of student performance, we can still use the model to predict student knowledge. We are also interested in the performance predicted by the model, specifically in the error rate expected at step n.  The probability Wn of a wrong response at step n can be split into two cases – either not knowing and not guessing, or knowing but slipping.  Consequently Wn = (1 - Kn) × (1- g) + Kn × s.  Plugging in our closed form expression for (1 - Kn) gives 
 FORMULA_2.
 What if the learning probability varies with the type of step?  We can generalize (1 – L) n to the product (1 – L1) × … × (1 – Ln).  If there are m types of steps, with ti steps of type i, each with learning probability Li, we rewrite this product as (1–L1) 
 FORMULA_3.
 and generalize the predicted error rate to:.
 FORMULA_4.
 If  s = g = 0, this formula reduces to (1 - K0) ×(1 – L1).
 FORMULA_5.
 m , which relates to the learning decomposition formula A × e –b × (β 1t1 + … + βmtm) as follows. The factors (1 – L1) … (1 – Lm) correspond to the coefficients β1, …, βm that represent the relative value of different types of practice.  More precisely, since (1 – Li) t i  = exp(log(1-Li)× ti)), the expression log(1 – Li )  corresponds to β1.  The factor (1 - K0) corresponds to A × e–b. This derivation reveals that we can extend learning decomposition to include slip rate s and guess rate g in the generalized formula s + (1 – g – s) × A × e –b × (β 1t1 + … + βmtm) . The additive term s represents the asymptotic performance beyond which the error rate will not decrease even with unlimited practice. However, it is important to point out that the generalized formula, at least in the form above, applies to the rate of errors or help requests, but not to response time.  The reason is that the parameter s appears both as an additive term and in the factor (1 – g – s).  If the formula represents a time quantity, s must be expressed in some unit of time.  But the s in (1 – g – s) must be unit-free to be comparable with the constant 1 and the probability g. Since s cannot be both a temporal quantity and unit-free, the overall formula cannot represent a time quantity, and in fact must itself be unit-free. Extending this generalized formula to predict time or other continuous measures of performance requires modeling how they are affected by slips and guesses.  For example, if guessing takes negligible time, the guess parameter g already models the effect of guesses on performance time:  if s = 0, then g = 0.5 cuts predicted performance time in half.  But if guesses take non-negligible time, modeling them requires extending the formula by interpolating it with guessing time.  Likewise, modeling the effect of slips on time requires replacing the additive term s with slip time, e.g. the time to misread a known word.  The extended form of the generalized formula therefore looks like this, where the expressions slip time and guess time depend on how they are modeled: s × (slip time) + g × (guess time) + (1 – g – s) × A × e –b × (β 1t1 + … + βmtm) 
 6 Contributions.
 This paper provides a descriptive and analytical comparison of three methods to evaluate tutorial behaviors:  RCT analysis, learning decomposition, and knowledge tracing using DBNs.    We compare their inputs, outputs, models, and assumptions.  In particular, we elucidate the underlying mathematical relationship between knowledge tracing and learning decomposition, thereby showing how to generalize learning decomposition to incorporate slip and guess parameters.  We hope that other researchers will find this paper useful in making informed choices of which method(s) to use to model and evaluate learning in tutors. 
 Acknowledgements.
 The research reported here was supported by the National Science Foundation under ITR/IERI Grant No. REC-0326153, by the Institute of Education Sciences, U.S. Department of Education, through Grant R305B070458 to Carnegie Mellon University, and by the Heinz Endowments. The opinions expressed are those of the authors and do not necessarily represent the views of the National Science Foundation, the Institute, the U.S. Department of Education, or the Heinz Endowments.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Analytic Comparison of Three Methods to Evaluate Tutorial Behaviors</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/jack-mostow"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/jack-mostow"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/xiaonan-zhang"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/xiaonan-zhang"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/235/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/jack-mostow"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/xiaonan-zhang"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/236">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Analyzing Rule Evaluation Measures with Educational Datasets: A Framework to Help the Teacher</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/236/authorlist"/>
		<swrc:abstract>Rule evaluation measures play an important role in educational data mining. A lot of measures have been proposed in different fields that try to evaluate features of the rules obtained by different types of mining algorithms for association and classification tasks. This paper describes a framework for helping non-expert users such as instructors analyze rule evaluation measures and define new ones. We have carried out several experiments in order to test our framework using datasets from several Cordoba University Moodle courses.</swrc:abstract>
		<led:body><![CDATA[ 1. Main window of the application and windows with the rules and values of the measures. 
 In order to use our framework, the user/teacher has to select 2 obligatory files (data and rules) and can also select 2 optional files (measures and ontology). The data file is a local file or URL (Uniform Resource Locator) that contains the dataset. This file can have CSV (Comma-Separated Values) format or Weka format [9]. The rules file is also a local file or URL that contains the rules discovered by the mining algorithm. It has to have PMML (Predictive Modeling Markup Language) format that is an XML-based language which provides a way for applications to define statistical and data mining models and to share models between compliant applications. The measure description file is an optional local file with XML format that contains the definition of the measures in Latex equation format. Thus the measures are defined using not only mathematics latex symbols and functions, but also probabilistic and contingency table symbols, such as n(A), n(C), N, P(A), P(C/A), etc. as well as all the availables measures for defining new measures. The framework provides a default measure description file with over 40 measures already defined so that the teacher can use them directly with no need to define them. We have also developed a wizard and an equation editor using Latex equation format in order not to have to write out this XML file by hand, since this could be a difficult task for a teacher. Using this wizard, the teacher can define brand-new measures easily by only following several guided steps and the equation editor. Finally, the ontology file is an optional local file. It uses OWL (Ontology Web Language) format to define the specific domain of the data and rules used. Then, after the user/teacher has chosen the previous input files; the application calculates the values of each measure for each rule coming from the data file. Next, all the rules and all the measures are displayed for the teacher in the results window (see Figure 1 down). For each rule, the elements of rule antecedents and consequents are displayed as well as the calculated values of each evaluation measure. The rules can be sorted by any of the measures by simply clicking on the header of a specific column so that the teacher can compare different ranks depending on the measure used. Furthermore, if the user has selected an ontology file, then the OWL file will be visualized graphically so the teacher can interpret/understand better the meaning of the rules in that domain. Finally, we have also developed a PCA (Principal Component Analysis) module [1] in order to help the user/teacher to group and reduce the number of measures used. Each principal component is unrelated and corresponds to orthogonal directions in the newly generated search space. In our framework, the teacher can execute PCA starting from the results windows by pressing the PCA button (see Figure 1 down). A new window appears (see Figure 1 up) in which the user/teacher can select the number of principal components or the maximum eigen value, and has the option of showing the scree plot and the coefficients of the measures in each PC. Then the communality values of each principal component for each measure are shown along with  the scree plot. Using the scree plot and the eigenvalues, the user/teacher can select a number of principal components, normally those with eigenvalues greater than 1 or when the inclination of plot starts to decrease. Then, the teacher can group each measure into  one principal component using the communality values for each measure. In order to do so, the teacher has to assign or classify each measure in the component where it shows the highest absolute value. 
 3 Experimental results with Moodle courses.
 We have carried out several experiments in order to test our framework using educational datasets. We have used 4 dataset files obtained from 4 Moodle courses with about 80 students in each course. The courses are computer science technical-engineering second- year courses in Cordoba University. We have preprocessed these students’ usage data that is stored in a Moodle database. First, we have filtered only the information about the 4 courses activities that interest us, such as assignments, forums and quizzes. Next, we have created a summarization table that integrates this information at student level (number of assignments done, number of messages sent/read to/in the forum, number of quizzes taken/passed/failed, total time used on assignment/quiz/forum, and student’s final mark). We have discretized all the numerical values in order to increase interpretation and comprehensibility since categorical values (low, medium and high) are more familiar to teacher s than precise magnitudes and ranges. Finally, we have saved them in 4 data files, one for each course. Before using our framework, we applied the Apriori-C algorithm [3] to discover Class Association Rules (CARs) from previous Moodle data. Apriori-C is a well-known algorithm for discovering association rules for classification. In our experiment, the class is the mark attribute. In this way, the teacher can obtain rules that show relationships between Moodle activities that influence the mark obtained by the students [15]. Specifically, we have executed Apriori-C algorithm over the 4 course dataset files with a minimum support of 0.03 and a minimum confidence of 0.6 as parameters. Next, the class association rules obtained are saved into a PMML file. In the first column of Table 1, we can see the number of rules obtained for each dataset. Next, we have used our framework to obtain values for all evaluation measures beginning with the Moodle datasets and PMML rules files. In this experiment, we have used only 12 measures: chi-squared, correlation coefficient, predictive association, entropy, support, confidence, laplace, interest, interestingness, gini, interest function and conviction. We have chosen these measures specifically because they are some of the most representatives [8]. So we have obtained the values of the 12 measures for all the rules and then we have applied PCA with 1, 2, 3 and 4 principal components in order to see how many  components or groups  all these measures can be grouped into. In Table 1, we can see the amount of variance obtained for each principal component from the rules discovered in each dataset. The results obtained show that we can select 3 principal components since they store between 80%-90% of the variance of the data. So, we can use these components as new evaluation measures in which almost all the information provided by the original measures is included. In this way we can reduce the number of measures used from the original 12 measures to 3 new meta-measures. The teacher could define three new measures using the editor, one for each PC using the coefficients of the measures in each PC. For example, the 2nd PC in course 1 could be defined as the following new measure: 
 FORMULA_1.
 4 Conclusions and Future Work.
 In this paper we have described a specific framework for analyzing rule evaluation measures. We have shown how a user/teacher can use it together with Moodle course datasets in order to: obtain the values of the measures of the rule discovered by a rule mining algorithm, sort and select the rules according to the values of any specific measure, compare and group the measures using PCA and define new measures using a wizard and an equation editor. Currently we are working on other techniques for comparing rule evaluation measures. 
 Table 1.  Comparison of %Variance with the principal components using 12 measures. 
 For example, correlation techniques in order to see what measures are correlated. In the future, we want to work with subjective and semantics-based measures. Our objective will be to add subjective restrictions to our framework user that take into account information about the domain. For example, restrictions to different granularity levels to only show rules about relationships between activities, or relations between chapters or between courses. Finally, we also want to develop brand-new semantic-based measures that can use the domain information of the OWL files. In this way, we could create new measures specifically geared toward each application domain or dataset. 
 Acknowledgments.
 The authors gratefully acknowledge the financial subsidy provided by the Spanish Department of Research under TIN2005-08386-C05-02 projects. FEDER also provided additional funding.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Analyzing Rule Evaluation Measures with Educational Datasets: A Framework to Help the Teacher</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/s-ventura"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/s-ventura"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/c-romero"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/c-romero"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/cesar-hervas"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/cesar-hervas"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/236/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/s-ventura"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/c-romero"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/cesar-hervas"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/237">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Labeling Student Behavior Faster and More Precisely with Text Replays</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/237/authorlist"/>
		<swrc:abstract>We present text replays, a method for generating labels that can be used to train classifiers of student behavior. We use this method to label data as to whether students are gaming the system, within 20 intelligent tutor units on Algebra. Text replays are 2-6 times faster per label than previous methods for generating labels, such as quantitative field observations and screen replays; however, being able to generate classifiers on retrospective data at the coder’s convenience (rather than being dependent on visits to schools) makes this method about 40 times faster than quantitative field observations. Text replays also give precise predictions of student behavior at multiple grain-sizes, allowing the use of both hierarchical classifiers such as Latent Response Models (LRMs), and non-hierarchical classifiers such as Decision Trees. Training using text replay data appears to lead to better classifiers: LRMs trained using text replay data achieve higher correlation and A' than LRMs trained using quantitative field observations; Decision Trees are more precise than LRMs at identifying exactly when the behavior occurs.</swrc:abstract>
		<led:body><![CDATA[ 1.3 minutes. Additionally, this measure does not account for the difficulty of scheduling classroom observations within schools, and time lost to waiting for observation opportunities. Second, the resulting data labels are not immediately synchronized with the log data. Whereas log data is generally organized either at the semantic level of student actions (i.e. entering an answer, requesting help, etc.) or keystrokes/mouse movements [cf. 11]), the observations occupy 20-30 second time windows. In many cases, it is difficult to exactly synchronize these two types of data, since even a slight skew in time recording mechanisms may significantly affect accuracy. To compensate, researchers have probabilistically assigned time windows [cf. 20] or used hierarchical models that fit to overall proportions of behavior rather than labeling individual actions [cf.6]. A second approach to developing classifiers of student behavior is to use knowledge engineering rather than machine learning on labeled data [cf.1,9]. This approach is generally quite quick to implement, but it is not possible to directly validate the accuracy of classifications without obtaining labeled data of some sort. The single example of a validation of a knowledge engineering behavior classifier in a learning environment (that we are aware of) involved the use of data collected through quantitative field observations [cf. 18]. A related approach is to use clustering to develop behavior categories, and then develop a classifier based on those behavior categories [cf. 2]. Like knowledge engineering, this approach is quick to implement, but suffers from the same difficulty in model validation. An alternate approach is to directly label the log files with the construct(s) of interest. One method for doing so, proposed by de Vicente and Pain [11], is screen replays – labeling a student’s behavior or affect while watching a video capture of the student’s screen during learning software usage. This approach avoids synchronization problems in labeling data, as well as scheduling/driving time, but is still quite time-consuming, as coders watch student behavior in real time. de Vicente and Pain [11] report observers making 85 classifications in around 6 hours, an average of one classification every 4.2 minutes. Cocea and Weibelzahl [10] also report having human coders label log files, although they do not report the coding process in full detail. 
 3 Text Replays.
 We propose another method for directly labeling log files with the constructs of interest: text replays. Text replays represent a segment of student behavior from the log files in a textual (“pretty-printed”) form. A sequence of actions of a pre-selected duration (in terms of time or length) is shown in a textual format that gives information about the actions and their context. In the example shown in Figure 1, the coder sees each action’s time (relative to the first action in the clip), the problem context, the input entered, the relevant skill (production), and how the system assessed the action (correct, incorrect, a help request, or a “bug”/ misconception). The coder can then choose one of a set of behavior categories (in this study, gaming or not gaming), or indicate that something has gone wrong, making the clip uncodeable. Text replays give relatively limited information, compared to quantitative field observations or full screen replays, omitting the visual information that would be seen in those methods (including mouse movements and partial responses). It is also necessary for the coder to understand the user interface in order to interpret contextual information. However, text replays are likely to be very quick to classify, and can be generated automatically from existing log files. Text replays were first proposed in Baker, Corbett, & Wagner [7], where it was shown that text replays have good inter-rater reliability, and that text replays agree well with predictions made by models generated using data from quantitative field observations. In this paper, we test this technique’s speed for labeling large amounts of data, develop classifiers of student behavior, and test these classifiers’ goodness of fit. 
 4 Text Replay Labeling Study.
 We used text replays to label student behavior within a Cognitive Tutor for Algebra. Cognitive Tutors are a popular type of interactive learning environment now used by around half a million students a year in the USA. In Cognitive Tutors, students solve problems, with exercises and feedback chosen based on a model of which skills the student possesses. Cognitive Tutor Algebra has been shown to significantly improve student performance on standardized exams and tests of problem-solving skill [15]. Within our text replays, we labeled whether a student was gaming the system. We chose gaming the system, because it is a behavior for which multiple classifiers have been developed and validated [6, 18, 20].  Within Cognitive Tutor Algebra, as with other Cognitive Tutors, gaming the system consists of systematic guessing and hint abuse (clicking through hints at high speed until the system gives the answer). We obtained data from students’ use of Cognitive Tutor Algebra from the Pittsburgh Science of Learning Center DataShop (https://learnlab.web.cmu.edu/datashop/). The DataShop is a public resource for the learning science community, giving free access to anonymized data sets of student use of learning software. We used the “Algebra I 2005- 2006 (Hampton only)” data set, a data set consisting of 436,816 student actions (an action is defined as entering an answer or requesting help) made by 59 students over the course of an entire school year, in a high school in the suburbs of a city in the Northeastern USA. Data from 32 tutor lessons was obtained; however, 12 lessons were eliminated from consideration for one of two reasons: either having insufficient data to be able to conduct at least 498 observations (500 was the planned cut-off, but one lesson with 498 observations was included), or gaming the system never being coded in that lesson. Across lessons, 18,737 text replays were labeled. These text replays were randomly selected; the chance of a specific sequence of actions being chosen was weighted, for each lesson, according to the total number of actions in that lesson. An average of 887 text replay observations were made in each lesson (SD=178; min=498; max=1075). A single coder (the second author) labeled all 18,737 text replays. This coder was trained by the first author, who had previously used the technique in [7]. Training consisted of repeatedly coding the same clips, and comparing and discussing the results, until 100% agreement was obtained on two sets in a row. Text replays of gaming previously achieved reasonably high inter-reliability (Cohen’s κ) of 0.58, in a study where coders did not engage in this training practice [7]. Training took approximately two hours. The coder labeled the 18,737 text replays in 206 hours of work, a rate of about 39.6 seconds per observation. The 206 hours included time spent studying each tutor lesson’s user interface. This was about twice as fast, label per label, as quantitative field observations of gaming conducted in prior research [7], and about 6 times as fast as observations of affect conducted using screen replays [11]. The observations were conducted across 4.5 months, at the coder’s convenience, rather than during an entire school year during school hours. The time savings from conducting the observations when convenient for the coder – rather than when convenient for the school – was quite substantial. 4.5 months of work was able to generate data to build gaming classifiers for 20 tutor lessons (the classifiers will be discussed in the next section). By comparison, 3 years of work using quantitative field observations to label student data only produced enough data to develop classifiers of gaming for 4 tutor lessons [6]. Hence, text replays enabled us to collect data for 5 times as many classifiers in 12.5% as much total time – around 40 times faster. This result suggests that the text replay method is substantially more efficient than prior methods for generating labels of gaming the system, beyond just the time spent on each individual label. 
 5 Developing Classifiers of Gaming the System.
 Once the text replays were obtained, we developed two types of classifiers of gaming the system. First, we built classifiers of gaming using a Latent Response Model(LRM) [16]. In this approach, discussed in considerably more detail in [6], the model predicts whether each student action is gaming, then aggregates those predictions to predict each student’s frequency of gaming (and trains on the overall proportion of time each student spent gaming, rather than training on labels of individual actions). Training detectors in this fashion enables us to study whether detectors developed using data from text replays are as accurate as detectors previously developed using data from quantitative field observations [6], using the same classification method. Second, we took advantage of the fact that text replays label individual actions in the logs as gaming or not gaming, to use a second method. We built gaming detectors using J48 decision trees, the same technique used in Walonoski & Heffernan [20], using the Weka data mining package [21].  This method was slightly to moderately more accurate at classifying gaming the system than other classification algorithms within the Weka package. It is worth noting that these labels of individual actions cannot be considered perfectly accurate, since the observer labeled a clip as “gaming” if any of the actions in the clip involved gaming. Therefore, actions at the beginning or end of clips may not in all cases be instances of gaming. This suggests that, within this data set, a 100% perfect match between our classifier’s labels of individual actions and those actions’ labels (which will be measured with Kappa) is not necessary (or desirable). This limitation could be addressed in future work by having observers explicitly label which actions in a clip are gaming, but would have the cost of reducing the method’s speed. Within each approach, a separate classifier was trained for each lesson and tested in that lesson. Due to the large number of models fit, the training set was used as the test set in all cases, for tractability. As this testing method risks some over-fitting, pruning was used on the J48 trees, and model size was capped for the latent response models. 26 features were distilled for each action in the log files for use by the classification algorithms, including features involving details about the action (Was it correct or incorrect, or a help request? Was it the first attempt at the step?), assessments of student knowledge, information about the time the student took on this step (absolute, and relative to other students), and information about the student’s previous interaction behaviors (How often has this student gotten this step wrong in the past? How much help has the student requested?). A full list of features can be found in [6]. 
 6 Classifier Goodness.
 We assessed the two types of classifiers, for each lesson, using three metrics: A', correlation, and kappa. A' addresses a classifier’s ability to assess which students gamed. A' is the probability that if the detector is comparing two students, one who gamed and one who never gamed, it will correctly identify which student is which. A' is equivalent to both the area under the ROC curve in signal detection theory, and to W, the Wilcoxon statistic [14]. 
 Table 1. The performance of each model on each metric, across models (standard errors given in parentheses). Both models are statistically better than chance on all metrics; boldface indicates a model is statistically significantly better than the other model, for that metric. 
 A model with an A' of 0.5 performs at chance, and a model with an A' of 1.0 performs perfectly. Correlation assesses whether the detector predicts the correct amount of gaming for each student. Kappa assesses whether the detector accurately identifies the correct actions as gaming. A Kappa of 0 indicates that the detector performs at chance, and a Kappa of 1 indicates that the detector performs perfectly. The full pattern of results is shown in Table 1. For A', the Latent Response Models averaged an A' of 0.96 (SE=0.02) across the 20 lessons, meaning that they could distinguish a gaming student from a non-gaming student in the data 96% of the time. This A' is considerably higher than the A' of  previous models of gaming the system developed using data from quantitative field observations (in that earlier work, models averaged an A' of 0.86 on the training set) [6]. The Decision Trees averaged an A' of 0.69 (SE=0.03). We can calculate the statistical significance of the difference of these models from chance (and from each other) by computing the standard error of each A' estimate [14], conducting Z tests, and then using Strube’s Adjusted Z to aggregate across lessons in a fashion that controls for within-student non- independence [20, Appendix II in 6]. We find that the LRM A' is significantly higher than chance, Z=26.56, two tailed p<0.0001, that the Decision Tree A' is also significantly higher than chance, Z=3.24, two tailed p<0.01, and that the LRM A' is significantly higher than the Decision Tree A' across lessons, Z=3.35, two tailed p<0.01. For correlation, the Latent Response Models averaged a correlation of 0.90 (SE=0.02) across the 20 lessons, between the predicted and actual frequencies of gaming, and the Decision Trees averaged a correlation of 0.44 (SE=0.05). Statistical significance can be computed by computing the significance of each correlation (or the significance of differences in correlation for correlated samples – [cf. 13]), converting those significance values to Z scores, and then aggregating across Z scores using Strube’s Adjusted Z. We find that the LRM correlation is significantly higher than chance, Z=10.04, two tailed p<0.0001, that the Decision Tree correlation is also significantly higher than chance, Z=3.46,two-tailed  p<0.0001, and that the LRM correlation is significantly higher than the Decision Tree correlation across lessons, Z=5.68, two tailed p<0.0001. For kappa, the Latent Response Models averaged a kappa of 0.04 (SE=0.01) across the 20 lessons in predicting the labels of whether individual actions involved gaming, and the Decision Trees averaged a kappa of 0.40 (SE=0.05). The statistical test most closely corresponding to kappa is chi-squared; however, this data violates the independence assumptions of chi-squared. Thus, we instead do t-tests on the kappa values for each lesson (either one-sample t-tests or paired t-tests), convert the significance values to Z scores, and then aggregating across Z scores using Strube’s Adjusted Z. This method treats the kappa values as point-estimates rather than as having a standard error, effectively giving us a sample size of 20 (the number of lessons) rather than the full sample size – in other words, this test is overly conservative, and should err in the direction of non-significance. Despite the poor kappa for LRM, it is significantly higher than chance, t(19)=3.77, two tailed p<0.01. The Decision Tree kappa is also significantly higher than chance, t(19)=7.81,two-tailed  p<0.0001. The Decision Tree kappa is significantly higher than the LRM kappa across lessons, t(19)=7.45, two tailed p<0.0001. 
 The poor performance of the LRM-based classifiers on kappa is surprising, given the high performance on the other metrics, and the effectiveness of this technique at assigning interventions to students which improve learning [4]. One potential explanation is that the model’s use of historical features leads it to identify gaming in the correct skills, but on transactions after the transaction where gaming actually occurred (i.e. the next time the skill is encountered), a pattern observed in previous classifiers of gaming trained in this fashion [6]. Indeed, we find that the LRM-based classifier is significantly more likely to detect gaming on skills the student has previously gamed (i.e. detecting gaming after the fact), than on other skills, t(58) = -4.77, two-tailed p<0.001, for a paired t-test. Classifiers with this characteristic will be useful for some types of interventions, such as giving supplementary exercises on material a student bypassed by gaming [4] or giving metacognitive interventions to gaming students between problems [3], but will be less appropriate for more immediate types of interventions. Interventions which depend on occurring exactly after a student games should probably be assigned by detectors trained on individual actions rather than overall proportions of behavior. On the other hand, the LRM-based classifier’s higher ability to identify gaming students is also relevant, since it increases the probability of assigning interventions to the students who most need them. Similarly, the degree to which this limitation will affect this classifier’s usefulness for data mining analyses of motivation or learning depends on the analysis. Analyses at broader grain-sizes which look at the overall incidence of gaming [e.g. 8, 12] may benefit from using an LRM-based classifier, whereas analyses that depend on accurate assessments of whether each action involves gaming may benefit more from using a Decision Tree. One potential solution that could avoid the limitations of the classifiers presented here would be to develop a hierarchical classifier (such as LRM) which optimizes on measures at both grain-sizes during training (e.g. using all three measures presented here). Such a classifier could potentially succeed both at detecting when an individual student is gaming, and distinguishing with maximum accuracy which students game and how much they game. However, this classifier would require the type of labels at multiple grain- sizes that Text Replays can provide. 
 7 Discussion and Conclusions.
 In this paper, we have presented text replays, a method for labeling student’s behavior within log files. When all factors are taken into account, including the time needed to make individual labels, and the logistics involved in conducting studies in schools, text replays appear to speed the process of data collection by around 40 times compared to quantitative field observations, and at least 6 times compared to screen replays. Where this technique applies, therefore, it may make classifier development accessible to a much larger pool of researchers and developers. However, this technique may not be applicable for coding every type of construct that can be coded with quantitative field observations or screen replays. Those techniques have been used to code students’ affect and motivation [cf. 11, 17]; it is likely that some affective and motivational constructs will be difficult to code using text replays. Establishing which categories of behavior can accurately be labeled in text replays will be an important area for future work. Unlike quantitative field observations, text replays make it easy to label individual actions as gaming or not gaming, though these labels are not 100% accurate, as clips often do not coincide exactly with the beginning and end of a gaming episode. Nonetheless, these action-by-action labels make it much more feasible to use off-the- shelf classifiers such as J48 Decision Trees to train gaming detectors which are reasonably successful at identifying exactly when students game, which students are gaming, and how much each student is gaming. Being able to use off-the-shelf classification algorithms available in Weka should make it more feasible for researchers and developers without machine learning experience to develop classifiers which are useful for learning analyses and to drive interventions by learning software. An alternate modeling framework, Latent Response Models, was trained on each student’s frequency of gaming. LRMs, as implemented here, were much more successful at identifying which students gamed, and how much each student gamed, but much less successful at identifying exactly when students game. Interestingly, the LRMs developed using text replay data appeared to be more accurate than prior LRMs developed using quantitative field observations. One explanation is that the text replay method both enables more precise assessments of students’ gaming frequency (via making it easy to collect more labels), and allows a coder to take extra time on more ambiguous cases (while working quickly on clear cases). The pattern of successes of the classifiers trained using different data suggests that it may be necessary to develop an algorithm that uses both overall gaming frequency data and action-by-action labels of gaming during the training processes in order to optimally capture both which students game, and when they game. One curious aspect of the models developed here is that they do not replicate the split between types of gaming found in [6]. In that work, LRMs trained to classify gaming students systematically only captured a proportion of students – the students who gamed and had poorer learning. (A separate classifier was trained to detect students who gamed but did not have poorer learning). There was no evidence for such a split in this study, where LRM classifiers had average A' values of 0.96. It is not yet clear whether the split in gaming behavior in [6] was idiosyncratic to the learning system studied, or whether this effect is dependent on differences in the labeling method in some subtle fashion. In conclusion, text replays appear to considerably speed the process of collecting the data necessary to develop effective classifiers of student behavior. Making it easier to develop classifiers of student behavior will expand the benefits of this technique to a wider pool of researchers, facilitating the development of more adaptive educational software and the use of data mining techniques to conduct complex analyses on student learning. 
 Acknowledgements.
 We would like to thank Mercedes Rodrigo and Albert Corbett for helpful suggestions and discussions. This work was funded by the Pittsburgh Science of Learning Center, National Science Foundation award SBE-0354420.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Labeling Student Behavior Faster and More Precisely with Text Replays</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/ryan-sjd-baker"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/ryan-sjd-baker"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/adriana-mjb-de-carvalho"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/adriana-mjb-de-carvalho"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/237/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/ryan-sjd-baker"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/adriana-mjb-de-carvalho"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/238">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Adaptive Test Design with a Naive Bayes Framework</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/238/authorlist"/>
		<swrc:abstract>Bayesian graphical models are commonly used to build student models from data. A number of standard algorithms are available to train Bayesian models from student skills assessment data. These models can assess student knowledge and skills from a few observations. They are useful for Computer Adaptive Testing (CAT), for example, where the test items can be administered in order to maximize the informa- tion they will provide. In practice, such data often contains missing values and, under some circumstances, missing values far outnumber observed values. However, when collecting data from test results, one can often choose which values will be present or missing by a consequent test design. We study how to optimize the choice of test items for collecting the data that will be used for training a Bayesian CAT model, such as to maximize the predictive performance of the model. We explore the use of a sim- ple heuristic for test item choice based on the level of uncertainty. The uncertainty of an item is derived from its initial probability of success and, thus, from its difficulty. The results show that this choice does affect model performance and that the heuristic can lead to better performance. Although the study’s results are more exploratory than conclusive, they suggest interesting research avenues.</swrc:abstract>
		<led:body><![CDATA[ 1. Uniform: Uniform random samples of missing values. 2. Most uncertain: Higher sampling rate of missing values for uncertain items (favoring the choice of average difficulty items). 3. Least uncertain: Lower sampling rate of missing values for uncertain items (favoring the choice of difficult and easy items alike). 
 Figure 1: Sampling probability distribution of items used for the most uncertain and least uncertain sampling schemes. 
 Uncertain items are the items that, obviously, are closest to an initial probability of 0.5. For the most uncertain and least uncertain conditions, the probability of sampling is based on the x = [0, 2.5] segment of a normal (Gaussian) distribution as reported in Figure 1. The probability of an item being sampled will therefore vary from 0.40 to 0.0175 as a function of its rank, from the most to the least uncertain item on that scale. Items are first ranked according to their uncertainty and they are attributed a probability of being sampled following this distribution. The distributions are the same for both conditions (2) and (3), but the ranking is reversed between the two of them. For the uniform condition (1), all items have equal probability of being sampled. Ten samples are created according to the three sampling schemes above. They are used to validate the effect of the sampling scheme by performing CAT simulations and measuring the predictive power of the models based on different sampling schemes. 
 4.1 Simulation process.
 The experiment consists in simulating the question answering process with the real subjects. An item is chosen and the outcome of the answer, success or failure, is fed to the inference engine (POKS). An updated probability of success is computed given this new evidence. All items for which the probability is above 0.5 are considered mastered and all others are considered non-mastered. We then compare the results with the real answers to obtain a measure of how accurate the predictions are. The process is repeated from 0 item administered until all items are “observed”. Observed items are bound to their true value, such that after all items are administered, the score always converges to 100%. The simulations replicate a context of computer adaptive testing (CAT) where the system chooses the question items in order to optimize skills assessment. The choice of item relies on a measure of the most informative question that gets administered to the examinee. This can be achieved in a number of ways and the results are often relatively close. We use a heuristic that our exploratory results has shown to approach the performance of the information gain approach (see [5]), but which is computationally much faster. It consists in choosing the item i that has a high entropy and is highly connected to other nodes: 
 FORMULA_3.
 where E(i) is the entropy of item i and links(i) is the number of incoming and outgoing links. The use of the maximal entropy of a item, E(0.5), in the above equation is a normalizing factor that ensures the weights between the number of links and the entropy are similar. Once the outcome of the answer to a question item is obtained, the probability of success to each other questions is then recalculated according to the POKS framework described above. Simulations consist in ten-fold cross-evaluation runs. Each run consists of a different random sampling for test design (the choice of items according to the three schemes described in section 4) and a different random sampling of the examinee used for training and testing. We report the average results of the 10 simulations for each experimental condition. 
 4.2 Data sets.
 Four data sets are used for the simulations. They are based on real data from tests in four different domains : 
 Table 1 reports general statistics on these data sets as well as the sizes of the training and testing samples used for the simulations. 
 Table 1: Data sets. 
 The proportion of missing values inserted in the training set is half of the data. The testing data sets contain no missing values. 
 1. College math: a 60 question items test covering different topics in mathematics, from general high school math, to college level geometry, linear algebra, and calculus. The test was administered to 426 candidates newly admitted at an engineering school. 2. UNIX: a 34 question items test covering knowledge of the UNIX shell commands, from the basic “change directory” (cd) to advanced data manipulation commands with awk. The test was administered to 48 individuals with a wide variety of knowledge about UNIX. 3. Arithmetic: a 20 questions test on basic fraction arithmetic. The test was administered to 149 pupils in grade 10 to 12. More details can be found in [13]. 4. French: a 160 general French grammar, reading, and comprehension test administered to 42 adults. 
 5 Results.
 The results of the simulation experiments are reported in Figures 2(a) to 2(d). The Y axis represents the proportion of correct predictions while the X axis reports the number of items administered. As mentioned, administered items are considered correctly classified, and thus, after all items are administered, the score reaches 100%. Given that the items are initialized to their unconditional probabilities, the prediction score generally starts above 70%, which indicates that more than two thirds of items are already correctly classified initially. A 90% confidence interval over the 10 simulations is reported around each data point. Each figure contains four curves. For comparison purpose, we report the Full condition which corresponds to the results for the full data set, without any missing values. The other three conditions are described in section 4. The results show non significant differences for the Arithmetic and College math data sets. However, more significant differences are observed for the other two data sets (UNIX and French), and they follow a regular pattern: The least uncertain condition systematically outperforms the most uncertain condition, which, in turn, performs systematically worst than the uniform condition. As expected, the full data set is systematically better than, or equal to, the data sets that contains missing values. 
 6 Discussion.
 These results suggest that higher sampling rates for the least uncertain items generally bring a higher predictive performance than for the most uncertain or the uniform choice, although this gain is not systematic. These results remain exploratory and a number of questions are left open. For one, how should we explain the patterns of differences found between the least uncertain, and the most uncertain? We initially hypothesized that the most uncertain items are the ones that would benefit the most from a higher sampling frequency. These items are generally the ones that bring the most information, and it seems reasonable to gather more data for them to correctly establish their relations to other items. 
 Figure 2: Results of the four data test. 90% confidence intervals are displayed around each data point. 
 However and contrary to these expectations, higher sampling of uncertain items yields the models with the poorest performance. One plausible explanation is that the estimation of the model’s conditional probabilities is more subject to noise and to miscalibration for probabilities closer to 0 or 1 than for mid-range probabilities. As a consequence, a higher sampling rate for these items is required. This hypothesis also explains why we observe a large difference between least uncertain and most uncertain for small data sets (UNIX and French) than for the larger ones (College math and French): larger data sets are not as subject to sampling noise as smaller ones are. Another open question is whether these results apply to other domains and to other Bayesian frameworks for student modeling. For example, would the results be the same if we used a more general Bayesian Network approach that captures independence relations, such as in [13]? A potentially interesting question to investigate is the hypothesis that the items that would be most informative are the ones that are central and highly connected in a Bayesian Network, that is, the nodes that are likely to influence the greatest number of nodes in the network. These nodes could benefit from a higher sampling rate. Moreover, given an initial topology of a Bayesian Network, we could guide the sampling beyond individual nodes, to pairs or to n-tuples of nodes that are deemed more critical. However, the topology of a Bayesian network might not be reliably established with small sample sizes, in contrast to the heuristic that we used which is based on estimating the individual items non conditional probabilities: they require relatively small sample size. It is feasible to design the tests with an initial sample of a few tens of data records, and then collect a larger sample for estimating the conditional, joint probabilities. Whether this can be effectively done for a Bayesian Network remains open. Further analysis and investigations are obviously required to bring some understanding to these results. Nevertheless, this investigation shows that we can influence the predictive performance of a Naive Bayes framework with partial data when we have the opportunity to select the missing values. It opens interesting questions and can prove valuable in some contexts of application.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Adaptive Test Design with a Naive Bayes Framework</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/michel-c-desmarais"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/michel-c-desmarais"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/alejandro-villarreal"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/alejandro-villarreal"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/michel-gagnon"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/michel-gagnon"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/238/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/michel-c-desmarais"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/alejandro-villarreal"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/michel-gagnon"/>
	</rdf:Description>
	<swrc:InProceedings rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/239">
		<swc:isPartOf rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/proceedings"/>
		<dc:title>Improving Contextual Models of Guessing and Slipping with a Truncated Training Set</dc:title>
		<bibo:authorList rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/239/authorlist"/>
		<swrc:abstract>A recent innovation in student knowledge modeling is the replacement of static estimates of the probability that a student has guessed or slipped with more contextual estimation of these probabilities [2], significantly improving prediction of future performance in one case. We extend this method by adjusting the training set used to develop the contextual models of guessing and slipping, removing training examples where the prior probability that the student knew the skill was very high or very low. We show that this adjustment significantly improves prediction of future performance, relative to previous methods, within data sets from three different Cognitive Tutors.</swrc:abstract>
		<led:body><![CDATA[ 1. Corbett and Anderson [9] instead used a bounded approach, where the guess and slip parameters are not allowed to rise above pre-chosen thresholds. Beck and Chang [7] showed that both of these approaches are prone to the “identifiability problem”, where multiple models can fit the data equally well. They proposed that models be chosen using Dirichlet Priors, which chooses a single best model by biasing parameters towards values that fit the whole data set well. Within this paper, we fit parameters for the Dirichlet Priors approach using Bayes Net Toolkit-Student Modeling (BNT-SM) [6]. However, the baseline and Dirichlet Priors approaches may result in parameters which are “theoretically degenerate” [2]. The conceptual idea behind using Bayesian Knowledge Tracing to model student knowledge is that knowing a skill generally leads to correct performance, and that correct performance implies that a student knows the relevant skill. A model deviates from this theoretical conception, and thus is theoretically degenerate, when its guess (G) parameter or slip (S) parameter is greater than 0.5. A slip parameter over 0.5 signifies that a student who knows a skill is more likely to answer incorrectly than correctly; similarly, a guess parameter over 0.5 signifies that a student who does not know a skill is more likely to answer correctly than incorrectly. 
 3 The Contextual Guess and Slip Model of Student Knowledge. 
 Baker, Corbett, and Aleven [2] proposed a new way of fitting parameters: estimating whether each individual student response is a guess or a slip based on contextual information (such as prior history and the speed of response), rather than using fixed guess and slip probability estimates across situations. This modeling approach was tested within a data set from an intelligent tutor for middle school mathematics, and significantly reduced the degree of model degeneracy. This approach was significantly better at predicting student performance than models developed using the Dirichlet Priors, bounded, and baseline methods, despite using substantially fewer parameters. The first step of the Contextual Guess and Slip method is to label a set of existing student actions with the probability that these actions involve guessing or slipping, using the Dirichlet Priors skill estimates. The set of student actions to be labeled is drawn (in this approach) from the set of first actions on each problem step, on the set of skills for which the Dirichlet Priors model is not theoretically degenerate. This set of skills was used, rather than all skills, in order to avoid training the models to include model degeneracy. Each student action (N) is labeled with the probability that it represents a guess or slip, using information about the two actions afterwards (N+1, N+2). Using information about future actions gives considerable information about the true probability that a student’s action at time N was due to knowing the skill – if actions N, N+1, and N+2 are all correct, it is (in most cases) unlikely that N’s correctness was due to guessing. The probability that the student guessed or slipped at time N (i.e., the action at time N, which we term An) is directly obtainable from the probability that the student knew the skill at time N, given information about the action’s correctness: P(An is guess | An is correct) = 1- P(Ln)  P(An is slip | An is incorrect) = P(Ln) Next, the probability that the student knew the skill at time N can be calculated, given information about the actions at time N+1 and N+2 (which we term A+1+2). This is done by using Bayes’ Rule to combine 1) the probability of the actions at time N+1 and N+2 (A+1+2), given the probability that the student knew the skill at time N (Ln); 2) the prior probability that the student knew the skill at time N (Ln); and 3) the initial probability of the actions at time N+1 and N+2 (A+1+2). In equation form, this gives: 
 FORMULA_2.
 The probability of the actions at times N+1 and N+2 is computed as.
 FORMULA_3.
 The probability of the actions at time N+1 and N+2, in the case that the student knew the skill at time N (Ln), is a function of the probability that the student guessed or slipped at each opportunity to practice the skill. C denotes a correct action; ~C denotes an incorrect action (an error or help request). 
 FORMULA_4.
 The probability of the actions at time N+1 and N+2, in the case that the student did not know the skill at time N (Ln), is a function of the probability that the student learned the skill between actions N and N+1, the probability that the student learned the skill between actions N+1 and N+2, and the probability of a guess or slip. 
 FORMULA_5.
 Once the set of actions is labeled with estimates of whether each action was a guess or slip, the labels are used to train models that can accurately predict at run-time the probability that a given action is a guess or slip. The original labels were developed using future knowledge, but the machine-learned models predict guessing and slipping using only data about the action itself and events before the action (i.e. no future data is used). For each action, a set of 23 features are distilled to describe that action, including information on the action itself (time taken, type of interface widget) and the action’s historical context (for instance, how many errors the student had made on the same skill in past problems). Linear Regression is then used, within Weka [16], to create 2 models predicting the probability of guessing (model 1) and slipping (model 2). Finally, these 2 models are used within Bayesian Knowledge Tracing to dynamically estimate the probability that each response is a guess or a slip. The first action of each opportunity to use a skill is labeled (using the machine-learned models) with predictions as to how likely it is to be a guess or slip, and parameter values are fit for P(T) and P(L0), for each skill. At this point, this model – like the earlier work – can make a prediction about student knowledge each time a student attempts to use a skill for the first time on a given problem step. It is worth noting that this model involves considerably fewer parameters than previous models – whereas the Dirichlet Priors and baseline models had exactly 4 parameters per skill, this model fits just over 2 parameters per skill (parameters for T and L0 for each skill, with parameters for G and S amortizes across all skills). 
 4 Choice of Data Set Used to Train Contextual Models.
 In the version of the Contextual Guess and Slip method published in [2], the data set used to train a knowledge model is the set of first actions on each problem step, on the set of skills for which the Dirichlet Priors model is not theoretically degenerate. However, there are potential drawbacks to using this data set. Specifically, if the data set involves significant amounts of over-practice, there may be a large number of actions for which a student has a probability close to 1 of knowing the relevant skill. On these actions, the estimated probability that any incorrect response is due to a slip may be very close to 1, and the probability that any correct response is due to a guess may be very close to 0. To give an example: Let us consider a skill which has Dirichlet Prior values of P(G) = 0.3 P(S) = 0.2, P(T) = 0.1, and at the current opportunity to practice the skill P(Ln-1) = 0.99. If the current action is incorrect (~C), and the following two actions are not correct (~C,~C), it is reasonable to assume that the current incorrect action is due to not knowing the skill, rather than a slip. However, the probability that the current action was a slip will be very high, 97.6%, according to the equations above, because of the very high value of P(Ln-1). This may be the correct prediction in this context; but if the model trains on this prediction and then uses it in different contexts when P(Ln-1) is further from 1, the probability that those actions are slips may be overestimated. (One explanation for why three errors in a row could occur on a skill with very high P(Ln-1) is that the mapping between actions and skills may have errors [cf. 8,9]; fixing such errors is a research topic in its own right [cf. 5,8]). 
 Pragmatically, it is more important for these estimations to be accurate when (Ln) is distant from 0 and 1. As P(Ln-1) approaches 1, P(S) has less and less impact on P(Ln) – the base probability is too extreme. This can be seen in Figure 1. Similarly, as P(Ln-1) approaches 0, P(G) has less and less impact on P(Ln). Hence, it is more important for the model to be highly accurate in cases where P(Ln) is not very close to 0 or 1. One way to accomplish this is to truncate the training set, so that actions where P(Ln-1) is too close to 0 or 1 are omitted. We choose the cutoffs 0.1 and 0.9, to err on the side of truncating too much rather than truncating too little. Hence, only cases where 0.1 < P(Ln-1) < 0.9 are included in the training set for the models of guessing and slipping. We can then follow the procedure given in the previous section to create the machine learned models of guessing and slipping, and then use these models in the model of student knowledge. We call the resultant knowledge model Truncated Training Set Contextual Guess and Slip, or Contextual-Trunc for short. In the following sections, we will compare this model to a version of the Contextual model without any truncation of the training set, and to the Dirichlet Priors model. To avoid bias, all models are evaluated on non-truncated data. 
 5 Data.
 We evaluate the models of knowledge tracing discussed here within data sets drawn from three Cognitive Tutors, on Algebra, Geometry, and Middle School mathematics. Cognitive Tutors are a popular type of interactive learning environment now used by around half a million students a year in the USA. In Cognitive Tutors, students solve problems, with exercises chosen based on the student knowledge model [1], on-demand help, and instant feedback. Cognitive Tutors have been shown to significantly improve student performance on standardized exams and tests of problem-solving skill [13]. The Algebra and Geometry data sets were obtained from the Pittsburgh Science of Learning Center DataShop (https://learnlab.web.cmu.edu/datashop/). 
 Table 1. The size of each data set (after exclusion of actions not labeled with skills). 
 The DataShop is a public resource for the learning science community, giving free access to anonymized data sets of student use of learning software. The Middle School data set was previously collected by the authors [cf. 3]. Each data set consisted of an entire year’s use of an intelligent tutor in schools in the suburbs of a city in the Northeastern USA; we are not aware of any overlap in the student population between data sets. Within each data set, actions which were not labeled with skills (information needed to apply Bayesian Knowledge Tracing) were excluded. However, all other actions on all other skills (including actions eliminated from the Contextual and Contextual-Trunc training sets) are included. The magnitude of the data sets is shown in Table 1. 
 6 Results.
 Bayesian Knowledge-Tracing models make predictions about student knowledge (i.e. the probability a student knows a skill at a given time). These predictions can be validated by comparing them to future performance in two ways. The first is to compare actions at time N to the models’ predictions of the probability that actions at time N will be correct – P(Ln)*P(~S)+ P(~Ln)*P(G). This method accurately represents exactly what each model predicts; however, this method biases in favor of the Contextual Guess and Slip models, since those models use information associated with the answer being predicted to estimate the probability of guessing and slipping. Therefore, we instead compare actions at time N to the models’ predictions of the probability that the student knew the skill at time N, before the student answered. This method under-estimates goodness of fit for all models (since it does not include the probability of guessing and slipping when answering), but is preferable because it does not favor any model. We use A' (the probability that the model can distinguish a correct response from an incorrect response) as the measure of goodness-of-fit. A model with an A' of 0.5 performs at chance, and a model with an A' of 1.0 performs perfectly. To assess the statistical significance of the differences between models, we compute A' for each student in each model, compute the standard error of the A' estimates [12], use a Z test to find the difference between models within each student [11], use Stouffer’s Z [15] to aggregate across students, and finally compute the (two-tailed) statistical significance of the Z score obtained. This method does not collapse across any data (i.e. it is not overly conservative) but accounts for the non-independence of actions within a single student. Within the Middle School data set, the Dirichlet Priors approach achieves an average A', across students, of 0.641. The Contextual approach achieves an average A' of 0.749. The Contextual-Trunc approach achieves an average A' of 0.758. 
 Table 2. The A' of each model within each tutor, across students. The Contextual-Trunc model is in boldface where it is statistically significantly better than the Dirichlet Priors model, and in italics where it is statistically significantly better than the Contextual model. 
 The Dirichlet Priors approach is statistically significantly poorer than the other two approaches, Z=59.56, p<0.0001, Z=64.17, p<0.0001. The Contextual-Trunc approach is statistically significantly better than the Contextual approach, Z=4.59, p<0.0001. Within the Algebra data set, the Dirichlet Priors approach achieves an average A' of 0.694. The Contextual approach achieves an average A' of 0.632. The Contextual-Trunc approach achieves an average A' of 0.707. The Contextual-Trunc approach is statistically significantly better than the Dirichlet Priors approach, Z=2.89, p<0.01. However, the Contextual approach is statistically significantly worse than the Dirichlet Priors approach, Z= -27.76, p<0.0001. The Contextual-Trunc approach is statistically significantly better than the Contextual Approach, Z= 30.65, p<0.0001. Within the Geometry data set, the Dirichlet Priors approach achieves an average A' of 0.638. The Contextual approach achieves an average A' of 0.666. The Contextual-Trunc approach achieves an average A' of 0.669. The Contextual-Trunc approach is statistically significantly better than the Dirichlet Priors approach, Z=2.52, p=0.01; the difference between the Dirichlet Priors approach and the Contextual approach is (at best) marginally significant, Z=1.60, p=0.11. The difference between the Contextual and Contextual- Trunc approaches is not significant, Z=0.92, p=0.35. The full pattern of results is shown in Table 2. As can be seen, the Contextual-Trunc model consistently performed better than the Dirichlet Priors model. The Contextual model, by contrast, performed almost as well as the Contextual-Trunc model in two cases, but was far worse than the other models in the Algebra data set. The primary difference appears to have been that the Algebra Contextual model predicted massively more slips than the other two models did. Whereas the average value of P(S) (across skills) in the Algebra Dirichlet Priors model was 0.19, and the average value of P(S) (across actions) in the Algebra Contextual-Trunc model was 0.38, the average value of P(S) (across actions) in the Algebra Contextual model was 0.67. Values of the slip parameter above 0.5 are degenerate, as discussed earlier; these values cause the model to very quickly infer that a student has mastered a skill, even when the student displays poor performance. By truncating the data set used to train the contextual model of slipping, the Contextual-Trunc model avoids this degenerate performance and is significantly more successful at predicting student performance. 
 7 Conclusions.
 In this paper, we have presented an improvement to the Contextual Guess and Slip model proposed in [2]. Earlier models of student knowledge [cf. 7,9] estimated a single probability of guessing and slipping for each skill, and used that estimate for all actions. By contrast, the model presented here (and the model in [2]) contextually estimate the probability that a student obtained a correct answer by guessing, or an incorrect answer by slipping. The Contextual models also use fewer parameters to estimate student knowledge than previous models. In earlier work [2], contextual models of guess and slip were trained using every action involving non-degenerate skills. In this paper, we adjusted the training set, removing actions where the probability that the student already knows the skill is below 0.1 or above 0.9. Truncating the training set in this fashion avoids training on cases where probabilities of guess or slip are close to 0 or 1 due to prior probabilities rather than the information contained in successive actions. We show that using a truncated training set leads to models which are statistically significantly better at predicting future student performance than the Dirichlet Priors approach to parameter selection. A non-truncated training set is also better than Dirichlet Priors in two cases, but in a third case (the Algebra data set) performs significantly worse, due to assigning degenerate values for the slip parameter. This shows that it is valuable to test new student modeling methods on data sets from different learning software (increasingly available in publicly accessible databases such as the PSLC DataShop), since the non-truncated data set would have been perfectly adequate in the Geometry and Middle School data sets. Further investigation of how to optimally truncate training sets is probably warranted. The choice of 0.1 and 0.9 as cut-offs in this data set is based on data but ultimately arbitrary, and while the solution is effective, a more principled method for selecting cut- offs may lead to better performance. Studying whether truncation of training sets is useful to other classification problems in educational data is another area for future work; input probabilities very close to 0 or 1 are likely to bias the output of any Bayesian method. At this point, contextual estimation of guess and slip has proven to be better at predicting future performance than earlier methods for student knowledge modeling, for three different learning systems. In the long term, more sensitive and accurate estimation of student knowledge has the potential to improve the effectiveness of learning software. Additionally, as accurate knowledge modeling is a key component of models of complex student behavior used in data mining analyses [cf. 4, 10], better knowledge modeling is likely to be useful to the broader advancement of the field of educational data mining. 
 8 Acknowledgements.
 We would like to thank Project LISTEN and Joseph Beck for offering the BNT-SM toolkit used within our model creation process. This work was funded by NSF grant REC-043779 to “IERI: Learning-Oriented Dialogs in Cognitive Tutors: Toward a Scalable Solution to Performance Orientation”, and by the Pittsburgh Science of Learning Center, National Science Foundation award SBE-0354420.]]></led:body>
		<swrc:month></swrc:month>
		<swrc:year>2008</swrc:year>
		<rdfs:label>Improving Contextual Models of Guessing and Slipping with a Truncated Training Set</rdfs:label>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/ryan-sjd-baker"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/ryan-sjd-baker"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/albert-t-corbett"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/albert-t-corbett"/>
		<dc:creator rdf:resource="http://data.linkededucation.org/resource/lak/person/vincent-aleven"/>
		<foaf:maker rdf:resource="http://data.linkededucation.org/resource/lak/person/vincent-aleven"/>
	</swrc:InProceedings>
	<rdf:Description rdf:about="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/239/authorlist">
		<rdf:_1 rdf:resource="http://data.linkededucation.org/resource/lak/person/ryan-sjd-baker"/>
		<rdf:_2 rdf:resource="http://data.linkededucation.org/resource/lak/person/albert-t-corbett"/>
		<rdf:_3 rdf:resource="http://data.linkededucation.org/resource/lak/person/vincent-aleven"/>
	</rdf:Description>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/arizona-state-university">
		<rdfs:label>Arizona State University</rdfs:label>
		<foaf:name>Arizona State University</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/danielle-s-mcnamara"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/kurt-vanlehn"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/bentley-college">
		<rdfs:label>Bentley College</rdfs:label>
		<foaf:name>Bentley College</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/roland-hubscher"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/beuth-hochschule-fur-technik-berlin">
		<rdfs:label>Beuth Hochschule fur Technik Berlin</rdfs:label>
		<foaf:name>Beuth Hochschule fur Technik Berlin</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/agathe-merceron"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/sebastian-schwarzrock"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/birkbeck-college">
		<rdfs:label>Birkbeck College</rdfs:label>
		<foaf:name>Birkbeck College</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/sergio-gutierrez"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university">
		<rdfs:label>Carnegie Mellon University</rdfs:label>
		<foaf:name>Carnegie Mellon University</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/ilya-m-goldin"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/vincent-aleven"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/bruce-m-mclaren"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/michael-v-yudelson"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/emma-brunskill"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/martina-a-rau"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/jung-in-lee"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/leigh-ann-sudol-delyser"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/kelly-rivers"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/richard-scheines"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/john-c-stamper"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/derek-lomas"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/jessica-kalka"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/angela-z-wagner"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/gail-w-kusbit"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/jose-p-gonzalez-brenes"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/jack-mostow"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/elizabeth-a-mclaughlin"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/stephen-e-fancsali"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/yanbo-xu"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/p-pavlik-jr"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/geoff-gordon"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/nan-li"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/noboru-matsuda"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/william-w-cohen"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/weisi-duan"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/s-isotani"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/m-munna"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/s-wu"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/bao-hong-tan"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/albert-t-corbett"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/jon-m-fincham"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/john-r-anderson"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/shawn-betts"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/jennifer-l-ferris"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/rebecca-nugent"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/turadg-aleahmad"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/robert-kraut"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/benjamin-shih"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/hao-cen"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/carolyn-p-rose"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/yue-cui"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/adriana-mjb-de-carvalho"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/xiaonan-zhang"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-valeri"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/lili-wu"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/kyle-cunningham"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/alida-skogsholm"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/brett-leber"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/clausthal-university-of-technology">
		<rdfs:label>Clausthal University of Technology</rdfs:label>
		<foaf:name>Clausthal University of Technology</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/niels-pinkwart"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/cordoba-university">
		<rdfs:label>Cordoba University</rdfs:label>
		<foaf:name>Cordoba University</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/pedro-g-espejo"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/cesar-hervas"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/ecole-polytechnique-de-montreal">
		<rdfs:label>Ecole Polytechnique de Montreal</rdfs:label>
		<foaf:name>Ecole Polytechnique de Montreal</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/behzad-beheshti"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/michel-c-desmarais"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/rhouma-naceur"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/eindhoven-university-of-technology">
		<rdfs:label>Eindhoven University of Technology</rdfs:label>
		<foaf:name>Eindhoven University of Technology</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/rafal-kocielnik"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/mykola-pechenizkiy"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/natalia-sidorova"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/n-trcka"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/p-de-bra"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/ekaterina-vasilyeva"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/evgeny-knutov"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/sicco-verwer"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/wil-van-der-aalst"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/gerben-w-dekker"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/jan-m-vleeshouwers"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/toon-calders"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/eps-universidad-autonoma-de-madrid">
		<rdfs:label>EPS-Universidad Autonoma de Madrid</rdfs:label>
		<foaf:name>EPS-Universidad Autonoma de Madrid</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/manuel-freire"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/grand-ledge-public-schools">
		<rdfs:label>Grand Ledge Public Schools</rdfs:label>
		<foaf:name>Grand Ledge Public Schools</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/christina-trotochaud"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/institute-of-education">
		<rdfs:label>Institute of Education</rdfs:label>
		<foaf:name>Institute of Education</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/manolis-mavrikis"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/michigan-state-university">
		<rdfs:label>Michigan State University</rdfs:label>
		<foaf:name>Michigan State University</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/nell-duke"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/niigata-university">
		<rdfs:label>Niigata University</rdfs:label>
		<foaf:name>Niigata University</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/safia-abbas"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/hajime-sawamura"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/northwestern-university">
		<rdfs:label>Northwestern University</rdfs:label>
		<foaf:name>Northwestern University</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/r-benjamin-shapiro"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/hisham-petry"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/louis-m-gomez"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/polytechnique-montreal">
		<rdfs:label>Polytechnique Montreal</rdfs:label>
		<foaf:name>Polytechnique Montreal</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/ildiko-pelczer"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/alejandro-villarreal"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/michel-gagnon"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/stanford-university">
		<rdfs:label>Stanford University</rdfs:label>
		<foaf:name>Stanford University</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/dave-barker-plummer"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/min-chi"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/worsley"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/blikstein"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/technical-university-of-lisbon">
		<rdfs:label>Technical University of Lisbon</rdfs:label>
		<foaf:name>Technical University of Lisbon</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/pedro-crespo"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/claudia-antunes"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/j-barracosa"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/tel-aviv-university">
		<rdfs:label>Tel Aviv University</rdfs:label>
		<foaf:name>Tel Aviv University</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/rafi-nachmias"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/sharon-hardof-jaffe"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/ronit-azran"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/university-of-california">
		<rdfs:label>University of California</rdfs:label>
		<foaf:name>University of California</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/anna-n-rafferty"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/michelle-m-lamar"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/thomas-l-griffiths"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/stuart-russell"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/elizabeth-ayers"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/university-of-canterbury">
		<rdfs:label>University of Canterbury</rdfs:label>
		<foaf:name>University of Canterbury</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/antonija-mitrovic"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/moffat-mathews"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/tanja-mitrovic"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/university-of-canterbury">
		<rdfs:label>University of Canterbury</rdfs:label>
		<foaf:name>University of Canterbury</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/antonija-mitrovic"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/moffat-mathews"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/tanja-mitrovic"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/university-of-cordoba">
		<rdfs:label>University of Cordoba</rdfs:label>
		<foaf:name>University of Cordoba</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/mi-lopez"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/jm-luna"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/c-romero"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/s-ventura"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/mm-molina"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/r-pedraza-perez"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/jose-raul-romero"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/enrique-garcia"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/carlos-de-castro"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/amelia-zafra"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/university-of-glasgow">
		<rdfs:label>University of Glasgow</rdfs:label>
		<foaf:name>University of Glasgow</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/nema-dean"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/university-of-missouri">
		<rdfs:label>University of Missouri</rdfs:label>
		<foaf:name>University of Missouri</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/kwangsu-cho"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/university-of-north-carolina-at-charlotte">
		<rdfs:label>University of North Carolina at Charlotte</rdfs:label>
		<foaf:name>University of North Carolina at Charlotte</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/michael-john-eagle"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/matthew-w-johnson"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/tiffany-barnes"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/leena-joseph"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/b-mostafavi"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/m-croy"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/lorrie-lehman"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/university-of-pittsburgh">
		<rdfs:label>University of Pittsburgh</rdfs:label>
		<foaf:name>University of Pittsburgh</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/pamela-jordan"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/peter-brusilovsky"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/wenting-xiong"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/diane-litman"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/christian-schunn"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/collin-lynch"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/kevin-d-ashley"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/moses-hall"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/university-of-sydney">
		<rdfs:label>University of Sydney</rdfs:label>
		<foaf:name>University of Sydney</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/roberto-martinez-maldonado"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/kalina-yacef"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/judy-kay"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/irena-koprinska"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/anna-katrina-dominguez"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/james-r-curran"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/rajibussalim"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/vilaythong-southavilay"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/rafael-a-calvo"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/sunghwan-mac-kim"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/university-of-utah">
		<rdfs:label>University of Utah</rdfs:label>
		<foaf:name>University of Utah</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/cecily-heiner"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-l-zachary"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/university-of-wisconsin">
		<rdfs:label>University of Wisconsin</rdfs:label>
		<foaf:name>University of Wisconsin</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/sadhana-puntambekar"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/vanderbilt-university">
		<rdfs:label>Vanderbilt University</rdfs:label>
		<foaf:name>Vanderbilt University</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/john-s-kinnebrew"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/gautam-biswas"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/larry-howard"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/julie-johnson"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/carin-neitzel"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/hogyeong-jeong"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/virginia-tech">
		<rdfs:label>Virginia Tech</rdfs:label>
		<foaf:name>Virginia Tech</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/anthony-allevato"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/matthew-thornton"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/stephen-h-edwards"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/manuel-a-perez-quinones"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute">
		<rdfs:label>Worcester Polytechnic Institute</rdfs:label>
		<foaf:name>Worcester Polytechnic Institute</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/zachary-a-pardos"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/qing-yang-wang"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/shubhendu-trivedi"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/ryan-sjd-baker"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/yutao-wang"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-e-beck"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/sujith-m-gowda"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/michael-wixon"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/aatish-salvi"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/jaclyn-ocumpaugh"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/lisa-rossi"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/gabor-n-sarkozy"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/c-heffernan"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/yue-gong"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/dovan-rai"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/arnon-hershkovitz"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/j-gobert"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/adam-b-goldstein"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/matt-bachmann"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/michael-a-sao-pedro"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/orlando-montalvo"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/adam-nakama"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/mingyu-feng"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/carolina-ruiz"/>
	</foaf:Organization>
	<foaf:Organization rdf:about="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute">
		<rdfs:label>Worcester Polytechnic Institute</rdfs:label>
		<foaf:name>Worcester Polytechnic Institute</foaf:name>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/zachary-a-pardos"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/qing-yang-wang"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/shubhendu-trivedi"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/ryan-sjd-baker"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/yutao-wang"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/joseph-e-beck"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/sujith-m-gowda"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/michael-wixon"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/aatish-salvi"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/jaclyn-ocumpaugh"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/lisa-rossi"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/gabor-n-sarkozy"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/c-heffernan"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/yue-gong"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/dovan-rai"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/arnon-hershkovitz"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/j-gobert"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/adam-b-goldstein"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/matt-bachmann"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/michael-a-sao-pedro"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/orlando-montalvo"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/adam-nakama"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/mingyu-feng"/>
		<foaf:member rdf:resource="http://data.linkededucation.org/resource/lak/person/carolina-ruiz"/>
	</foaf:Organization>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/kurt-vanlehn">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/arizona-state-university"/>
		<rdfs:label>Kurt Vanlehn</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Kurt</foaf:firstName>
		<foaf:lastName>Vanlehn</foaf:lastName>
		<foaf:mbox_sha1sum>da39a3ee5e6b4b0d3255bfef95601890afd80709</foaf:mbox_sha1sum>
		<foaf:name>Kurt Vanlehn</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/233"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/roland-hubscher">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/bentley-college"/>
		<rdfs:label>Roland Hubscher</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Roland</foaf:firstName>
		<foaf:lastName>Hubscher</foaf:lastName>
		<foaf:mbox_sha1sum>2eb9b19833c5ae61345dda3e6aacf4a5bd3efbb0</foaf:mbox_sha1sum>
		<foaf:name>Roland Hubscher</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/222"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/agathe-merceron">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/beuth-hochschule-fur-technik-berlin"/>
		<rdfs:label>Agathe Merceron</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Germany"/>
		<foaf:firstName>Agathe</foaf:firstName>
		<foaf:lastName>Merceron</foaf:lastName>
		<foaf:mbox_sha1sum>8ee6764a7b05a55e48bddb0480c946579d970f51</foaf:mbox_sha1sum>
		<foaf:name>Agathe Merceron</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/211"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/sergio-gutierrez">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/birkbeck-college"/>
		<rdfs:label>Sergio Gutierrez</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/UK"/>
		<foaf:firstName>Sergio</foaf:firstName>
		<foaf:lastName>Gutierrez</foaf:lastName>
		<foaf:mbox_sha1sum>37594b00f4048d43e14423ba9ef2e248511da385</foaf:mbox_sha1sum>
		<foaf:name>Sergio Gutierrez</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/224"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/john-c-stamper">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>John C. Stamper</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>John</foaf:firstName>
		<foaf:lastName>C. Stamper</foaf:lastName>
		<foaf:mbox_sha1sum>bfaeaa7192e9815d69eb5153d89e3962b4bcd7c5</foaf:mbox_sha1sum>
		<foaf:name>John C. Stamper</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/212"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/jack-mostow">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Jack Mostow</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Jack</foaf:firstName>
		<foaf:lastName>Mostow</foaf:lastName>
		<foaf:mbox_sha1sum>cfcda98863a9ad325506c095b9e5e5f3e019de5d</foaf:mbox_sha1sum>
		<foaf:name>Jack Mostow</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/209"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/235"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/alida-skogsholm">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Alida Skogsholm</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Alida</foaf:firstName>
		<foaf:lastName>Skogsholm</foaf:lastName>
		<foaf:mbox_sha1sum>652efd9db8974f9f6b91f5c3376f425f24210b9a</foaf:mbox_sha1sum>
		<foaf:name>Alida Skogsholm</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/228"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/rebecca-nugent">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Rebecca Nugent</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Rebecca</foaf:firstName>
		<foaf:lastName>Nugent</foaf:lastName>
		<foaf:mbox_sha1sum>8e3f2493492992c603e53cd69fa4b57e54c2c860</foaf:mbox_sha1sum>
		<foaf:name>Rebecca Nugent</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/216"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/jack-mostow">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Jack Mostow</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Jack</foaf:firstName>
		<foaf:lastName>Mostow</foaf:lastName>
		<foaf:mbox_sha1sum>cfcda98863a9ad325506c095b9e5e5f3e019de5d</foaf:mbox_sha1sum>
		<foaf:name>Jack Mostow</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/209"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/235"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/hao-cen">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Hao Cen</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Hao</foaf:firstName>
		<foaf:lastName>Cen</foaf:lastName>
		<foaf:mbox_sha1sum>a37887427b172bd01b8bc0d04c1d0c8792541c27</foaf:mbox_sha1sum>
		<foaf:name>Hao Cen</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/219"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/vincent-aleven">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Vincent Aleven</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Vincent</foaf:firstName>
		<foaf:lastName>Aleven</foaf:lastName>
		<foaf:mbox_sha1sum>694107a0b6904a685e35b22902a10a7376409e41</foaf:mbox_sha1sum>
		<foaf:name>Vincent Aleven</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/214"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/239"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/brett-leber">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Brett Leber</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Brett</foaf:firstName>
		<foaf:lastName>Leber</foaf:lastName>
		<foaf:mbox_sha1sum>21bfe0f50dfde3ada5f3d32f595ef464aa4ebfcc</foaf:mbox_sha1sum>
		<foaf:name>Brett Leber</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/228"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/xiaonan-zhang">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Xiaonan Zhang</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Xiaonan</foaf:firstName>
		<foaf:lastName>Zhang</foaf:lastName>
		<foaf:mbox_sha1sum>c68e5e9cc5518458ea24acf511ded151c3f42c8e</foaf:mbox_sha1sum>
		<foaf:name>Xiaonan Zhang</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/209"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/235"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Kenneth R. Koedinger</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Kenneth</foaf:firstName>
		<foaf:lastName>R. Koedinger</foaf:lastName>
		<foaf:mbox_sha1sum>0f1e313636d51d167f86b5b0daddf63f02ca3ca3</foaf:mbox_sha1sum>
		<foaf:name>Kenneth R. Koedinger</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/219"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/221"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/228"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/lili-wu">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Lili Wu</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Lili</foaf:firstName>
		<foaf:lastName>Wu</foaf:lastName>
		<foaf:mbox_sha1sum>c53f7e7e79e596188be68cd20d8ffcc9168c457b</foaf:mbox_sha1sum>
		<foaf:name>Lili Wu</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/219"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/adriana-mjb-de-carvalho">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Adriana M.j.b. De Carvalho</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Adriana</foaf:firstName>
		<foaf:lastName>M.j.b. De Carvalho</foaf:lastName>
		<foaf:mbox_sha1sum>da39a3ee5e6b4b0d3255bfef95601890afd80709</foaf:mbox_sha1sum>
		<foaf:name>Adriana M.j.b. De Carvalho</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/237"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/benjamin-shih">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Benjamin Shih</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Benjamin</foaf:firstName>
		<foaf:lastName>Shih</foaf:lastName>
		<foaf:mbox_sha1sum>51a67fffd13772fbc5ff6f407b8e5ae51d90700a</foaf:mbox_sha1sum>
		<foaf:name>Benjamin Shih</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/221"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/albert-t-corbett">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Albert T. Corbett</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Albert</foaf:firstName>
		<foaf:lastName>T. Corbett</foaf:lastName>
		<foaf:mbox_sha1sum>2546e2efa8f61b061a0636b16acb57e12856a6c1</foaf:mbox_sha1sum>
		<foaf:name>Albert T. Corbett</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/209"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/239"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Kenneth R. Koedinger</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Kenneth</foaf:firstName>
		<foaf:lastName>R. Koedinger</foaf:lastName>
		<foaf:mbox_sha1sum>0f1e313636d51d167f86b5b0daddf63f02ca3ca3</foaf:mbox_sha1sum>
		<foaf:name>Kenneth R. Koedinger</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/219"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/221"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/228"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Kenneth R. Koedinger</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Kenneth</foaf:firstName>
		<foaf:lastName>R. Koedinger</foaf:lastName>
		<foaf:mbox_sha1sum>0f1e313636d51d167f86b5b0daddf63f02ca3ca3</foaf:mbox_sha1sum>
		<foaf:name>Kenneth R. Koedinger</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/219"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/221"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/228"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Kenneth R. Koedinger</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Kenneth</foaf:firstName>
		<foaf:lastName>R. Koedinger</foaf:lastName>
		<foaf:mbox_sha1sum>0f1e313636d51d167f86b5b0daddf63f02ca3ca3</foaf:mbox_sha1sum>
		<foaf:name>Kenneth R. Koedinger</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/219"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/221"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/228"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/joseph-valeri">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Joseph Valeri</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Joseph</foaf:firstName>
		<foaf:lastName>Valeri</foaf:lastName>
		<foaf:mbox_sha1sum>e2a2a1698d53f0d9a2ac9e7e503022a8c31f1513</foaf:mbox_sha1sum>
		<foaf:name>Joseph Valeri</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/209"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/kenneth-r-koedinger">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Kenneth R. Koedinger</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Kenneth</foaf:firstName>
		<foaf:lastName>R. Koedinger</foaf:lastName>
		<foaf:mbox_sha1sum>0f1e313636d51d167f86b5b0daddf63f02ca3ca3</foaf:mbox_sha1sum>
		<foaf:name>Kenneth R. Koedinger</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/219"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/221"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/228"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/vincent-aleven">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Vincent Aleven</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Vincent</foaf:firstName>
		<foaf:lastName>Aleven</foaf:lastName>
		<foaf:mbox_sha1sum>694107a0b6904a685e35b22902a10a7376409e41</foaf:mbox_sha1sum>
		<foaf:name>Vincent Aleven</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/214"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/239"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/xiaonan-zhang">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Xiaonan Zhang</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Xiaonan</foaf:firstName>
		<foaf:lastName>Zhang</foaf:lastName>
		<foaf:mbox_sha1sum>c68e5e9cc5518458ea24acf511ded151c3f42c8e</foaf:mbox_sha1sum>
		<foaf:name>Xiaonan Zhang</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/209"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/235"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/kyle-cunningham">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Kyle Cunningham</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Kyle</foaf:firstName>
		<foaf:lastName>Cunningham</foaf:lastName>
		<foaf:mbox_sha1sum>fb90bbbbf69d3abbd202b6db0bcce517b24baac6</foaf:mbox_sha1sum>
		<foaf:name>Kyle Cunningham</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/228"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/albert-t-corbett">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Albert T. Corbett</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Albert</foaf:firstName>
		<foaf:lastName>T. Corbett</foaf:lastName>
		<foaf:mbox_sha1sum>2546e2efa8f61b061a0636b16acb57e12856a6c1</foaf:mbox_sha1sum>
		<foaf:name>Albert T. Corbett</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/209"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/239"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/richard-scheines">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>Richard Scheines</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Richard</foaf:firstName>
		<foaf:lastName>Scheines</foaf:lastName>
		<foaf:mbox_sha1sum>b5357d50a33f46391728d9d3a3c5f3a3e0a90760</foaf:mbox_sha1sum>
		<foaf:name>Richard Scheines</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/221"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/p-pavlik-jr">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/carnegie-mellon-university"/>
		<rdfs:label>P. Pavlik Jr</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>P.</foaf:firstName>
		<foaf:lastName>Pavlik Jr</foaf:lastName>
		<foaf:mbox_sha1sum>85528a9cf2d288d3dae150bfbc031ae708989272</foaf:mbox_sha1sum>
		<foaf:name>P. Pavlik Jr</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/219"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/niels-pinkwart">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/clausthal-university-of-technology"/>
		<rdfs:label>Niels Pinkwart</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Niels</foaf:firstName>
		<foaf:lastName>Pinkwart</foaf:lastName>
		<foaf:mbox_sha1sum>3537e6de4b95ee485ec1e0a31d6df95329603ef7</foaf:mbox_sha1sum>
		<foaf:name>Niels Pinkwart</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/214"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/pedro-g-espejo">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/cordoba-university"/>
		<rdfs:label>Pedro G. Espejo</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Spain"/>
		<foaf:firstName>Pedro</foaf:firstName>
		<foaf:lastName>G. Espejo</foaf:lastName>
		<foaf:mbox_sha1sum>b585b81fc069d693c003791ab6d04f84617b001f</foaf:mbox_sha1sum>
		<foaf:name>Pedro G. Espejo</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/231"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/cesar-hervas">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/cordoba-university"/>
		<rdfs:label>Cesar Hervas</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Spain"/>
		<foaf:firstName>Cesar</foaf:firstName>
		<foaf:lastName>Hervas</foaf:lastName>
		<foaf:mbox_sha1sum>e83e6c0dcb3e5f64a2197c6c8c113379395073ee</foaf:mbox_sha1sum>
		<foaf:name>Cesar Hervas</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/231"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/236"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/cesar-hervas">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/cordoba-university"/>
		<rdfs:label>Cesar Hervas</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Spain"/>
		<foaf:firstName>Cesar</foaf:firstName>
		<foaf:lastName>Hervas</foaf:lastName>
		<foaf:mbox_sha1sum>e83e6c0dcb3e5f64a2197c6c8c113379395073ee</foaf:mbox_sha1sum>
		<foaf:name>Cesar Hervas</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/231"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/236"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/michel-c-desmarais">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/ecole-polytechnique-de-montreal"/>
		<rdfs:label>Michel C. Desmarais</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Canada"/>
		<foaf:firstName>Michel</foaf:firstName>
		<foaf:lastName>C. Desmarais</foaf:lastName>
		<foaf:mbox_sha1sum>a706c2f86e96db418a4437eea2da031a806698fc</foaf:mbox_sha1sum>
		<foaf:name>Michel C. Desmarais</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/238"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/p-de-bra">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/eindhoven-university-of-technology"/>
		<rdfs:label>P. De Bra</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Netherlands"/>
		<foaf:firstName>P.</foaf:firstName>
		<foaf:lastName>De Bra</foaf:lastName>
		<foaf:mbox_sha1sum>5e6e0140af8fc08b5b9df45f327ebf20cf224f18</foaf:mbox_sha1sum>
		<foaf:name>P. De Bra</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/229"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/mykola-pechenizkiy">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/eindhoven-university-of-technology"/>
		<rdfs:label>Mykola Pechenizkiy</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Netherlands"/>
		<foaf:firstName>Mykola</foaf:firstName>
		<foaf:lastName>Pechenizkiy</foaf:lastName>
		<foaf:mbox_sha1sum>92ec847241e20acbe9bd8be3fda6d568619228d8</foaf:mbox_sha1sum>
		<foaf:name>Mykola Pechenizkiy</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/229"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/toon-calders">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/eindhoven-university-of-technology"/>
		<rdfs:label>Toon Calders</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Netherlands"/>
		<foaf:firstName>Toon</foaf:firstName>
		<foaf:lastName>Calders</foaf:lastName>
		<foaf:mbox_sha1sum>b0357548865bacdaa1472c86155bea8c879ee8a6</foaf:mbox_sha1sum>
		<foaf:name>Toon Calders</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/229"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/ekaterina-vasilyeva">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/eindhoven-university-of-technology"/>
		<rdfs:label>Ekaterina Vasilyeva</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Netherlands"/>
		<foaf:firstName>Ekaterina</foaf:firstName>
		<foaf:lastName>Vasilyeva</foaf:lastName>
		<foaf:mbox_sha1sum>836e3a34e8066b0b9c2708abc07e75eab24445a8</foaf:mbox_sha1sum>
		<foaf:name>Ekaterina Vasilyeva</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/229"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/manuel-freire">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/eps-universidad-autonoma-de-madrid"/>
		<rdfs:label>Manuel Freire</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Spain"/>
		<foaf:firstName>Manuel</foaf:firstName>
		<foaf:lastName>Freire</foaf:lastName>
		<foaf:mbox_sha1sum>61ec5e53cef540bd9f995ae7b8033c07ca0ae8a9</foaf:mbox_sha1sum>
		<foaf:name>Manuel Freire</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/224"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/christina-trotochaud">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/grand-ledge-public-schools"/>
		<rdfs:label>Christina Trotochaud</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Christina</foaf:firstName>
		<foaf:lastName>Trotochaud</foaf:lastName>
		<foaf:mbox_sha1sum>4f56c281ef06fb25e7365dd9de9b2dd9fa023b1f</foaf:mbox_sha1sum>
		<foaf:name>Christina Trotochaud</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/209"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/manolis-mavrikis">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/institute-of-education"/>
		<rdfs:label>Manolis Mavrikis</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/UK"/>
		<foaf:firstName>Manolis</foaf:firstName>
		<foaf:lastName>Mavrikis</foaf:lastName>
		<foaf:mbox_sha1sum>34d650ae118a34f0975adde00d0d3d3428049e79</foaf:mbox_sha1sum>
		<foaf:name>Manolis Mavrikis</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/232"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/nell-duke">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/michigan-state-university"/>
		<rdfs:label>Nell Duke</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Nell</foaf:firstName>
		<foaf:lastName>Duke</foaf:lastName>
		<foaf:mbox_sha1sum>bcff3f5540c529c222f22ff02bbd5e1ff90fda8b</foaf:mbox_sha1sum>
		<foaf:name>Nell Duke</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/209"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/safia-abbas">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/niigata-university"/>
		<rdfs:label>Safia Abbas</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/JAPAN"/>
		<foaf:firstName>Safia</foaf:firstName>
		<foaf:lastName>Abbas</foaf:lastName>
		<foaf:mbox_sha1sum>57c8301f458f586726549b0f1140bba0679041e3</foaf:mbox_sha1sum>
		<foaf:name>Safia Abbas</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/215"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/hajime-sawamura">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/niigata-university"/>
		<rdfs:label>Hajime Sawamura</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/JAPAN"/>
		<foaf:firstName>Hajime</foaf:firstName>
		<foaf:lastName>Sawamura</foaf:lastName>
		<foaf:mbox_sha1sum>fa4e773c240d1d130f205667d3610a3d44305fd2</foaf:mbox_sha1sum>
		<foaf:name>Hajime Sawamura</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/215"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/hisham-petry">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/northwestern-university"/>
		<rdfs:label>Hisham Petry</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Hisham</foaf:firstName>
		<foaf:lastName>Petry</foaf:lastName>
		<foaf:mbox_sha1sum>7ecfeb3c83d603a23411fd182210b4d33e22273a</foaf:mbox_sha1sum>
		<foaf:name>Hisham Petry</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/220"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/louis-m-gomez">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/northwestern-university"/>
		<rdfs:label>Louis M. Gomez</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Louis</foaf:firstName>
		<foaf:lastName>M. Gomez</foaf:lastName>
		<foaf:mbox_sha1sum>230f4e41e77ebeba45b487fd9441fb05b5056c56</foaf:mbox_sha1sum>
		<foaf:name>Louis M. Gomez</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/220"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/r-benjamin-shapiro">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/northwestern-university"/>
		<rdfs:label>R. Benjamin Shapiro</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>R.</foaf:firstName>
		<foaf:lastName>Benjamin Shapiro</foaf:lastName>
		<foaf:mbox_sha1sum>d5ff27b1a808f3071b755bb8ade58904af9449c8</foaf:mbox_sha1sum>
		<foaf:name>R. Benjamin Shapiro</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/220"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/michel-gagnon">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/polytechnique-montreal"/>
		<rdfs:label>Michel Gagnon</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Canada"/>
		<foaf:firstName>Michel</foaf:firstName>
		<foaf:lastName>Gagnon</foaf:lastName>
		<foaf:mbox_sha1sum>57eaf56a605e6b7e99b2c41c9320955ac12d1f6a</foaf:mbox_sha1sum>
		<foaf:name>Michel Gagnon</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/238"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/alejandro-villarreal">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/polytechnique-montreal"/>
		<rdfs:label>Alejandro Villarreal</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Canada"/>
		<foaf:firstName>Alejandro</foaf:firstName>
		<foaf:lastName>Villarreal</foaf:lastName>
		<foaf:mbox_sha1sum>aaf005acaa8e15c5b79b99ae38e6de974a5281ad</foaf:mbox_sha1sum>
		<foaf:name>Alejandro Villarreal</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/238"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/min-chi">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/stanford-university"/>
		<rdfs:label>Min Chi</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Min</foaf:firstName>
		<foaf:lastName>Chi</foaf:lastName>
		<foaf:mbox_sha1sum>da39a3ee5e6b4b0d3255bfef95601890afd80709</foaf:mbox_sha1sum>
		<foaf:name>Min Chi</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/233"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/claudia-antunes">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/technical-university-of-lisbon"/>
		<rdfs:label>Claudia Antunes</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Portugal"/>
		<foaf:firstName>Claudia</foaf:firstName>
		<foaf:lastName>Antunes</foaf:lastName>
		<foaf:mbox_sha1sum>3c798f2d88d4fe97acbe7899d4a0105b6ea91a8a</foaf:mbox_sha1sum>
		<foaf:name>Claudia Antunes</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/210"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/rafi-nachmias">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/tel-aviv-university"/>
		<rdfs:label>Rafi Nachmias</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Israel"/>
		<foaf:firstName>Rafi</foaf:firstName>
		<foaf:lastName>Nachmias</foaf:lastName>
		<foaf:mbox_sha1sum>cea4310497b4026a3128713418a30f3d559cc461</foaf:mbox_sha1sum>
		<foaf:name>Rafi Nachmias</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/223"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/elizabeth-ayers">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-california"/>
		<rdfs:label>Elizabeth Ayers</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Elizabeth</foaf:firstName>
		<foaf:lastName>Ayers</foaf:lastName>
		<foaf:mbox_sha1sum>aae9cb2462a54bbcff7dc90d448896423efc64ab</foaf:mbox_sha1sum>
		<foaf:name>Elizabeth Ayers</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/216"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/moffat-mathews">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-canterbury"/>
		<rdfs:label>Moffat Mathews</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Moffat</foaf:firstName>
		<foaf:lastName>Mathews</foaf:lastName>
		<foaf:mbox_sha1sum>c24fded4b25b25920d7d180c0e4ff513a80d7c3a</foaf:mbox_sha1sum>
		<foaf:name>Moffat Mathews</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/227"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/tanja-mitrovic">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-canterbury"/>
		<rdfs:label>Tanja Mitrovic</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/New_Zeland"/>
		<foaf:firstName>Tanja</foaf:firstName>
		<foaf:lastName>Mitrovic</foaf:lastName>
		<foaf:mbox_sha1sum>6a8c6c39fdb2859677b07d7c3ec23e0b28a64b65</foaf:mbox_sha1sum>
		<foaf:name>Tanja Mitrovic</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/227"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/c-romero">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-cordoba"/>
		<rdfs:label>C. Romero</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Spain"/>
		<foaf:firstName>C.</foaf:firstName>
		<foaf:lastName>Romero</foaf:lastName>
		<foaf:mbox_sha1sum>4fa368945fa5e56c76943d4dc36bc95f3b25899f</foaf:mbox_sha1sum>
		<foaf:name>C. Romero</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/224"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/231"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/236"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/c-romero">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-cordoba"/>
		<rdfs:label>C. Romero</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Spain"/>
		<foaf:firstName>C.</foaf:firstName>
		<foaf:lastName>Romero</foaf:lastName>
		<foaf:mbox_sha1sum>4fa368945fa5e56c76943d4dc36bc95f3b25899f</foaf:mbox_sha1sum>
		<foaf:name>C. Romero</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/224"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/231"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/236"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/s-ventura">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-cordoba"/>
		<rdfs:label>S. Ventura</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Spain"/>
		<foaf:firstName>S.</foaf:firstName>
		<foaf:lastName>Ventura</foaf:lastName>
		<foaf:mbox_sha1sum>7cc996020e6d4f219b9c38c3863805c7682d4571</foaf:mbox_sha1sum>
		<foaf:name>S. Ventura</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/224"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/231"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/236"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/s-ventura">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-cordoba"/>
		<rdfs:label>S. Ventura</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Spain"/>
		<foaf:firstName>S.</foaf:firstName>
		<foaf:lastName>Ventura</foaf:lastName>
		<foaf:mbox_sha1sum>7cc996020e6d4f219b9c38c3863805c7682d4571</foaf:mbox_sha1sum>
		<foaf:name>S. Ventura</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/224"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/231"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/236"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/s-ventura">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-cordoba"/>
		<rdfs:label>S. Ventura</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Spain"/>
		<foaf:firstName>S.</foaf:firstName>
		<foaf:lastName>Ventura</foaf:lastName>
		<foaf:mbox_sha1sum>7cc996020e6d4f219b9c38c3863805c7682d4571</foaf:mbox_sha1sum>
		<foaf:name>S. Ventura</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/224"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/231"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/236"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/c-romero">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-cordoba"/>
		<rdfs:label>C. Romero</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Spain"/>
		<foaf:firstName>C.</foaf:firstName>
		<foaf:lastName>Romero</foaf:lastName>
		<foaf:mbox_sha1sum>4fa368945fa5e56c76943d4dc36bc95f3b25899f</foaf:mbox_sha1sum>
		<foaf:name>C. Romero</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/224"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/231"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/236"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/nema-dean">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-glasgow"/>
		<rdfs:label>Nema Dean</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/UK"/>
		<foaf:firstName>Nema</foaf:firstName>
		<foaf:lastName>Dean</foaf:lastName>
		<foaf:mbox_sha1sum>5847deff91aa9447d6418367c31eb9fdc80cc552</foaf:mbox_sha1sum>
		<foaf:name>Nema Dean</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/216"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/kwangsu-cho">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-missouri"/>
		<rdfs:label>Kwangsu Cho</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Kwangsu</foaf:firstName>
		<foaf:lastName>Cho</foaf:lastName>
		<foaf:mbox_sha1sum>0a717ce3bf4eeac25ca513f65b760c20d356f8b3</foaf:mbox_sha1sum>
		<foaf:name>Kwangsu Cho</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/218"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/lorrie-lehman">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-north-carolina-at-charlotte"/>
		<rdfs:label>Lorrie Lehman</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Lorrie</foaf:firstName>
		<foaf:lastName>Lehman</foaf:lastName>
		<foaf:mbox_sha1sum>a56ff7c301c8d8c0106e6b4d3d39a11c6a840dfc</foaf:mbox_sha1sum>
		<foaf:name>Lorrie Lehman</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/212"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/m-croy">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-north-carolina-at-charlotte"/>
		<rdfs:label>M. Croy</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>M.</foaf:firstName>
		<foaf:lastName>Croy</foaf:lastName>
		<foaf:mbox_sha1sum>b12851595d518e2a95690fbb8d187fc0657109d4</foaf:mbox_sha1sum>
		<foaf:name>M. Croy</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/212"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/tiffany-barnes">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-north-carolina-at-charlotte"/>
		<rdfs:label>Tiffany Barnes</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Tiffany</foaf:firstName>
		<foaf:lastName>Barnes</foaf:lastName>
		<foaf:mbox_sha1sum>daf05503be29d62c7a709507c606228daa499645</foaf:mbox_sha1sum>
		<foaf:name>Tiffany Barnes</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/212"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/moses-hall">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-pittsburgh"/>
		<rdfs:label>Moses Hall</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Moses</foaf:firstName>
		<foaf:lastName>Hall</foaf:lastName>
		<foaf:mbox_sha1sum>a3c33c0a4868307847f5e2607026f6d53be5f8f6</foaf:mbox_sha1sum>
		<foaf:name>Moses Hall</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/233"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/collin-lynch">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-pittsburgh"/>
		<rdfs:label>Collin Lynch</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Collin</foaf:firstName>
		<foaf:lastName>Lynch</foaf:lastName>
		<foaf:mbox_sha1sum>34a23ca10e57c1a8dc798e2e6b60a9017e1a48e2</foaf:mbox_sha1sum>
		<foaf:name>Collin Lynch</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/214"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/pamela-jordan">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-pittsburgh"/>
		<rdfs:label>Pamela Jordan</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Pamela</foaf:firstName>
		<foaf:lastName>Jordan</foaf:lastName>
		<foaf:mbox_sha1sum>da39a3ee5e6b4b0d3255bfef95601890afd80709</foaf:mbox_sha1sum>
		<foaf:name>Pamela Jordan</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/233"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/kevin-d-ashley">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-pittsburgh"/>
		<rdfs:label>Kevin D. Ashley</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Kevin</foaf:firstName>
		<foaf:lastName>D. Ashley</foaf:lastName>
		<foaf:mbox_sha1sum>135c74704589bea69af29e5bf6d402b3c091d5ff</foaf:mbox_sha1sum>
		<foaf:name>Kevin D. Ashley</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/214"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/kalina-yacef">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-sydney"/>
		<rdfs:label>Kalina Yacef</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/Australia"/>
		<foaf:firstName>Kalina</foaf:firstName>
		<foaf:lastName>Yacef</foaf:lastName>
		<foaf:mbox_sha1sum>a996139b89c064243c13504322ae7fc688ace4b5</foaf:mbox_sha1sum>
		<foaf:name>Kalina Yacef</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/211"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/cecily-heiner">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-utah"/>
		<rdfs:label>Cecily Heiner</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Cecily</foaf:firstName>
		<foaf:lastName>Heiner</foaf:lastName>
		<foaf:mbox_sha1sum>885affae88e87e0520c1ad7be0e44b1c6cf64d8c</foaf:mbox_sha1sum>
		<foaf:name>Cecily Heiner</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/217"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/sadhana-puntambekar">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/university-of-wisconsin"/>
		<rdfs:label>Sadhana Puntambekar</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Sadhana</foaf:firstName>
		<foaf:lastName>Puntambekar</foaf:lastName>
		<foaf:mbox_sha1sum>1218b27c3374f3ba21b00991d7dad1c39fd4c57e</foaf:mbox_sha1sum>
		<foaf:name>Sadhana Puntambekar</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/222"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/hogyeong-jeong">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/vanderbilt-university"/>
		<rdfs:label>Hogyeong Jeong</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Hogyeong</foaf:firstName>
		<foaf:lastName>Jeong</foaf:lastName>
		<foaf:mbox_sha1sum>2a0a33dd8e91855f6a4c1c2e46416924c2793fc6</foaf:mbox_sha1sum>
		<foaf:name>Hogyeong Jeong</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/226"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/gautam-biswas">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/vanderbilt-university"/>
		<rdfs:label>Gautam Biswas</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Gautam</foaf:firstName>
		<foaf:lastName>Biswas</foaf:lastName>
		<foaf:mbox_sha1sum>da39a3ee5e6b4b0d3255bfef95601890afd80709</foaf:mbox_sha1sum>
		<foaf:name>Gautam Biswas</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/226"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/manuel-a-perez-quinones">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/virginia-tech"/>
		<rdfs:label>Manuel A. Perez-quinones</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Manuel</foaf:firstName>
		<foaf:lastName>A. Perez-quinones</foaf:lastName>
		<foaf:mbox_sha1sum>1efbed7f68eb1692d73b4aadabd79af5bfc42d85</foaf:mbox_sha1sum>
		<foaf:name>Manuel A. Perez-quinones</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/230"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/anthony-allevato">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/virginia-tech"/>
		<rdfs:label>Anthony Allevato</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Anthony</foaf:firstName>
		<foaf:lastName>Allevato</foaf:lastName>
		<foaf:mbox_sha1sum>425c483e8c26802f3465b57e262a6f14b0269c04</foaf:mbox_sha1sum>
		<foaf:name>Anthony Allevato</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/230"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/matthew-thornton">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/virginia-tech"/>
		<rdfs:label>Matthew Thornton</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Matthew</foaf:firstName>
		<foaf:lastName>Thornton</foaf:lastName>
		<foaf:mbox_sha1sum>af4fc162f51f775b0b923af9b1f51cd029eadee3</foaf:mbox_sha1sum>
		<foaf:name>Matthew Thornton</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/230"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/stephen-h-edwards">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/virginia-tech"/>
		<rdfs:label>Stephen H. Edwards</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Stephen</foaf:firstName>
		<foaf:lastName>H. Edwards</foaf:lastName>
		<foaf:mbox_sha1sum>82076258628802112348fb52e3b3134c1ea0c3ff</foaf:mbox_sha1sum>
		<foaf:name>Stephen H. Edwards</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/230"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute"/>
		<rdfs:label>Neil T. Heffernan</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Neil</foaf:firstName>
		<foaf:lastName>T. Heffernan</foaf:lastName>
		<foaf:mbox_sha1sum>8c86318b5e87ca4e61bed8db77402ba0b24d7701</foaf:mbox_sha1sum>
		<foaf:name>Neil T. Heffernan</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/234"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute"/>
		<rdfs:label>Neil T. Heffernan</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Neil</foaf:firstName>
		<foaf:lastName>T. Heffernan</foaf:lastName>
		<foaf:mbox_sha1sum>8c86318b5e87ca4e61bed8db77402ba0b24d7701</foaf:mbox_sha1sum>
		<foaf:name>Neil T. Heffernan</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/234"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/ryan-sjd-baker">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute"/>
		<rdfs:label>Ryan S.j.d. Baker</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Ryan</foaf:firstName>
		<foaf:lastName>S.j.d. Baker</foaf:lastName>
		<foaf:mbox_sha1sum>188538b9d7ab9a3c2883dc5640511f67db9e3aab</foaf:mbox_sha1sum>
		<foaf:name>Ryan S.j.d. Baker</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/237"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/239"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/zachary-a-pardos">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute"/>
		<rdfs:label>Zachary A. Pardos</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Zachary</foaf:firstName>
		<foaf:lastName>A. Pardos</foaf:lastName>
		<foaf:mbox_sha1sum>08ca8bfb6323c3c3b0d306d519cc1ff39b2cfb2e</foaf:mbox_sha1sum>
		<foaf:name>Zachary A. Pardos</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/234"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/ryan-sjd-baker">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute"/>
		<rdfs:label>Ryan S.j.d. Baker</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Ryan</foaf:firstName>
		<foaf:lastName>S.j.d. Baker</foaf:lastName>
		<foaf:mbox_sha1sum>188538b9d7ab9a3c2883dc5640511f67db9e3aab</foaf:mbox_sha1sum>
		<foaf:name>Ryan S.j.d. Baker</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/237"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/239"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/joseph-e-beck">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute"/>
		<rdfs:label>Joseph E. Beck</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Joseph</foaf:firstName>
		<foaf:lastName>E. Beck</foaf:lastName>
		<foaf:mbox_sha1sum>98757703f9ddfd60ced2fbeb80219aee5e11c1b6</foaf:mbox_sha1sum>
		<foaf:name>Joseph E. Beck</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/234"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/joseph-e-beck">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute"/>
		<rdfs:label>Joseph E. Beck</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Joseph</foaf:firstName>
		<foaf:lastName>E. Beck</foaf:lastName>
		<foaf:mbox_sha1sum>98757703f9ddfd60ced2fbeb80219aee5e11c1b6</foaf:mbox_sha1sum>
		<foaf:name>Joseph E. Beck</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/234"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/arnon-hershkovitz">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute"/>
		<rdfs:label>Arnon Hershkovitz</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Arnon</foaf:firstName>
		<foaf:lastName>Hershkovitz</foaf:lastName>
		<foaf:mbox_sha1sum>a63c9b6def54cbcc5d6415c35de988d400ab954e</foaf:mbox_sha1sum>
		<foaf:name>Arnon Hershkovitz</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/223"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/carolina-ruiz">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute"/>
		<rdfs:label>Carolina Ruiz</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Carolina</foaf:firstName>
		<foaf:lastName>Ruiz</foaf:lastName>
		<foaf:mbox_sha1sum>9ef1f9c946529126feb046631eab75c808a8a099</foaf:mbox_sha1sum>
		<foaf:name>Carolina Ruiz</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/234"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/mingyu-feng">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute"/>
		<rdfs:label>Mingyu Feng</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/"/>
		<foaf:firstName>Mingyu</foaf:firstName>
		<foaf:lastName>Feng</foaf:lastName>
		<foaf:mbox_sha1sum>1e94e64b29291795ef21d71ad0c9731a65fc09b8</foaf:mbox_sha1sum>
		<foaf:name>Mingyu Feng</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/neil-t-heffernan">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute"/>
		<rdfs:label>Neil T. Heffernan</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Neil</foaf:firstName>
		<foaf:lastName>T. Heffernan</foaf:lastName>
		<foaf:mbox_sha1sum>8c86318b5e87ca4e61bed8db77402ba0b24d7701</foaf:mbox_sha1sum>
		<foaf:name>Neil T. Heffernan</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/234"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/joseph-e-beck">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute"/>
		<rdfs:label>Joseph E. Beck</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/USA"/>
		<foaf:firstName>Joseph</foaf:firstName>
		<foaf:lastName>E. Beck</foaf:lastName>
		<foaf:mbox_sha1sum>98757703f9ddfd60ced2fbeb80219aee5e11c1b6</foaf:mbox_sha1sum>
		<foaf:name>Joseph E. Beck</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/234"/>
	</foaf:Person>
	<foaf:Person rdf:about="http://data.linkededucation.org/resource/lak/person/mingyu-feng">
		<swrc:affiliation rdf:resource="http://data.linkededucation.org/resource/lak/organization/worcester-polytechnic-institute"/>
		<rdfs:label>Mingyu Feng</rdfs:label>
		<foaf:based_near rdf:resource="http://dbpedia.org/resource/"/>
		<foaf:firstName>Mingyu</foaf:firstName>
		<foaf:lastName>Feng</foaf:lastName>
		<foaf:mbox_sha1sum>1e94e64b29291795ef21d71ad0c9731a65fc09b8</foaf:mbox_sha1sum>
		<foaf:name>Mingyu Feng</foaf:name>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/213"/>
		<foaf:made rdf:resource="http://data.linkededucation.org/resource/lak/conference/edm2008/paper/225"/>
	</foaf:Person>
</rdf:RDF>