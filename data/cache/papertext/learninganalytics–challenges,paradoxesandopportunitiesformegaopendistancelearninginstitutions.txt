1. INTRODUCTION.
 One of the basic premises of learning analytics is that if higher education institutions optimise and analyse the data they hold on their students, they can identity and (more) effectively and appropriately address the challenges that students face, whether they are at risk, underprepared or high performance students. Siemens [10] suggests that learning analytics refers to ‘student-produced data and analysis models to discover information and social connections, and to predict and advise on learning’ (emphasis added). It is true that students produce data and leave trails that higher education institutions may not fully exploit. To focus only on the data trails which students produce may result in the incomplete assumption that they are the primary actors in their learning journeys. Students’ trails and data regarding their activities, actions or non-actions are a useful baseline, but often institutional decisions, efficiencies and non-action on the side of the institution impact equally on students’ choices, and their actions or non-action. This latter perhaps falls into the category of academic rather than learning analytics, though both approaches have many overlapping elements and both are relevant here. We do not see learning analytics as the panacea which will solve all the complexities in understanding student success, attrition or retention. Several authors [7, 8] have cautioned that learning analytics can very easily serve to increasingly bureaucratise students’ learning even further, or serve a panoptical purpose and culture of increasing surveillance rather than empowering students and their institution to facilitate more appropriate choices. In this paper we present two case studies and propose that learning analytics can at least support student success if we consider that both students and institutional data trails are found in the ‘student walk’ as the space where these two actors meet in a ‘Thirdspace’ (as described by various authors) [2, 4, 6, 9, 11]. Our discussions of the potential of learning analytics to help map and engage with this ‘Thirdspace’ are set against the concerns expressed by Tinto [15] who bemoans the fact that, despite all the research done since the first conceptual mappings of student success and retention, the impact on success and retention rates has been minimal. Tinto [14, 15] and others [5] suggest that student departures are more of a ‘puzzle’ than we (currently) accept, and that knowing why students fail does not give us an equal understanding of why students persist or stay despite failing. In their attempt to unravel the ‘student departure puzzle’ [5, 13] indicate that student success and retention is a multidimensional phenomenon where a number of interrelated and often interdependent variables meet in complex relationships. In their socio-critical model for understanding and predicting student success, retention and throughput, Subotzky and Prinsloo [13] aim to provide a conceptual map to identity measureable and actionable data in contrast with data which may ostensibly shape student success, but which are outside the locus of control of both students and the institution. They propose that three interrelated and often interdependent levels of factors impact on student success namely: individual (academic and attitudinal attributes, and other personal characteristics and circumstances); institutional (quality and relevance of academic, non-academic, and administrative services); and supra-institutional (macro-political and socio-economic factors) [13]. Subotzky and Prinsloo [13] propose a number of constructs that underscore their socio-critical conceptual model; and which we find useful as a shared point of departure for our comparative analysis and discussion of the role of learning analytics in mega open distance learning institutions. The constructs are as follows: 1. Students and the institution as situated agents: ‘Success is seen as the outcome of the mutually inﬂuential activities, behaviours, attitudes, and responsibilities of students and the institution’. The situatedness of their agency relates to the ‘structural conditions of their historical, geographical, socio-economic, and cultural backgrounds and circumstances’. Within these structural constraints, both students and the institution are agents, and not merely passive recipients or providers of services. 2. The second construct is that of the ‘student walk’ which embodies the mutually constitutive interactions and relations between students and the institution. 3. The notion, amount and role of ‘capital’ – whether social, epistemological, intellectual or other forms of capital – provides a basis for understanding the socio-critical nature of the ‘student walk’ where mutual engagement and transformation are shaped by engagement and exchanges. 4. The fourth construct refers to the impact of habitus on the agency of both students and the institution, where habitus refers to refers to socially acquired, embodied systems of dispositions and/or predispositions [3]. 5. The fifth construct is the notion that both students and the institution have inter and intra-relational aspect shaping their agency. Students’ intrapersonal relations are shaped by self-efficacy, attribution and locus of control, while their interpersonal relations are the multiple networks impacting and shaping students’ learning. Self-efficacy, attribution and locus of control also apply to the institution within three different domains namely academic, administrative, and non-academic social domains of institutional life. 6. Student success, as a final construct is more broadly constructed than just course success, but also refers to students’ satisfaction with their learning journeys, optimal ‘fit’ between their aspirations and abilities and the institution’s offerings. Student success can also imply not graduating or completing their initial educational aims. Though the detail of the mapping of students’ journeys differs between the OU and Unisa, the constructs developed by Subotzky and Prinsloo [13] encompass, from our understanding, a shared basis for our continued exploration. In determining the potential for analytics to help us make sense of students’ journeys through a ‘Thirdspace’, we must also accept that it is not always feasible, from a student or from an institutional perspective, to act on what the data may be telling us. 
 2. THE STUDENT JOURNEY AS ‘THIRDSPACE’.
 The conceptual model described above illustrates a ‘Thirdspace’, a mostly temporary nexus where students and the institution engage. In a certain sense, this nexus of engagement is a temporary diasporic space for both students and institution. The notion of ‘Thirdspace’, ‘liminal’ or ‘diasporic’ space is used in a range of contexts such as identity, multicultural, phenomenological geography and identity theories discourses by authors such as Bhabha [2], Brah [4] and Soja [11]. Soja [11] describes the Firstspace as the material world in which individuals and communities live; Secondspace as their mental world of beliefs, assumptions and epistemologies. Thirdspace is the space where these two worlds merge and become one temporal space. In the work of Bhabha [2], third space functions as a space where individuals negotiate and renegotiate their assumptions, beliefs, identities in a constant space of becoming. The notion of ‘Thirdspace’ is not commonly used in describing the engagement between students and institutions, except for by Burnapp [6], Whitchurch [16] and in an indirect sense, Barnett [1]. Burnapp [6] uses the notion of the ‘Thirdspace’ in describing international student experiences whilst Whitchurch [16] uses it to describe the fluidness of academic identity in a digital age. Barnett [1] refers to the notion of a ‘third world’ where students find themselves in their trajectories of ‘being and becoming’. In this so-called ‘third world or Thirdspace, students have left the known pre-enrolment spaces and move into a space where their identities, epistemologies and ontologies are shaped by their engagement with academic and professional discourses. A student enrolling in higher education moves from often a highly structured ‘place’ to an undefined and liminal and unstructured space’ [6]. In this ‘Thirdspace’ students are caught in a liminal space between what they were and what they are becoming. They may be labelled as ‘underprepared’, ‘at risk’, ‘illiterate’, or ‘deficient’ – and blamed for not ‘fitting in’ into the world of higher education. Early conceptual models attempting to understand and map student success and retention disproportionately emphasised the responsibility of students to fit in, to prepare for and ensure that they are sufficiently assimilated and integrated into the epistemologies and ways of being required by the higher education of their choice (see for example [5], [13]). The ‘student walk’ as Thirdspace is a temporary space where yet another identity construct and role are imposed on students. This new identity shapes and is shaped by their other identities as mothers, professionals, etc. Students and especially distance education students in ODL settings do not leave their other identities ‘outside’ of their learning, but rather find them in ever-increasing networks of identity constructs. On the other hand, students’ engagement with their studies and institution has the potential to shape their multiple identities in often profound ways. This ‘Thirdspace’ also has implications for the institution which provides learning based on students choices, prior knowledge and aspirations. The success of the ability of the institution to match the aspirations, prior knowledge and levels of preparedness of students has a profound impact on the success of students, attrition and throughput rates. Although this ‘Thirdspace’ is actually, in the context of ODL, a ‘non-place’ or a space of ‘placelessness’ [6], students and other institutional stakeholders leave traces which, if harvested, can help us to understand the complexities of student success, attrition and throughput. Using the actionable intelligence provided by learning analytics allows this ‘Thirdspace’ to be a safe and critical ‘non-place’ of becoming. We suggest that the notion of a ‘Thirdspace’ provides useful pointers for understanding the potential of learning analytics in higher education institutions and more particularly, in mega ODL institutions. We now turn briefly to providing short overviews of two different ODL contexts as basis for our exploration of the challenges, paradoxes and potential of learning analytics. 
 3. ANALYTICS AT THE OPEN UNIVERSITY: A SHORT CASE STUDY.
 The OU supports around 200,000 students each year and collects vast amounts of data about its students, the majority of which is been collated and disseminated to academic units and support departments by a central unit. This unit provides several services in support of the University in supplying external reports and in helping internal staff to better understand student cohorts: 
 - Providing information systems and easy access to student retention and progression data, and demographic profiles. - Delivering and reporting internal and external institutional surveys (student feedback). - Disseminating institutional data and information analysis. - Collaborating internally to undertake ad-hoc projects aimed at enhancing the quality of the student experience. - Supporting internal review processes and external audits. 
 Academic teams typically make use of faculty or module level information to inform curriculum design, for example, by using feedback from surveys sent to students at the end of their module. Other datasets relating to points of withdrawal and student such information have been used to create, for example, a single University-wide model of vulnerability based on historical shared student characteristics. At a very broad level then, the OU has made good use of ongoing data to make adjustments to curriculum design and to form a view of how to provide effective student support. This understanding is well communicated and has provided a shared understanding of a model of support as a generic ‘good fit’ for all students. Since 2005, the OU has captured all outward and inward communications with students and tutors. Currently, over 7.5 million contacts have been recorded, each categorized to reflect the nature of the contact and the resultant outcomes. Until recently, this dataset has largely been a repository for student information and has not been widely exploited to extract cohort information, patterns of behaviour or useful insights into commonalities between programmes of study, approaches to assessment and modes of delivery. In the last two years, greater use has been made of this information and data captured at registration, to develop a fuller understanding of the reasons which lead to student contact and the triggers for student behaviours, which can then be matched to a variety of anticipatory support behaviours. In addition, much work has been invested in the OU’s ability to interrogate its Moodle-based VLE system to track student behaviour and engagement on and between modules. The OU is now moving toward a tailored, at scale and largely automated approach to student support that does not assume that a single model of support fits all, but allows curriculum-based support teams to provide the most time effective, appropriate support for their own student cohort. 
 4. ANALYTICS AT THE UNIVERSITY OF SOUTH AFRICA: A SHORT CASE STUDY.
 Unisa reports to various national higher education and legislative networks on student throughput, module success, and attrition. Most of the data required relates to programme cohort analysis, though analyses regarding student profiles and success in individual modules are also available. Analyses are also available on request by departments, schools or individual lecturers. Until recently, most of the analyses were used by institutional structures for operational planning purposes, and, to a lesser extent, by departments and/or individual lecturers in planning module specific interventions or teaching strategies. Up to 2010, academic and learning analytics at Unisa remained fragmented. There was no coherent and shared understanding of student success as a phenomenon, nor any committee or task team that were either representative of all stakeholders involved in the development, delivery and support of teaching and learning; nor having access to appropriate analyses of institutional and module (course)-specific trends. Different departments responded in their individual capacities to increase student success and retention. Compounding the impact of this fragmented approach was the fact that the analyses conducted focused more on cohort analyses in programmes and institution-wide trends, and not necessarily at module level. In addition, institution-wide interventions and strategies impacted on individual modules with no input from the academic and tutoring staff involved in those modules. However, 2010 saw a major change in the institutional comprehension of the role and impact of learning analytics. Three major developments emerged, namely 
 1. The development and formal acceptance of the socio-critical conceptual model [13] has provided Unisa with an integrated and shared framework for understanding and predicting student success and retention. While there was a general understanding of the notion of the ‘student walk’ or ‘student journey’, there was no clear understanding of the complexities facing both students and the institution in their reciprocal engagement in a ‘Thirdspace’. Successful implementation of a framework will hugely depend on the role and function of learning analytics. Currently the main centralised sources of student data are: 
 - Information provided by students during the application and registration processes - Submission of assignments - Financial interactions with the University - Student activity on the learning management system 
 Other data sources, for example, interactions with tutors or support staff, are not centrally recorded. 2. The second major development in the context of realizing a future for learning analytics is the development and piloting of a ‘student tracking system’. The aim is to map student risk on all currently held historical data. This system will eventually house and track all interactions between students and the institution and generate automated (where appropriate) and personal proactive and reactive responses. 3. The third and final development realizing the potential of learning analytics is the formation of a Student Success Committee. This comprises the major role-players dealing with student retention and success ranging from Senate to administrative, professional and academic departments. 
 5. CHALLENGES, PARADOXES AND POINTERS.
 From the above case studies, the following issues emerge: - Both institutions (like most other higher education and ODL institutions) have huge student datasets. - Perversely, the sheer volume of available data can act as a constraint rather than as an enabler of better understanding both student and institutional behaviours. - At present it is not clear whether the two institutions in question fully understand or have a conceptual map of how the data is used, by whom, and for what purpose. - Both institutions provide analytical services to a range of customers but may need a meta-picture of how data is used and the impact of different strategies based on analyses. - How do overarching institutional goals, for example, widening participation and open access act with or against messages provided by analyses? That is, mega ODL institutions are often balancing conflicting drivers. - While the two institutions in question have different structures and different approaches to the notion of cohort, it is not clear whether there is an institutional perspective which makes sense of cohort and module specific trends. - It is not clear how the results of analyses flow through the organisation, that is, to individuals or support departments and back? - Monitoring and evaluation of support systems based largely on the output of an analytics approach needs to be ongoing for support systems to remain effective and optimal. Such analyses are time intensive. - Both institutions encourage the scholarship of teaching and learning to increase evidence-based approaches to interventions aimed at improving student retention and success. How best then to capture and integrate scholarship practices into institutional sense making processes? - Academics involved in such scholarship may find their efforts to change delivery and teaching strategies based on found evidence frustrated by a lack of institutional support. - Although the data may suggest tailoring, it is not practical for mega ODL institutions to have a multitude of differentiated support systems in place. 
 There are however also some pointers for consideration. The use of analytics at all levels would be more successful if founded on a shared and institutionally-accepted conceptual understanding of the nexus or ‘Thirdspace’ of student and institutional interaction. Analytics should provide an integrated, coordinated and holistic platform for all stakeholders to make sense of and find their own way in supporting student learning and institutional efficiency recognising interrelations and interdependencies. It falls outside of the scope of this paper to argue for a centralised or decentralised approach to analytics, but rather to point to a need for an integrated, coordinated and holistic approach involving all stakeholders who can contribute or use the analyses. 
 6. CONCLUSIONS.
 Learning analytics aims to help us to teach more effectively by providing us timely and appropriate actionable data on which to make choices regarding pedagogy, assessment strategies, student support interventions and use of technology to mention but a few. Using the notion of ‘Thirdspace’ to describe the space where students and institution meet, we explored some of the challenges, paradoxes and potential for learning analytics to better support learning outcomes and student success. If learning analytics is considered only as a tool, then simply having more information about our students may not necessarily change the way we teach. There would be a danger that learning analytics might become part of the broader bureaucratisation of student learning. If however, learning analytics is embedded in organisational culture, systems, and processes, there is the potential to really impact and shape our approaches to student needs, whether as individuals or as groups. Learning analytics is an essential tool for mega ODL institutions for personalising learning as far as possible for very diverse groups of students with even more diverse prior experiences, contexts, aspirations and futures.