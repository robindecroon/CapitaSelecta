INTRODUCTION.
 Epistemic games have been developed in recent years to help players develop domain- specific expertise that characterizes how professionals in a particular domain reason, communicate, and act [1]. For example, learners may learn what it is like to think and act like journalists, artists, business managers, or engineers by using digital learning technologies to solve realistic complex performance tasks. This is accomplished by designing the game in such a way that completing it mimics the core experiences that learners outside the gaming environment would have in a professional practicum in the field. As one might expect, traditional measurement models with latent variables designed for traditional large-scale assessments struggle to jointly accommodate the complexities of the data that arise from these games. Thus, there are currently no off-the- shelf statistical models that can be applied directly to epistemic games to satisfy the desired scaling and reporting purposes; alternative modeling approaches grounded in non-parametric methods appear to be more promising in this regard. 
 In this poster, we report on a comprehensive simulation study for investigating one candidate method that has recently been proposed in the literature called epistemic network analysis (ENA) [3]. The method is purely descriptive at this point and has been applied to real data collected in several different epistemic games. However, it has not been thoroughly investigated using simulation studies that use conditions representing a wide variety of realistic game-play scenarios. In our work we specifically investigate the sensitivity of different ENA statistics to capturing the different learning trajectories of players who play different types of epistemic games. 
 In order to simulate data we used principles from modern latent variable models, specifically models in item response theory (IRT) and diagnostic classification models (DCMs) [2]. In these models, contributions of learner and task characteristics to response probabilities are statistically separated by specifying separable parameters for each. The following table provides an overview of the simulation design for our study. Note that we are specifically investigating various ENA outcome statistics on different metrics. For example, we are using the raw ENA statistics as well as the percentage overlap of empirical confidence bands, computed using the 100 replications, across the entire game play of ENA statistics. The latter approach in particular provides us with a non- parametric approach for sorting learners according to their learning trajectory profiles that can be adapted for real-data analyses. The simulation design further helps us to quantify the relative influence of different design factors on the variation in the raw ENA statistics or secondary derived statistics such as percentage overlap of ENA statistics. For example, the following table shows how most of the variation in one global statistic, the weighted density, is accounted for by the similarity of the underlying learning trajectories independent of the different game conditions as captured by the task parameters. The research is currently ongoing with the goal of having completed results submitted for publication by the end of the summer.