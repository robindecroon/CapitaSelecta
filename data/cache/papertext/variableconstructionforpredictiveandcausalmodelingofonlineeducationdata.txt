1 Introduction.
 Scientists and engineers at the Apollo Group are developing an Individualized Learning Platform (ILP) for online education, the broad overview of which is illustrated by Fig. 1 [1]. The ILP is being constructed using insight from domain experts in cognitive and learning sciences while deploying a data-driven Intelligence Engine that takes input data or “signals” from the ILP and provides appropriate guidance to administrators, faculty, and students to better customize and individualize the online learning experience. A wide variety of information is provided to and recorded by the ILP, including information about learner and faculty context, aspects of curriculum, and so on. Coupling insight from educational theory with the Intelligence Engine will allow the Apollo Group to enhance learner satisfaction while improving learning outcomes and supporting other institutional goals. Ann Brown’s inﬂuential work [2] calls for a designbased empiricism, and the reader will ﬁnd Fig. 1 only slightly adapted from a diagram in that work. The ILP is designed around several core principles, one of which is that guidance be evidence-based [1]. This paper focuses on a candidate methodology to achieve this core objective, focusing on the discovery of causes of positive learning outcomes in the online education environment. The learning management system of the ILP will track student progress and activity in online courses. A central challenge is to determine the predictors, and especially causes, of student learning outcomes given these records of their activities and interactions. 
 Fig.

 1. Illustration of Apollo Group’s Individualized Learning Platform, reproduced from [1]. 
 Predictive models are useful for purposes such as identifying students likely to withdraw from courses or otherwise have negative learning outcomes; such models rely on discovering “symptoms” in student behaviors and activity to predict likely outcomes. If we can identify, from passive observation, students “at risk” for negative learning outcomes, instructors can “ﬂag” students to target existing resources toward them to rectify problems a student may be having. However, “symptoms” and predictors of learning outcomes need not identify causes of learning outcomes. When we acquire causal knowledge, we acquire the ability to predict values of variables post-intervention. Traditional statistical methods focus on predictive tasks, allowing us to forecast or classify from observed attributes of a unit (e.g., student) but not to reliably do so after manipulation of the environment (e.g., online courseware, methods of instruction, etc.). If we are able to identify causes, we can better design interventions to drive learning gain and other positive outcomes for students, knowing that post-intervention these changes will drive better learning outcomes. Further, such knowledge can lead to the development and engineering of better online learning platforms and environments. However, there are several hurdles to overcome to achieve such insight. We focus on the complexity of data collected in the online environment and begin to address the dearth of literature focusing on transforming log-style, transactional data collected in online courseware for use with causal discovery procedures (1). In the next section we sketch an extant framework for causal discovery from non-experimental datasets. In Section 3, we survey a past application of this framework in the online education domain. We outline the multi-faceted complexity of data collected in online education environments in Section 4. In Section 5, we describe a pilot study of data from an online graduate economics course and suggest in Section 6, based on the results of the pilot study, that we need to construct new measures of student behavior from underlying “raw” variables. In Section 7 we outline three remaining general problems for causal discovery in the online education domain and provide concluding remarks in Section 8. 
 2 Causal Discovery from Observational Data.
 Data collected in log ﬁles and databases that underlie online courseware are non-experimental, historical data. As a result, we are rarely in the position to learn causal relations in the paradigmatic manner of the sciences: namely, from randomized experimental data. Despite natural diﬀerences in courses from offering to oﬀering and from instructor to instructor, we as investigators cannot reach into the past to intervene and experiment with courseware or other aspects of the online education experience. Over the past twenty years, there has been a large research program by philosophers, statisticians, and computer scientists to develop many diﬀerent methods for the discovery of causal relations from observational datasets. Much of this research has focused on causal interpretations of probabilistic graphical models, speciﬁcally directed acyclic2 graphs (DAGs) with associated probability distributions, called Bayesian networks ([7], [8]). Within this formalism, variables are represented by nodes in a graph with edges between nodes representing direct causal relationships between variables. Consider the graph of Fig. 2, modeling qualitative, hypothetical causal relationships among attributes of students in an imaginary online course. Several attributes might be particularly salient for non-traditional students to whom online education and degree programs are appealing. We model relationships between hypothetical measures of employment, size of family (familySize), time obligations not related to a student’s education (obligations), time spent studying, motivation, length of messages in an online discussion forum (messageLength), academic ability, and ﬁnal exam scores in a course (ﬁnal ). In our hypothetical model, student ﬁnal exam performance has two direct causes: student ability and studying. Further, the model represents relationships among the determinants of a student’s studying behavior. 
 (1) A noteworthy exception for educational data is ([3]), though their analysis is not directed speciﬁcally at causal discovery. 
 (2) Feedback cycles (in time) can be modeled within the Bayes nets framework by, for example, deploying variables indexed by time. Some literature ([4], [5], [6]) focuses on the discovery of cyclic graphical models, though work on this topic is underdeveloped compared to the Bayes nets formalism. 
 Fig. 2. Graphical representation of hypothetical causal relationships for students in an online course 
 If two crucial (usually reasonable) assumptions hold-the Causal Markov Axiom and the Causal Faithfulness Condition [7]3 - then the causal structure encoded in the Bayesian network graph implies a set of probabilistic (conditional) independence relations between the variables. The Causal Markov Axiom asserts4 that, assuming there are no unmeasured common causes of variables we consider, a variable is probabilistically independent of its non-descendents (noneﬀects) conditional on its direct causes. The assumption of Faithfulness asserts that all probabilistic independencies that are actually observed occur only because of an absence of a direct causal relation. That is, conditional independence between variables does not occur by accident (via canceling out settings of parameters, for example). 
 (3) There is substantial philosophical literature about the Causal Markov Axiom and the Causal Faithfulness Condition (e.g., [9], [10], [11], [12], [13], [14], [15]). I pass over this controversy as these assumptions are standard in the causal learning framework deployed here. 
 (4) Assuming it is possible to represent the underlying causal structure as a directed acyclic graph 
 Fig. 3. Hypothetical illustration of causal relations that could lead to a faithfulness violation 
 To illustrate how a violation of this assumption might occur, consider a slight modiﬁcation to hypothetical causal relations among three variables from Fig. 2 in Fig. 3, in which the association represented by each arrow is positive or negative. Suppose we posit that increased family size has a negative impact on employment; the student is likely to work less as the size of his or her family increases but that employment and family size both contribute to increased noneducational time obligations. The negative eﬀect of familySize on employment combined with the positive eﬀect of employment on obligations, given appropriate (perhaps unlikely) parameter values (representing strength of causal relations), may exactly “cancel out” the positive eﬀect of familySize on obligations. Such “canceling out” parameter values could lead us to believe that familySize and obligations are independent, despite the fact that there is a direct causal relation between the two. This hypothetical judgment of independence despite a direct causal relation is a violation of faithfulness. While a causal Bayesian network implies conditional independencies, this “graphs → independencies” mapping is many-one: for any particular graph G, there will typically be other graphs, though not all graphs, that predict the same (conditional) independencies, and so are observationally indistinguishable from G. We are all familiar with the old maxim that “correlation does not imply causation.” For example, if verbosity in online message forums (messageLength) and studying are correlated, this can be explained by messageLength → studying, studying → messageLength, or studying and messageLength sharing a common cause (as they do in Fig. 2, motivation), or a combination of these explanations. Multiple graphs can imply the same observed correlations and/or independencies. We can use observational data to learn a set of (observationally indistinguishable) causal structures: namely, exactly the set of possibilities that could have produced the observed pattern of independencies in the data. Causal Bayesian network structure learning algorithms, e.g., the PC algorithm [7] and GES ([16], [17]), under suitable assumptions, will identify (the set of observationally equivalent graphs containing) the correct DAG in the large sample limit. Two rough intuitions illustrate basic principles of search for graphical causal models from conditional independence relations. The ﬁrst concerns “screening oﬀ” relations whereby, to consider a simple three variable example, two variables, say messageLength and studying, are correlated but become independent when we condition upon a third variable, motivation; this conditional independence claim tells us that messageLength and studying are not directly causally related. Assuming there are no unmeasured common causes of messageLength, studying, and motivation, this conditional independence claim is explained by three possible causal structures: messageLength → motivation → studying; studying → motivation → messageLength; or messageLength ← motivation → studying. If we lack background knowledge, these three graphs are indistinguishable from observational data. However, if we assume student motivation to be inherent or at least temporally prior to their enrollment in a program and behavior in a course, then we can infer that motivation is a common cause of messageLength and studying. The second intuition has us consider two independent variables that share a common eﬀect. Suppose that a student’s level of motivation and non-educational, time-consuming obligations are independent. We expect that each of these student attributes share a common eﬀect in the amount of time a student devotes to study. Unconditionally the instructor cannot infer anything about a student’s motivation level from the knowledge that a student has many time-consuming obligations outside of the course in which they are enrolled; the instructor, however, can make inferences about a student’s motivation when the student (honestly) reports to the instructor how much they study. If we know that a student is studying a lot while juggling many obligations, we infer something about the student’s motivation level, namely that is high. We can similarly infer from a student’s report that they are highly motivated and yet are not studying as much as they would like that they are likely dealing with many outside obligations. In both cases, when we condition on a common eﬀect two otherwise independent variables now provide information about each other. In the graph of Fig. 2, this is represented as what is called a “collider,” where arrows from motivation and obligations meet at studying (motivation → studying ← obligations). Assuming (however unlikely) that we omit no common causes, there are no other graphical structures that explain this constraint on conditional independencies (or dependencies). That is, we can orient edges into a “collider” when such circumstances arise as we search over conditional independence relations in a larger dataset. Since we also assume that graphs are acyclic, having oriented colliders, we can often orient edges in such ways that avoid creating “colliders” where they were not discovered via tests for conditional independence. Thus, we can often orient many edges to make causal inferences from observational data alone. A constraint-based algorithm such as PC simply systematizes search over (sets of) variables in a data set to determine the conditional independence relations that hold among the variables and produces the set of graphical structures that imply those relations. 
 3 A Simple Causal Model of Outcomes in an Online Learning Environment 
 The work below is certainly not the ﬁrst to deploy methods for causal discovery in the online education domain. Scheines et al. ([18]), for example, focused on a set of variables relevant to students in an online causal and statistical reasoning course, including measures of: 
 – student background knowledge (pre: a measure of pretest abilities derived from GRE items) – behavior in online courseware (print: a measure of the extent to which students print out online course material, and volqs: a measure of the number of interactive, voluntary understanding questions attempted within the courseware), and – learning outcomes (quiz : an average of quiz scores over several course modules, and ﬁnal : ﬁnal exam grade). They then used several causal Bayes net learning algorithms to develop a path analytic model (Fig. 4) for these variables. They found interesting links between the background variable as well as their behavioral variables and learning outcomes. 
 Fig. 4. Linear path analytic model of student behavior and outcomes in an online causal and statistical reasoning course [18]; marginally signiﬁcant edges are dashed 
 Examining this model, student ﬁnal exam performance is well-predicted by the extent to which students “check their understanding,” and printing out reading material is negatively associated with these self-checks. Controlling for other possible mediators they still ﬁnd a negative eﬀect (though it is only marginally signiﬁcant) of greater printing behavior on ﬁnal exam score. They cautiously suggest an interpretation of this eﬀect as due to diﬀering study habits. Students who print out material are less likely to engage the voluntary, interactive questions during studying while students who did not print out material may be more likely to do so. Student behavior with respect to printing course material may also be indicative of other study habits, though those habits were unmeasured in this analysis. Thus, we ﬁnd a fruitful deployment of causal discovery methods to ﬁnd behavioral and background attributes of students in the online environment that are predictive of (and more cautiously, causally related to) learning outcomes. 
 4. The Complexity of Collected Data and Variable Construction.
 Having brieﬂy explored basic principles of causal discovery, we consider a second, more distinctive challenge to discovering causal models that arises from the complexity of the data collected from online courseware systems. Most online courseware collects an enormous amount of data about a multitude of diﬀerent phenomena, which leads to very high-dimensional datasets. Variables collected fall into three rough categories: 
 1. purely observed variables with (relatively) straightforward interpretations or meanings 2. measured indicators of underlying “latent” phenomena, and 3. “raw” variables that require some form of construction to be interpretable or meaningful. 
 The ﬁrst two categories are well-treated in the literature on causal discovery as well as multivariate analysis in general. Further, latent variable modeling is an active area of research in the social science methodology (e.g., psychometrics) community. We also brieﬂy discuss procedures for the discovery of latent variable models later in this work. There is, however, little literature dealing with the third category of variables in a principled way with respect to causal discovery. Natural and social scientists construct variables frequently, but the approach taken is usually either based on signiﬁcant, richly detailed background theory or ad-hoc guesswork. Consider, for example, weather forecasting, in which prognostications are made frequently in terms of “high” pressure and “low” pressure weather systems. While these systems cover large geographic regions, their features-strength, size, speed, etc.-are constructed from a multitude of directly observed barometric pressure readings spread out over large geographic regions. Meteorologists’ high and low pressure systems are instances of constructed variables, while individual, localized barometric pressure readings are the raw variables from which such constructions arise. In general, a host of situations call for principled, data-driven methods for constructing variables from underlying “raw” data. In many cases, we measure many variables but it is not clear just what the causal variables of interest should be. While latent variable modeling is one way to potentially reduce the dimensionality of data, in some situations it is more appropriate to seek dimensionality reduction methods whereby we construct new measured variables as deterministic functions of “raw” measured variables. This diﬀerence between latent variable modeling (i.e., group 2 above) and the construction of variables via deterministic functions of “raw” variables is partly illustrated in Fig. 5. The larger rectangle of Fig. 5 illustrates a discovery and estimation problem within the framework of latent variable models. When deploying a latent variable model, the modeler must ﬁrst decide (or discover) the appropriate causal structure relating latent variables to their manifest eﬀects and then estimate the parameters (“factor loadings”) quantifying the nature of these causal relationships. Conditional upon the latent variable, each of its noisy, measured (or manifest) indicators (X1, X2, and X3 ) is independent of the other measures. Whether this condition is appropriately tested or assumed, this assumption is usually called that of “local independence.” 
 Fig. 5. Illustrative example of the diﬀerence between latent variable modeling and deterministic variable construction. The larger rectangle envelops a discovery and estimation problem, the smaller rectangle a construction problem. 
 Contrast this estimation problem with the heuristic illustration of a variable construction problem in the smaller rectangle of Fig. 5. Here, we call X1, X2, and X3 our “raw” variables and deterministically construct a new variable called scale from these raw variables. Since we are using a latent variable model to motivate the illustration, there are no direct connections between X1, X2, and X3, but this need not be the case in general. Whether or not the “raw” variables are unconditionally independent, they remain or become dependent when conditioning upon the deterministically constructed new variable. Consider the situation in which we construct scale as the sum of only X1 and X2, and assume X1 and X2 to be unconditionally independent. Given information that scale takes on the value 10 (conditioning on scale) and that X2 takes on the value 7, then we know the value of X1 to be 3. Thus, conditioning on scale, X2 provides us information about X1, so the two components of scale are conditionally dependent. In situations in which latent variable models are deployed, scales like this are often constructed as well, and this is just one special case of the general problem at hand. Of course in general, not just any constructions will do. The problem that we face is to reduce a set of “raw” variables {R1 , ..., Rn } to some smaller set of variables {C1 , ..., Ck } via deterministic functions {f1 , ..., fk } of the “raw” variables in order to achieve some objective or goal. In the online education domain, we focus on predicting and identifying causes of learning outcomes as assessed by exam scores, course grades, or perhaps even another constructed variable5 incorporating several aspects of learning outcomes. This search problem is clearly intractable; the search space must be constrained by some combination of background knowledge and a guiding/focal objective function. Background knowledge may be rather general. For example, we might know that the relevant constructed variables will be linear combinations of the raw variables. Other forms of background knowledge may be domain- or application-speciﬁc, such as providing a speciﬁcation of which “raw” variables are relevant for particular constructed variables and which may be disregarded. Objective functions, similarly, may take on a multitude of forms. We might seek functions of raw variables that lead to the best prediction of a particular target variable. Alternatively, we might seek functions of raw variables that lead to greatest amount of causal knowledge with respect to some target variable. Any number of other objective functions may be appropriate in any number of situations, but note that the “best” constructed variables can change depending on the objective function. Once some sensible combination of background knowledge and an objective function have been speciﬁed, we will (hopefully) have a space of functions that is searchable. Thus, we can search for variable constructions for particular purposes. We later consider a speciﬁc example of message forum data from an online learning environment to ﬂesh out some possibilities for this program of research. 
 5 A Simple Pilot Study.
 One might plausibly wonder whether variable construction is actually required for successful prediction. We thus ﬁrst demonstrate that predictions about a set of students enrolled in an online, several month graduate economics course can be improved through the use of constructed variables. We note at the outset, however, that an unqualiﬁed causal interpretation of the resulting DAG is tricky at best, though further research to ﬁnd more plausible or appropriate “causal constructions” is ongoing. Nevertheless, a (graphical) representation of the probabilistic dependence structure for these variables can signiﬁcantly improve predictions. We focus on variables in three rough semantic categories provided in Table 1. Our categorization provides a rough time ordering. Background (including demographic) variables are those upon which we cannot in principle intervene but that might prove useful for predictive and/or classiﬁcation purposes. Behavioral variables measure aspects of students’ interaction with online courseware and are vital to the purpose of discovering the behavioral causes of student learning outcomes. 
 (5) In this work we principally focus on constructing predictors and causes of a given target variable, rather than constructing the target variable itself; the latter problem is brieﬂy discussed later. 
 Table 1. Description of measured and constructed variables included in pilot study 
 These are also the variables most likely to require construction to be meaningfully interpreted. Learning outcome variables are assessed at speciﬁc times within the course in our example. Two individual assignments are graded during the course while an individual ﬁnal exam is assessed at the end of the course. Final course grades are calculated including both individual assessments and assessments of a student’s work with a group of other students. Data from a sample of 815 students are provided to the PC algorithm6 along with time-ordering background knowledge. The algorithm returns a set of DAGs which imply the conditional independence relationships judged present in the data via statistical test. One DAG is chosen, and a path analytic model is estimated according to that structure. This model is provided as Fig. 6 (7). Both the structure of the model and estimated parameters characterize qualitative and quantitative relationships among the variables under consideration. As we are especially concerned with discovering the predictors and causes of learning outcomes, we focus on two particular learning outcome variables. The ﬁrst is student ﬁnal course grade (grade points). The model provides us with something of a “sanity” check of our method in this case. Among the variables directly connected to grade points are variables which constitute the basis by which the instructor assigns the ﬁnal grade, including both assignment scores and the ﬁnal exam score. Other inﬂuencers are GPA and both counts of messages, the instructor’s number of private messages to the student as well as the count of the student’s public and group messages. If we take GPA to be a proxy for general student ability in online courses of this sort (which we implicitly do by taking GPA to be a background variable as opposed to an outcome), then this seems like a sensible picture of the predictors of the ﬁnal course grade. However, the ﬁnal course grade may not be our best target for determining the causes of learning outcomes. 
 (6) Algorithms deployed in this work are all implemented in the freely distributed Tetrad IV suite of algorithms available at http://www.phil.cmu.edu/projects/tetrad. 
 (7) The model of Fig. 6 is judged to ﬁt the data by a relevant statistical test comparing the implied covariance matrix of this model with the sample covariance matrix [19]. 
 Fig. 6. Estimated linear path analytic model from our pilot study. Rectangles are placed around two learning outcomes on which we focus. 
 After all, the same instructor provides grades for assignments as well as the ﬁnal assessment via the course grade, and the ﬁnal course grade is really (in part) just a function of these components. Further, the ﬁnal course grade includes assessments of a student’s group work, so an independent, objective assessment of individual learning outcomes would be helpful. This we ﬁnd in our second learning outcome variable of interest, ﬁnal exam points. Students in this sample had diﬀerent instructors, but all took a ﬁnal exam, provided by a textbook manufacturer, that was independently graded. This provides us with a relatively clean, objective instrument to assess learning outcomes with respect to the material of this online economics course. However, the set of variables directly connected to ﬁnal exam points is relatively small. We ﬁnd that the unmediated predictors of a student’s ﬁnal exam score are sex, GPA, and average score on other MBA course ﬁnal exams. This may provide support for our use of the latter two variables as proxies for ability, but we ﬁnd no direct connections between this independent learning outcome assessment and behavioral variables we consider in this analysis. This, of course, does not mean that behavior and learning outcomes are unrelated. Perhaps we have just not constructed and included the appropriate sets of behavioral variables. We must explore the intriguing possibility that we failed to appropriately “carve up” our behavioral raw data. One crucial way that student behavior is captured in this environment is through messages that students post in an online forum. We need to carefully consider ways in which we can construct variables out of this data. Our ﬁrst pass included ad hoc constructions of studentPublicGroupMessageCount and instructorPrivateMessageCount; we did not ﬁnd signiﬁcant, unmediated links to ﬁnal exam score, though some interesting relationships between demographic features, message behavior, and other variables were discovered. Given the richness and importance of student and instructor interactions via these messages, we choose forum message data as the illustrative example of the problem of variable construction. (8) 
 6 The Construction of New Variables.
 Real, deployed online courseware collects data for every forum message posted by students in a given course. We focus here on only a handful of these characteristics to motivate the problem of variable construction search. For each message we know: 
 - message creator - message timestamp - message content - the forum in which the message was posted, and - whether the course facilitator judged the message as “substantive” or not. 
 These messages can be organized by student9 (as message creator, excluding messages posted by course instructors), and raw variables can be created that correspond to the message attributes. In a course with 50 students, the most proliﬁc of whom posted 100 messages, this scheme results in 400 “raw” variables. A schema of the resulting data set is shown in Table 2. The form of the data (binary, real valued, text, etc.), as well as background knowledge, informs the space of functions over which we might search. A plausible objective function is to optimize predictions for each student of measured learning outcomes, such as score on a ﬁnal exam or course grade. We seek useful, meaningful constructed variables to incorporate into causal and/or predictive models. Numerous potential constructed variables arise even out of our simple toy example. A simple example involves word counts from the content ﬁelds for each student. We let C denote the indices of content ﬁelds in our dataset (C = {2, 6, 10, 14, 18, ..., 398}). 
 
 (8) viewChapterCount is also an ad hoc construction from separate logs in the online courseware that could just as easily be the target of investigation for principled variable construction and search. 
 (9) The reader might sensibly inquire why we choose to organize message data by student (as opposed to, for example, organizing the data by message). This choice provides an organization in which most variables in the data are roughly independently and identically distributed (or i.i.d.). This is necessary for us to proceed with causal discovery techniques we deploy. The data would not be i.i.d. were it organized by message, having a variable representing the message creator. 
 Table 2. Hypothetical table for forum message “raw” variables organized by student. 
 FORMULA(1).
 where wordCount is a function that count words given a ﬁeld of text as an argument, and I is the indicator function (taking value 1 when the content ﬁeld is not empty, 0 otherwise). Letting F denote the set of indices for variables that identify the particular forum in which students posted (i.e., F = {3, 7, 11, ..., 399}), we can reproduce a variable from our pilot study: 
 FORMULA(2).
 Letting S denote the set of indices for variables containing the binary “substantive message” ﬂag, which takes value 1 when a message is substantive and 0 otherwise, (i.e., S = {4, 8, 12, ..., 400}), another simple example is: 
 FORMULA(3).
 We might consider many alternatives. We can deploy any number of functions just on the content and timing of messages. Guided by background knowledge and the form of the data, we iteratively search over potential variable constructions and judge them via resulting models in which they are used. We seek variable constructions and models incorporating them that maximize our ability to predict a student’s ﬁnal exam score and infer causes of learning outcomes. Given often lacking background knowledge tying together education domains with causal inference from data obtained from online courseware, as well as the dimensionality, granularity, and complexity of the latter, we are forced not only to search over potential causal structures that explain the data but also to search for the variables that take part in that modeling. Search for more, better variable constructions is currently ongoing and a topic for further research. 
 7 Future Directions for Causal Discovery from Online Education Data.
 Having delved into the problem of variable construction in considerable depth, we focus on three further problems for predictive and causal inference from online educational data. The resolution of these problems may aﬀect approaches to variable construction and search, but they are general problems for predictive and causal inference even when variables for analysis are given. Roughly these problems are: 1. the treatment of certain categorical variables for causal structure search 2. measurement of target variables intended to capture “learning outcomes”, and 3. inferring the presence of unmeasured (latent) common causes. We provide a brief overview of each of these problems and suggest some potential solutions. Getting a handle on approaches to these three problems in addition to the problem of variable construction will certainly advance the state-of-theart with respect to causal discovery in online education settings as well as for learning analytics in general. 
 7.1 The Treatment of Certain Categorical Variables for Causal Structure Search 
 A variety of phenomena in our pilot study are best represented by discrete variables; we include binary variables, for example, representing gender and Pell Grant eligibility. Other discrete and categorical phenomena cannot be ignored in attempts to discover causal structure. For example, learners may come from various demographic and ethnographic groups, and instructors may have various levels of preparation and credentials. To produce satisfying causal explanations of student learning, we must attempt to control for diﬀerences arising because of these categorical phenomena. If we treat the set of learners who, for example, had a particular instructor for a course as a separate sample for analysis, we consider a much smaller sample, leading to concerns for small eﬀect sizes and the power of statistical tests deployed for causal structure search. Further, discrete variables may pick out genuinely diﬀerent populations of learners having diﬀerent underlying causal structures. We focus on diﬀerences between instructors. Certain aspects of the educational experience of the student may be independent of the instructor (e.g., student messaging behavior may be unrelated to a particular instructor or course oﬀering); other aspects may be dependent on the instructor, and the underlying causal structure we attempt to model may be diﬀerent from instructor to instructor. In our pilot study, we included a measure of the instructor’s peer review score as a ﬁrst attempt to control for the instructor of each course, but this approach is sub-optimal as this variable takes on the same value for every student within a given class and is thus not independent and identically distributed (or i.i.d.) (10). 
 (10) This illustrates a general problem for deploying methods that rely on statistical tests for conditional independence when we have mixed data (including both categorical and continuous variables). A variety of techniques can be used to mitigate this problem. We might, for example, discretize continuous variables or treat binary or ordinal categorical data as if it were continuous (our strategy for treating binary variables and instructor avg pr in our pilot study). Diﬀerent situations will suggest diﬀerent approaches. 
 Further, conditional independence relations that obtain in distributions for individual instructors may not obtain in the distribution created by the combination of data sets for all instructors. Also, information common to distributions for every instructor can be destroyed even if instructors’ courses are well-represented by the same causal structure (cf. [20], [21]). We need some way of investigating what are potentially diﬀerent causal structures among instructors to provide causal insights into the dynamics of online courseware on a relatively large scale. An intuition about how to attack this problem comes from considering what we might call “invariant edges.” We begin by stratifying our full dataset into datasets for each individual instructor. We call “invariant edges” those that are discovered by graphical search procedures when applied to each instructor’s respective data set. We should expect, for example, that the edges oriented into grade points will remain invariant across instructors, as the ﬁnal course grade is a (noisy) function of various components included in the model. We know the “causes” of the ﬁnal course grade in this sense, but we might also discover other features of the underlying causal structure by ﬁnding other invariant edges. However, invariance over all data sets might be too strict a standard. Ramsey et al. [21] attack a similar methodological problem; they seek to discover what we might call “approximately invariant edges” from brain imaging (fMRI) studies in cognitive neuroscience. Seeking to discover qualitative causal relations amongst regions-of-interest (ROIs)11 in the brain, they provide a modiﬁcation of a causal structure learning algorithm that helps address this related problem. In fMRI data, from individual to individual, both the strength of causal relations among regions of the brain may diﬀer as well as the underlying causal structure itself may diﬀer. These possibilities coupled with various sources of measurement error lead to diﬀerent distributions (and data sets) for each individual of a study. The individuals of fMRI studies correspond to instructors in our online education setting; we face similar issues of diﬀering strength of causal relations and potentially diﬀering causal structure from instructor-to-instructor. Just as everyone has unique brain physiology, every classroom is unique. Ramsey et al. [21] propose IMaGES (Independent Multiple-sample Greedy Equivalence Search) as a modiﬁed version of Meek’s GES ([16], [17]) algorithm. This algorithm searches over equivalence classes of graphs, represented by a particular type of graphical structure called a pattern. Beginning with an empty graph, GES proceeds in two waves. In the ﬁrst, single edges are added until a Bayesian score assigned to each graph can no longer be improved. In the second wave, individual edges are deleted until the score can no longer be improved. Brieﬂy, IMaGES follows the same score-based procedure as GES, but at each stage the graph under consideration is scored based on its average score over each individual data set. This allows us to discover better models of the data we have despite the possibility of instructor-to-instructor variation in causal strength and causal structure. 
 (11) The construction of ROIs is itself another instance of the problem of variable construction that must be dealt with to reliably discover causal relations. 
 However, no work has deployed this technique in cases in which we also search for variable constructions or in applications outside of cognitive neuroscience. 
 7.2 Measurement of Target Variables for “Learning Outcomes”.
 In some cases, we are faced with a relatively simple (and relatively “noise-free”) target variable, for example, student retention rate or a variable representing whether (or when) a student dropped out of a particular course. At other times, our interest is establishing the predictors and causes of learning. To survey the broad scope of the problem of measuring student learning outcomes goes well beyond the scope of this paper. Sometimes we may have a well-devised assessment of learning gain in a particular course, perhaps from pre-test and post-test instruments. We then would seek out the predictors and causes of learning gain as advocated above. Frequently, however, we seek to measure “amount of learning,” treating it as a hidden construct with several possible indicators or measures. The design of instruments to measure such latent phenomena falls within the realm of the ﬁeld of psychometrics. Successful instruments to assess constructs like “amount of learning” must not only have established validity, so that they measure the intended phenomenon, but must also be reliable. Reliability is cashed out in social science research in a variety of ways. Dealing with diﬀerent instructors, who may grade by diﬀerent standards, leads us to seek an instrument with which we can achieve high “inter-rater” reliability. “Test-retest” reliability is another standard sought for learning assessment instruments. Further, we might be concerned that multiple items that make up an instrument are internally consistent, as assessed commonly by a measure like Cronbach’s alpha [22]. Some work has been done (e.g., [23]) connecting such traditional notions of reliability in the social sciences with reliable causal discovery, but further investigation is necessary. While the ﬁnal exam grade we consider in our pilot study has convenient properties for causal and statistical analysis as it is standardized for this course, designed by the course textbook manufacturer, and graded independently of the instructor, it is not ideal. We should seek out better, more robust indicators to assess learning outcomes, which are likely to vary from course-to-course and from program-to-program. Data-driven methods, augmented by expert domain knowledge, can inform the speciﬁcation of an outcome variable. We provide one potential methodological approach to this problem after we consider a third challenge we face. 
 7.3 Inferring the Presence of Unmeasured Common Causes.
 As is realistic in most social science applications, including those in the education domain, we must relax an assumption posited in our pilot study: namely, that our model includes all common causes of any variables therein. This assumption is called “causal suﬃciency” in causal discovery parlance (cf. [7]). If we relax this assumption and allow that there may be unmeasured or “latent” confounders of the variables we consider, we can deploy causal discovery algorithms that detect where such confounding may be present. The FCI algorithm [7] is intended to do just this, providing graphical output that indicates if variables potentially share an unmeasured common cause. The output of FCI for the data from our pilot study is provided as Fig. 7. Edges that appear as X ↔ Y indicate the presence of an unmeasured common cause of X and Y; edges that appear as X o→ Y indicate that either X is a cause of Y or they share an unmeasured common cause; edges that appear as X o-o Y indicate that either: (1) X causes Y, (2) Y causes X, (3) X and Y share a common cause, or (4) a combination of (1) and (3) or (2) and (3). 
 Fig. 7. Result of FCI search over data from our pilot study.
 The results align with intuitions in several ways, suggesting that measures of message counts share a common cause as well as suggesting that both GPA and average MBA exam scores share a common cause, perhaps something like background knowledge or ability. Other possible interpretations remain. The inference that we have possibly omitted common causes of variables provides great insight such that we might iteratively construct new models and measure new phenomena. Returning to the problem discussed in the previous section, we can deploy FCI search over a set of ﬁxed variables to inspect whether the result suggests that intended learning outcome measures share an unmeasured common cause; such a result provides evidence that latent variable model may be appropriate. We might construct a scale to serve as a proxy for such a latent variable reiﬁed as a learning outcome. The Build Pure Clusters algorithm (BPC [24]) might be deployed for a similar purpose to determine the suitable components of such a proxy constructed variable. Under suitable conditions (namely that indicators are linearly related to the underlying latent), the BPC algorithm discovers sets of variables that are measured indicators of only one underlying phenomenon and that satisfy other important assumptions for causal discovery. This returns to the problem of discovery and estimation illustrated in the large rectangle of Fig. 5. Such an algorithm can be fruitfully deployed, for example, to provide background knowledge to variable construction search procedures in cases in which we seek to construct a scale as a proxy for a latent phenomenon. 
 8 Conclusion.
 We have outlined several problems for causal discovery from observational, online education data, focusing especially on the complexity of data collected from online courseware. A pilot study suggests that ad hoc variable constructions are less successful than we would like for prediction and inferring causes of learning outcome variables. This contributes to the need for principled means of search over potential variable constructions from such complex data sets. Further, other important problems for causal discovery from data in this domain are illuminated, and we introduce techniques that might be deployed to (partially) solve these problems. Open avenues for research are plentiful. Setting up the appropriate space of search for variable constructions will require the input of domain experts and the implementation of appropriate search procedures. Data for other courses and from other academic programs will have to be considered. New “raw” variables can be included from the large amount of historical data available for the course used in our pilot study. Finally, the speciﬁcation of “learning outcomes” is a problem faced throughout education. Working from expert domain knowledge, we might seek ways in which data-driven methods can fruitfully address this problem, providing speciﬁcations useful for causal discovery and for the learning analytics and educational research community at large. Acknowledgments. The author wishes to thank David Danks, Satish Menon, Partha Saha, and Richard Scheines for helpful discussions and comments on early drafts of this work. Further, the author thanks Apollo Group, Inc. for a summer internship to conduct the “Simple Pilot Study,” and Partha Saha for extensive support and advice on data access, understanding, and manipulation during that time.